


\section{Introduction}
Within any organisation, no matter what the type, communication must be present. If members of a company don't communicate, then there is no way for a worker to know what they should be doing, or if what they are doing is actually important to the company. At the same time, if all members of an organisation are talking to each other there this may get in the way of actual work being done, as well as giving rise to redundant communication. We seek a way to model this phenomenon, and hence improve the efficiency of an organisation.

paragraph about other approaches being taken

The approach we take is inspired by the brain. If we think of the neurons within the brain passing information between each other, then this becomes a similar problem to communicating within an organisation. Motivated by this, we attempt to apply Integrated Information theory to the problem.

What is integrated information theory? Originally present in 2004 by Tononi \cite{tononi2004information}, this is the most recent attempt to rigorously define consciousness. Since its first appearance it presents the function $\Phi$ which computes the integrated information of a system of mechanism. The main claim of integrated information theory is that consciousness and integrated information are the same thing, and hence computing $\Phi$ is computing consciousness. The arguments used to justify this claim are primarily philosophical in nature, and thus will not be discussed in this report. 

Since 2004, IIT has received multiple updates and adjustments \cite{tononi2011integrated,balduzzi2008integrated,tononi2016consciousness} each of which resolve issues found in the previous definition. Currently the most up to date version of IIT is version 3.0 \cite{oizumi2014phenomenology}, and hence we will primarily focus on that version in this report.

While IIT has developed from version 1.0 to 3.0 by its inventor Giulio Tononi, at the same time other authors have developed the theory in different directions. For example Barrett and Smith \cite{barrett2011practical} designed an alternative definition in order to apply the theory to time series data. A list of such alternative definitions was compiled by Tegmark \cite{tegmark2016improved} for the purpose of considering their relative mathematical merits.

Our focus is to investigate whether the computation of $\Phi$ for a network model of an organisation might give any insight into the efficiency of communication within the organisation. As $\Phi$ is expensive to compute (as will be discussed in greater detail in section \ref{sec:cost}), we restrict our attention to a small scale toy model which we derive for the purpose of capturing the effects of poor communication within an organisation. Although computation of $\Phi$ based on IIT 2.0 is cheaper than for 3.0, we choose to use the most up to date version in order to ensure that we keep up to date with the state of the theory. 

\section{Integrated Information Theory}
\label{sec:iit}

In this section, we present an overview of Integrated Information Theory 3.0 as presented by Oizumi et all \cite{oizumi2014phenomenology} using a combination of their notation as well as that of Krohn and Ostwald \cite{krohn2016computing}.

\subsection{Definitions and Notation}

Integrated Information Theory introduces a function $\Phi$ which measures the integrated information of a discrete time multivariate stochastic process. We write:

\begin{equation}
\label{def:1}
Z_t = \left(\begin{array}{cccc} z^1_t&z^2_t&\ldots&z^n_t\end{array}\right)
\end{equation}

to represent the multivariate random variable, where $z^i_t \in \{0,1\} \quad\forall i, t$. This stochastic process can be related to a graph containing $n = |Z_t|$ nodes. Each node refers to one of the $z^i$'s and can be in one of two states: `off' at time $t$ if $z^i_t=0$ and `on' if $z^i_t = 1$. We join $z^i$ to $z^j$ with a directed edge if the future state of $z^i$ depends in some way on $z^j$. From now on, we will refer to the $z^i$'s as `nodes'.

Before we proceed, we need to specify what is meant by the terms \textit{mechanism} and \textit{system of mechanism}.

\begin{figure}[ht]
	\centering
	
	\includegraphics[scale = 0.12]{IITexplanationdiagram1.png}
	\caption{In this illustration, we identify the mechanism $CD$ by circling it in red. The system of mechanisms in consideration is similarly circled in green. Finally, all nodes lying outside of the system are considered to be external inputs/outputs.}
	\label{fig:IIT_illustration1}
\end{figure}


\begin{definition}{A \textit{mechanism} refers to any non-empty set of nodes. The \textit{order} of a mechanism refers to the size of the set. A mechanism is \textit{elementary} if it is of order 1.}
\end{definition}

\begin{definition}{A \textit{system of mechanisms} is a set of mechanisms. The elements of this set may have non-empty intersections.}
\end{definition}


Just as each node can be in one of two states, so too can mechanisms and systems be in states. The state of a mechanism is the combination of the states of all nodes within it. For example, if we have $z^1=1$, $z^2=0$ and $z^3=0$, than the mechanism $Z = \left(\begin{array}{ccc}z^1&z^2&z^3\end{array}\right)$ has state $\left(\begin{array}{ccc}1&0&0\end{array}\right)$. 


The progression of $Z_t$ as time passes is dictated by the transition probability matrix (TPM) $\mathbf{M}$, which gives at $M_{ij}$ the probability of transitioning from state $i$ to state $j$ after a single time step. There are 3 points in time for which we consider a mechanism: the immediate past (time $t-1$), present (time $t$) and future (time $t+1$). Oizumi et all \cite{oizumi2014phenomenology} denote the state of a mechanism at these times by $Z^c$, $Z^p$ and $Z^f$ referring to the current, past and future states respectively. Alternatively, Krohn and Ostwald \cite{krohn2016computing} write $Z_{t-1}$, $Z_{t}$, and $Z_{t+1}$. In this document, we adopt the latter style.


\begin{definition}
	{Let $Z$ be a mechanism with $W\subset Z$, and suppose that the current state of $W$ is known, that is: $W_t = X$. Then the \textit{effect repertoire} of the state $W_t = X$ is the conditional probability distribution for the future states of $Z$ given our current knowledge. We write it as $p_e(Z_{t+1}|W_t=X)$. Similarly the \textit{cause repertoire} of the state $W_t = X$ is the conditional probability distribution for past states of $Z$ given our current knowledge. We write it as $p_c(Z_{t-1}|W_t = X)$.}
\end{definition}


\subsection{Computation of Repertoires}
\label{sec:cost}
In this section, we construct each of the previously defined repertoires from the TPM. First however, we need to introduce both the \textit{perturb function}, and the assumption of conditional independence, as all future definitions rely on these.

\begin{definition}
	{Let $S$ be a set such that $|S| = n$, and its elements are indexed by $s_1, s_2, \ldots, s_n$. Further let $f$ be a function which operates on the elements of $S$. Then we write the perturbation function as:
	\[per(f(a, S), S) = \left(\begin{array}{cccc}f(a,s_1)&f(a,s_2)&\ldots&f(a,s_n) \end{array}\right)^T\]
	That is, the perturbation function returns a vector where each of its entries corresponds to the $f$ taking a different input from $S$.}
\end{definition} 

\subsubsection{Conditional Independence}
\label{sec:conditional_independence}
In order to simplify all computations, IIT makes a large mathematical assumption. Specifically it assumes that the probability distributions for the future states of each node are conditionally independent with respect to the previous state of the system. i.e. if $Z$ is a mechanism, then:

\begin{equation}
\label{eq:cond_independence}
p(Z_{t+1}|Z_t = X) = \prod \limits_{i=1}^{n} p(z^i_{t+1}|Z_t=X)
\end{equation}

This assumption allows us to simplify the $2^n \times 2^n $ \textit{state by state} transition probability matrix $\mathbf{M}$ into the $2^n \times n$ \textit{state by node} transition probability matrix $\mathbf{T}$. As is, each row of $\mathbf{M}$ is a distribution containing the probabilities that any of $2^{|Z|}$ possible future state may be transitioned to. We replace this row with the values of $p(z^j_{t+1}=1|Z_t=X)$ where $j$ is a column index. Equation \ref{eq:cond_independence}, along with the fact that: \[p(z^i_{t+1}=1|Z_t=X)+p(z^i_{t+1} =0|Z_t=X) =1\]
allows this smaller row of only $n$ values to uniquely specify the larger row of length $2^n$.


\subsubsection{Effect repertoire}

Let $Z$ be a mechanism, and suppose that the state of the subset $W \subset X$ is known: $W_t = X$. Then we first define the \textit{effect repertoire} to have the property of factorisation, that is:

\begin{equation}
\label{def:controversial}
p_e(Z_{t+1}|W_t = X) = \prod \limits_{i= 1}^n p(z^i_{t+1}|W_t = X)
\end{equation}

It is important to note that this factorisation does not follow generally from equation \ref{eq:cond_independence}, as it was only assumed that future state of each node was conditionally independent with respect to the current states of the entire system, as opposed to with respect to all possible subsets of this system as well.

This is justified by Oizumi et all \cite{oizumi2014phenomenology} in their supplementary methods document on the grounds that they are interested in how $W_t=X$ affects each $z^i_{t+1}$ individually and thus factorise as above in order to remove correlations.


Finally, let $W$ be a subset of $Z$ which is known, and let $z^{i_0}$ be a particular node in $Z$. Then we have:
\begin{equation}
\label{def:effect_repertoire}
p_e(z_{t+1}^{i_0}|W_t = X) = 2^{-|Z\setminus W|}\sum \limits_{Z\setminus W} p(z_{t+1}^{i_0}|W_t = X, Z\setminus W)
\end{equation}

This is equivalent to averaging over all rows of the TPM which corresponds to states of $Z_t$ such that $Z_t \supset W_t = X$.

Hence, the generator \textit{unconstrained effect repertoire} $p(Z_t | \emptyset)$ is s

\subsubsection{Cause repertoire}

Just as the effect repertoire is broken into a smaller problem in equation \ref{def:controversial}, there exists an equivalent simplification for computing the cause repertoire. Let the state of $W \subset Z$ be known,$m:=|W|$, and $V$ be any other subset of $Z$. Then 

\begin{equation}
\label{def:cause_rep1}
p_c(V_{t-1} | W_t=X) = \prod \limits_{i = 1}^{m} p_c(V_{t-1}|w^i_{t} = x^i)
\end{equation}

We then complete the computation as follows:

\begin{equation}
\label{def:cause_rep2}
p_c(V_{t-1}| w_t = x) = \frac{\sum \limits_{Z\setminus V} p_e(w_t = x| V_{t-1}, Z \setminus V)}{p(w_t = x)}
\end{equation}

In short, we add up the probabilities of each individual previous state resulting in our current information ($w_t = x)$, and then scale by the overall probability that we observe $w_t = x$ in the first place. Note that equation \ref{def:cause_rep2} features the effect repertoire $p_e$ on the right hand side, not $p_c$.

\begin{remark}
	Equation \ref{def:cause_rep1} does not make an additional assumption, but rather follows as a consequence from equation \ref{def:controversial}.
\end{remark}



\subsection{The Earth Mover's Distance (EMD)}
In the context of this document, we will frequently calculate the distance between two probability distributions $p1$ and $p1$. For this we will use the mathematical notation $D(p1,p2)$, where $D$ is referring to the earth mover's distance.

To use this distance measure, we require the existence of another metric which measures the distance between any pair of states. Here we use the Hamming distance for this purpose, that is the number of individual bytes which disagree when comparing two states. (i.e. the hamming distance between 001 and 101 is 1, as the have 1 disagreement in the first digit)

In simple terms, if we think of each distribution as piles of dirt on top of each given state. The earth mover's distance is the product of how much dirt needs to moved by how far this dirt needs to go. 

\begin{description}
	\item[EMD between Probability Distributions] Let $S$ be a set of $n$ states, $\mathbf{D} = \left[ D_{ij}\right]$ where $D_{ij}$ is the distance between $s_i$ and $s_j$, $P$ and $Q$ be two probability distributions over $S$ such that $P(X = s_i) = p_i$ and $Q(X=s_j) = q_j$, $\forall i,j$. 
	
	Calculate $\mathbf{F} = \left[F_{ij}\right]$ matrix which optimises the following problem:
	
	\begin{align}
	\label{eq:EMD1}
	\min \limits_{\mathbf{F}}\sum \limits_{i,j=1}^n &F_{ij} D_{ij}\quad \text{subject to}\\
	&F_{ij}\geq 0,\quad \forall 1 \leq i,j \leq n\\
	\sum \limits_{j=1}^n &F_{ij} = p_i,\quad 1 \leq i \leq n\\
	\sum \limits_{i=1}^n &F_{ij} = q_j,\quad 1 \leq j \leq n
	\end{align}
	
	Finally, we say: 
	
	\begin{equation}
	\label{def:EMD}
	\text{EMD}(P, Q) = \sum \limits_{i,j=1}^{n} F_{ij} D_{ij}
	\end{equation}
\end{description}

From now on, we'll use the notation $D(P,Q)$ to denote the earth mover's distance instead of bothering with $\text{EMD}(P,Q)$ each time.

\subsection{Calculations for Mechanisms}\label{sec:little_phi}
When making a computation for a mechanism, we must be sure to treat each type of node appropriately. Let $G$ be the set of all nodes present, $Z$ be the system of nodes which we are considering, and $W$ the mechanism within the system. For an illustration of this, consider figure \ref{fig:IIT_illustration1}.

For all nodes in $G\setminus Z$, that is the external inputs/outputs, we treat their states as constant. We do not concern ourselves with their past or future states when computing repertoires. However, the state of these nodes may affect the nodes within the mechanism $W$.

In contrast, the state of nodes within $Z \setminus W$ are treated as unknown. While they do affect past and future repertoires, the do so differently than nodes within the mechanism. Finally, we are concerned with how the state of the mechanism constrains the past and future states of these nodes.

\subsubsection{Cause-Effect Information}
The cause-effect information ($cei$) is a measurement of the significance which a piece of information has. It is calculated in 2 parts. First we have the cause information ($ci$), which measures how the past can be constrained given knowledge of the present. It is defined by:

\begin{equation}
\label{def:ci}
ci(W_{t} = X) = D\left(p_c(Z_{t-1}|W_{t} = X)||p_c(Z_{t-1}|\emptyset)\right)
\end{equation}


Next we have the effect information ($ei$), which measures how the future is constrained given knowledge of the present. We define it as:
\begin{equation}
\label{def:ei}
ei(W_{t} = X) = D\left(p_e(Z_{t+1}|W_{t} = X)||p_{e}(Z_{t+1}|\emptyset)\right)
\end{equation}

Finally, we define the cause-effect information ($cei$) to be the minimum between the cause information and effect information:

\begin{equation}
\label{def:cei}
cei(W_{t} = X) = \min\left(ci(W_{t} = X), ei(W_{t} = X) \right)
\end{equation}

\subsubsection{Integrated Information}
\label{sec:mech_integration}
IIT assumes that only information which is irreducible can contribute to consciousness. This motivates the calculation of $\varphi$, which calculates the distance between the cause-effect repertoires of an entire mechanism, and the cause-effect repertoires of the partitioned mechanism. 

Intuitively, if a mechanism can be split into parts and these smaller mechanisms generate the same result, then the mechanism is reducible and $\varphi=0$. In contrast, the larger $\varphi$ is, the more information the mechanism has beyond the sum of its parts.

As addition to $Z$ and $W$, we introduce the sets $N \in \mathbb{P}(W)$ and $M \in \mathbb{P}(Z)$.

\begin{equation}
\label{def:preMIP}
p_c(A_{t-1}|B_t ,M, N):= p(N_{t-1}|M_t) p(A_{t-1} \backslash N_{t-1} |B_t \backslash M_t)
\end{equation}

Then we define:

\begin{equation}
\label{def:phi2}
\varphi_{cause}^{M,N}(W_t=X, Z) := D \left( p_c(Z_{t-1}|W_t=X) ,p(Z_{t-1}|W_{t} = X,M,N)  \right)
\end{equation}.

With the benefit of this notation, we now introduce the notion of the minimum information partition (MIP). Specifically, the MIP refers to the sets $M'$ and $N'$ which minimise $\varphi_{cause}$. We then have:

\begin{equation}
\label{def:phi3}
\varphi_{cause}^{\text{MIP}}(W_t=X, Z)  = \varphi_{cause}^{M',N'}(W_t=X, Z) 
\end{equation}

$\varphi^{\text{MIP}}_{effect}$ is defined similarly. One need only swap $p_c$ for $p_e$ superscript. This allows us to define integrated information $\varphi$:
\begin{equation}
\label{def:phi}
\varphi^{\text{MIP}}(W_t=X, Z) = \min \left( \varphi_{cause}^{\text{MIP}}(W_t=X, Z), \varphi_{effect}^{\text{MIP}}(W_t=X, Z)  \right) 
\end{equation}



It is useful to recognise the relation between $\varphi^{\text{MIP}}$ and $cei$. Specifically we have following result which was established by Marshall et all \cite{marshall2016integrated}:
\begin{equation}
\label{eq:bound_phi_cei}
\varphi^{\text{MIP}}(W_t=X, Z) \leq cei(W_t=X) 
\end{equation}

This implies that the biggest different we can make to $\varphi$ by partitioning a mechanism occurs when the partitioned repertoire is precisely the unconstrained repertoire. 



\subsubsection{Maximally Integrated Information}
It follows from the assumptions of IIT that a mechanism has a unique cause and effect. We identify these as the maximally irreducible causes and effects respectively. 

Let $W_t = X$. We now ask the question: what is the cause of $X$? Any element in $\mathbb{P}(Z)$ is a candidate, so we need to conduct an exhaustive search. Hence we define $\varphi^{\text{Max}}$, the maximally integrated information as: 
\begin{equation}
\label{def:core_cause}
\varphi^{\text{Max}}_{\text{cause}}(W_t = X):=\max \limits_{S \in \mathbb{P}(Z)}\varphi^{\text{MIP}}_{\text{cause}}(W_t = X|S)
\end{equation}

The particular set $S'$ which maximised the right hand side we call the \textit{core cause}. The \textit{core effect} and $\varphi^{\text{Max}}_{\text{effect}}$ are defined in the equivalent fashion. Finally we finish  by setting $\varphi^{\text{Max}}$ to be the minimum of the two as before. It is important to note that we find the core cause and effect separately, and that these need not be the same set.

As with $\varphi^{\text{MIP}}$ we can bound $\varphi^{\text{Max}}$. Specifically we have for any current state $X$ that:

\begin{equation}
\label{eq:bound_phimax}
\varphi^{\text{MIP}}(W_t = X, Z) \leq \varphi^{\text{Max}}(W_t = X)\leq cei(W_t = X)
\end{equation}

If we find that $\varphi^{\text{Max}}(W_t = X)>0$, then we call the combination of $\varphi^{\text{Max}}(W_t = X)$ with its core cause and effect a \textit{concept}. This allows us to define a MICE.

\begin{definition}
	{The maximally integrated cause effect repertoire of a piece of information, or MICE, refers to the combination of the cause repertoire $p_c(C_{t-1}|W_t = X)$, where $C$ is the core cause of $W_t=X$ along with the effect repertoire $p_e(E_{t+1}|W_t = X)$, where $E$ is the core effect of $W_t = X$.}
\end{definition}

\subsection{Calculations for Systems of Mechanisms}
Thus far calculations have been restricted to a single mechanism, whether 1st, 2nd, or $n$th order. However, a network of more than one node may contain multiple mechanisms, which may overlap with each other. For example, a system of 3 nodes could potentially contain 7 mechanisms (all possible subsets of nodes less the empty set).

Now we focus our attention on computing integrated information in a system of mechanisms. 

\subsubsection{Conceptual Information}
\label{sec:CI}
The Conceptual Information (CI) extends the notion of cause-effect information to a system of nodes. Before we computed the distance between the repertoire specified by some information and the unconstrained repertoire. Now, instead of computing the distance between repertoires, we add up the distances between concepts.

The Conceptual Information is simply weighted sum of the distance between the MICE of each of its concepts, and the unconstrained MICE. We compute it below:

\begin{equation}
\label{def:CI}
CI(Z_t = X) = \sum \limits_{S \in \mathbb{P}(Z)} \varphi^{\text{Max}}(S_t=X) D(M^S, M^{uc})
\end{equation}

where $M^S$ refers to the MICE of the concept $S$, and $M^{uc}$ is the unconstrained MICE, which is just the unconstrained cause and effect repertoires. We measure the distance between $M^S$ and $M^{uc}$ by adding the distances between the two cause, and effect repertoires.

\begin{remark}
	Equation \ref{def:CI} uses Oizumi et all's \cite{oizumi2014phenomenology} definition of $CI$. However, it was pointed out by Krohn and Ostwald \cite{krohn2016computing} that this definition is not well defined. The MICE is defined as the set of cause and effect repertoires that maximize $\phi^{MIP}$. However, there may be two such MICE's: $M_1$ and $M_2$, which yield the same value for $\phi^{Max}$, and yet affect equation \ref{def:CI} differently. We show equation \ref{def:CI} as we used the software provided by Mayner et all \cite{pyphi} which follows the flawed definition. Krohn and Ostwald propose a simpler definition which fixes this issue, where they merely add up the values of $\varphi^{\text{Max}}$, and ignore the MICE.
\end{remark}

\subsubsection{Integrated Conceptual Information}
Now we measure the integration of a piece of information on the level of a system of mechanisms. Here it is useful to define the term \textit{constellation}.

\begin{definition}
	{A \textit{constellation} refers to the set of all concepts within a system, each concept equipped with its' MICE.}
\end{definition}

As before, we consider all ways to partition the system $Z$. However, on this occasions, each partition is a one directional cut. Hence there exist twice as many possible partitions as in section \ref{sec:mech_integration}. We compute the constellation for the partitioned system, labelling it as $M^p$. For this partitioned system, some of the concepts from the while system will remain intact, but others will have been destroyed by the partition.

Let the function $C(P)$ refer to the set of concepts, given the partition $P$. Then we define:

\begin{equation}
\label{def:Phi_integration1}
\Phi^P(Z_t = X) = \sum \limits_{S \in (Z \setminus C(p))} \varphi^{\text{Max}}(S_t = X)D(M^S, M^{uc})
\end{equation}

The difference between $\Phi^P$ and $CI$ is that while in $CI$ we sum over all concepts, in $\Phi^P$ we only sum over the concepts which have been destroyed by the partition.

As before we seek the minimum information partition (MIP). This time we define it as:

\begin{equation}
\label{def:Phi_integration2}
\Phi^{\text{MIP}} (Z_t = X) = \min \limits_{P} \Phi^P(Z_t = X)
\end{equation}

\begin{remark}
	As in section \ref{sec:CI}, the value specified in equation \ref{def:Phi_integration2} is not defined, for the same reason as previously. Krohn and Ostwald present the same solution as before: they remove the $D(M^S, M^{uc})$ term from the equation, leaving only the $\varphi^{\text{Max}}$ terms.
\end{remark}

\subsubsection{Maximally Irreducible Conceptual Structure}

Thus far in how $\Phi$ is defined, there exists an intuitive example which breaks the definition. Consider a network consisting of a dense cluster of nodes which has a large value of $\Phi$. Next, add a single node to this cluster, which we connect to the cluster with a single edge. If we compute $\Phi$ now, find a partition which makes almost no difference at all (when we eliminate the single node), which results in the new system having a small $\Phi$ value. 

Intuitively we understand that the conclusion: `adding a single extra neuron to the brain destroys all consciousness' is ridiculous. Hence we need the value $\Phi^{\text{Max}}$ to finish our definition of Integrated Information Theory. We define:

\begin{equation}
\label{def:Phimax}
\Phi^{\text{Max}}(Z_t = X) := \max \limits_{W \in \mathbb{P}(Z)}\Phi^{\text{MIP}} (W_t = X)
\end{equation}

\begin{remark}
	When we compute $\Phi^{\text{MIP}} $ for all subsets $W$ of $Z$, we are not computing it over the \textit{mechanism} $W$ but rather over the \textit{system} $W$. This means that all nodes in $Z \setminus W$ are now treated as external inputs/outputs, instead of unknown nodes in system.
\end{remark}

\subsection{Computational Cost}
We now ask how expensive is the computation of $\Phi^{Max}$. Let $Z$ refer to a system of nodes such that $|Z| = n$.

\begin{enumerate}
	\item To compute $\Phi^{\text{Max}}$, we must calculate $\Phi$ for possible subsets of our system. There are at most $2^n$ such subsets, and hence we must compute $\Phi$ this many times.
	\item For a particular subset of consideration, we must determine the Minimum information partition of one directional cuts. If the subset is of size $m$, then there at most $2^{m+1}$ ways to do this (if the connectivity matrix is sparse, then there are considerably less). $m$ itself is bounded by $n$, so we say that this step must occur at most $2^{n+1}$ times.
	\item Each computation of $\Phi$ for a particular partition requires the calculation of all values of $\varphi^{\text{Max}}$. As each element of the power set may have a positive value of such, we must carry out this computation up to $2^n$ times.
	\item Each computation of $\varphi^{\text{Max}}$ requires both the core cause and core effect to be identified. This involves calculation $\varphi^{\text{MIP}}_{cause}$ and $\varphi^{\text{MIP}}_{effect}$ each over the entire power set, resulting in a further $2^{n+1}$ computations.  
	\item To compute $\phi_{cause}^{\text{MIP}}$, we must search over all possible partitions. There are $2^n$ of these.
	\item Finally, when measuring the difference made by a partition, we must measure the distance between probability distributions. This is done using the Earth Mover's Distance, which scales $O(N^3 \log N)$, where $N$ is the number of states found in the distributions the distance is being measured between. As there are $2^n$ of these, this step scales with $O(2^{3n} (\log n)^3)$
\end{enumerate}

When we put this all together, we conclude that the calculation of $\Phi^{Max}$ scales with $O(n^3 2^{8n})$.


\section{Modelling an Organisation}

In this section, we seek to model communication flow within an organisation. To do this, the first step is to specify the type of organisation that we're referring to. 

\begin{enumerate}
	\item The organisation is a company which generates revenue by completing projects.
	
	\item Each project requires the application of certain skills in order to be completed.
	
	\item The organisation consists of a fixed number of teams, each possessing one or more skill.
	
	\item Projects are completed by assigning sufficiently many teams to the project which possess all skills required to complete the project.
\end{enumerate} 

Within this framework, where does communication come in? Suppose that a project appears which requires python programming skills. Further, let there be 2 distinct teams which have this skill. What happens now? If these teams are not communicating, then they might both take on the same project, depending on the policy by which they decide what to do. Alternatively, if they are communication, not only can they guarantee that they don't do the same thing, but they can also collaborate with each other, thus finishing the project faster than otherwise.

Suppose we have $n$ teams. We represent these teams in mathematics as nodes in a graph. Each of these nodes has 2 states: `on' and `off'. A team is active if its node is `on', and is idle if the node is `off'. Next we say that one team $v_1$ is paying attention to another team $v_2$ if there exists a directed edge from $v_1$ to $v_2$. Furthermore, these teams are said to be communicating both teams are paying attention to each other.

With this structure defined, we now need to consider how to build dynamics into the model. In particular we must define the following:

\begin{itemize}
	\item Progression of time. We take our model to be a discrete iterative process. Each iteration marks the passage of a fixed time period. 

	\item Arrival of Projects. We model projects such that with each time step, a single project might arrive. The nature of the project which arrives we determine using a multivariate Bernoulli distribution.
	
	\item Completion of Projects. We arbitrarily decide that the duration of a project will be distributed exponentially. This is equivalent to saying that each project has an identical chance of completion following each iteration.
\end{itemize}


\subsection{The Small 3-node Model}
\label{sec:3nodemodel}
In this model, we consider there to be 3 teams, and 2 skill types. We label the teams as $A$, $B$ and $C$, and the skill types as $\alpha$ and $\beta$. We decide arbitrarily that teams $A$ and $C$ have skill $\alpha$, while teams $B$ and $C$ have skill $\beta$. This arrangement is illustrated in figure \ref{fig:diagram1}.

\begin{figure}[ht]
	\centering

	\includegraphics[]{ModelDiagram.png}
	\caption{We have 3 types of nodes: skill types ($\alpha$ and $\beta$), teams ($A$, $B$ and $C$), and incoming project alerts ($P_\alpha$ and $P_\beta$). If a team node is joined to a skill node by an edge, then the team possesses that skill. All of the teams have one way connections with the incoming project alerts nodes because the teams respective state do not effect incoming projects' state, but are effected by them.}
	\label{fig:diagram1}
\end{figure}

With the teams, skills and assignment of these defined, we specify the details of the model dynamics in the following three steps.

\begin{steps}
	
	\item \textbf{Arrival of projects}\\
	Earlier we stated that this process was based on a multivariate Bernoulli distribution. Specifically we use the 2-dimensional version, as we are working with 2 types of skills. We specify the vector of probabilities: $\mathbf{p} = (p_\alpha, p_\beta)$ such that an incoming project requires skill $\alpha$ with probability $p_\alpha$ and similarly for skill $\beta$.
	
	We create 2 `incoming project alert' nodes which we label as $P_\alpha$ and $P_\beta$. The state of these nodes is determined only by the previously mentioned probability distribution. Hence these nodes transition states independently of any other node. 
	
	\item \textbf{Assignment of projects}\\
	First are the 3 simple cases. If a project which requires skill $\alpha$ but not $\beta$ arrives, and team $A$ is idle, then the project is assigned to $A$, resulting in team $A$ turning on. Similarly teams $B$ and $C$ will turn on if a project arrives tailored to their abilities while they are not already active.	
	
	2 more cases exist: If a project suitable for team $A$ arrives while $A$ is busy and $C$ is idle, then $C$ will be assigned $A$'s task. The same will apply if $B$ is busy when such a project arrives. Finally, if a project requiring both skills arrives while $C$ is busy while $A$ and $B$ are both idle, then $A$ and $B$ will be assigned the project, resulting in both of them transitioning to a state of `on'.
	
	\item \textbf{Completion of projects}\\
	We already stated the time required to complete a project to be modelled by th exponential distribution. This was so we could use a simple Bernoulli process to determine when a project is completed. This means that the probability of completing a project is constant w.r.t. time. However, to make this process more realistic, we decide that the probability of completing a project will not be independent of active working connections.
	
	We define the parameters $k_A$, $k_B$ and $k_C$ to represent the effectiveness of each team. If $A$ is active, then it will complete its task with probability $k_A$ after each time-step, and so on. 
	
	However, when teams are working on similar tasks, then collaboration occurs. Specifically, if teams $A$ and $C$ are both active, since skill $\alpha$ is required for both projects, $C$ will assist $A$. However, as $C$'s project also involved skill $\beta$, $A$ will be unable to return the assistance. In this case, $A$ will finish its task after the next time-step with probability $k_A + k_B$, which for $C$ things are unchanged. 
	
	$C$ can only receive assistance when all teams are active, since together $A$ and $B$ account for all required skills. In this final case, $C$ will complete its task with probability $k_A+k_B+k_C$.
\end{steps}


Now we can put this all together to form the state by node transition probability matrix: $\mathbf{T}$, defined as:
\begin{equation}
\mathbf{T}_{ij}= P(z^j_{t+1}=1 | Z_t = i)
\end{equation}

where $Z$ refers to the entire network with $z^j$ standing for $A$, $B$, and $C$ (the team nodes) in addition to $P_\alpha$ and $P_\beta$, (the incoming project alert nodes) for $j=1,2, \ldots, 5$. $\mathbf{T}$ is the \textit{state by node} transition probability matrix, as previous described in section \ref{sec:conditional_independence} having 32 rows and 5 columns. We present this matrix in table \ref{mat:simple_system}.


\begin{table}[h!]
	\centering
	$
	\begin{array}{|l|ccccc}
		\hline
		\multicolumn{1}{|r|}{\text{State}} & \multicolumn{1}{c|}{A} & \multicolumn{1}{c|}{B} & \multicolumn{1}{c|}{C} & \multicolumn{1}{c|}{P_\alpha} & \multicolumn{1}{c|}{P_\beta} \\ \hline
		000 00                      & 0                      & 0                      & 0                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		100 00                      & 1-k_A                 & 0                      & 0                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		010 00                      & 0                      & 1-k_B                 & 0                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		110 00                      & 1-k_A                 & 1-k_B                 & 0                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		001 00                      & 0                      & 0                      & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		101 00                      & 1-k_A-k_C            & 0                      & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		011 00                      & 0                      & 1-k_B-k_C            & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		111 00                      & 1-k_A-k_C            & 1-k_B-k_C            & 1-k_A-k_B-k_C       & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		000 10                      & 1                      & 0                      & 0                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		100 10                      & 1-k_A                 & 0                      & 1                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		010 10                      & 1                      & 1-k_B                 & 0                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		110 10                      & 1-k_A                 & 1-k_B                 & 1                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		001 10                      & 1                      & 0                      & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		101 10                      & 1-k_A-k_C            & 0                      & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		011 10                      & 1                      & 1-k_B-k_C            & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		111 10                      & 1-k_A-k_C            & 1-k_B-k_C            & 1-k_A-k_B-k_C       & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		000 01                      & 0                      & 1                      & 0                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		100 01                      & 1-k_A                 & 1                      & 0                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		010 01                      & 0                      & 1-k_B                 & 1                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		110 01                      & 1-k_A                 & 1-k_B                 & 1                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		001 01                      & 0                      & 1                      & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		101 01                      & 1-k_A-k_C            & 1                      & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		011 01                      & 0                      & 1-k_B-k_C            & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		111 01                      & 1-k_A-k_C            & 1-k_B-k_C            & 1-k_A-k_B-k_C       & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		000 11                      & 0                      & 0                      & 1                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		100 11                      & 1-k_A                 & 0                      & 1                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		010 11                      & 0                      & 1-k_B                 & 1                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		110 11                      & 1-k_A                 & 1-k_B                 & 1                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		001 11                      & 1                      & 1                      & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		101 11                      & 1-k_A-k_C            & 0                      & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		011 11                      & 0                      & 1-k_B-k_C            & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		111 11                      & 1-k_A - k_C          & 1-k_B-k_C            & 1-k_A-k_B-k_C       & p_\alpha                      & p_\beta                      \\ \cline{1-1}
	\end{array}
	$
	\caption{Above is the Transition Probability Matrix for the small 3-node model. We represent each state of the system as a length 5 binary string, where the 1's and 0's refer to `on' and `off' respectively. We list nodes in the order: $A, B, C, P_\alpha, P_\beta$. Hence, 10010 means that nodes $A$ and $P_\alpha$ are active, while the rest are idle.}
	\label{mat:simple_system}
\end{table}



Finally, for this model to be interesting, we need to have some control over the parameters. For this, we think of $k_A$, $k_B$ and $k_C$ of being directly related to the funding invested in each team. Hence we assume $k_A+k_B+k_C = K$, where $K$ is a constant which refers to the total amount of funding at the organisations disposal. $k_i$'s refer to how we allocate that funding.

When solving for this model, we will employ two methods: IIT and a classical approach. For IIT, we will compute the value of $\Phi$, while for the classical approach, we instead will introduce the notion of costs, and from this compute the economic performance with respect to the parameters $k_A$, $k_B$ and $k_C$. 

\subsubsection{Classical Solution}
Currently in our model a project will definitely be completed, the question is how long it will take. Thus we don't have to worry about the cost of failed projects. Instead, we concern ourselves with the value of missed projects: those which arrive when there is no suitable team or combination of team available to be assigned to it. Define $W_A$, $W_B$ and $W_C$ to be the waste incurred when a project requiring skills $\alpha$, $\beta$ and both  is missed respectively.

When does this waste happen? Look back at table \ref{mat:model1}. Based on how we've define the allocation process, the only states at which waste can occur are: $10110$, $11110$, $01101$, $11101$, $10111$, $01111$ and $11111$. If the last two digits of the state is $10$, then a project requiring skill $\alpha$ is lost, resulting in waste of $W_A$. $01$ means that a project needing skill $\beta$ is lost, resulting in waste of $W_C$. The rest refer to a project needing both skills, for which the waste is $W_C$. In short, waste results from exactly 7 different states, and can be either $W_A$, $W_B$ or $W_C$.

So we know how much money we expect to waste for each state. Now the question is: how often do we expect to be at each state? We can take two approaches: either we can simulate the system and compute waste from the time series, or else we can compute the expected waste per iteration by finding the stationary distribution of the system. We take the latter approach.

When the values of $k_i \in (0,1)$, then the $32\times32$ state by state transition probability matrix $\mathbf{M}$ will have an eigenvalue of 1 with geometric multiplicity 1. Furthermore, $-1$ will not be an eigenvalue. Hence the left eigenvector with eigenvalue 1 will the be stationary distribution of the system, which precisely describes the long term behaviour of the system. 

Hence our cost function is:
\begin{equation}
\label{eq:simple_model_cost_function}
f(k_A, k_B, k_C) = \mathbf{q}(W_A, W_B, W_C) \cdot \mathbf{v}(k_A, k_B, k_C, p_\alpha, p_\beta)
\end{equation}

where $\mathbf{v}$ is the stationary distribution of the system, which depends on $k_A$, $k_B$, $k_C$, $p_\alpha$ and $p_\beta$ while $\mathbf{q}$ is a vector which contains the cost of each state hence depending on $W_A$, $W_B$ and $W_C$. In short, given the 5 constants: $p_\alpha$, $p_\beta$, $W_A$, $W_B$ and $W_C$, we can express cost as a function of $k_A$, $k_B$ and $k_C$. 

\subsubsection{IIT Comparison}

In this section we compare the results of IIT with the expected waste of the network. $\Phi$ depends on the matrix $\mathbf{M}$ and the initial state. However, we would prefer to have a function which is independent of state like our cost function. Thus, just as we computed cost in equation \ref{eq:simple_model_cost_function} by taking the inner project of the cost vector with the stationary distribution, we take a similar approach here.
Define $\mathbf{\Phi}$ the length $2^n$ vector containing the values of $\Phi$ at each state of the system. Using this, we compute:

\begin{equation}
\mathbb{E}[\Phi]:= \mathbf{\Phi}\cdot \mathbf{v}(k_A, k_B, k_C, p_\alpha, p_\beta)
\end{equation}

Using $\mathbb{E}[\Phi]$ instead of $\Phi$ given a particular state makes sense intuitively. Suppose $\Phi$ measured in some what the quality of the project allocation process at a particular step. Then its is possible that the reason it was a good step was because it will create opportunities in the future by taking on costs in the present. Thus we would be more interested in the average value of $\Phi$ if it were to have this meaning, which is what we hope.

Finally we compare $\mathbb{E}[\Phi]$ against expected waste. We arbitrarily choose $p_\alpha$ and $p_\beta$ to both be $0.5$, while we pick $W_A=0.3$, $W_B = 0.5$ and $W_C = 0.2$. Finally we set $K = k_A+k_B+k_C = 0.5$, and vary the parameters according to this constraint. We present our results in figure \ref{fig:simple_model_phi_cost_plot}.

\begin{figure}[!ht]
	\centering
	\includegraphics[scale = 0.5]{phicostplot.pdf}
	\caption{We present a scatter-plot of the values for $\mathbb{E}[\Phi]$ and expected waste, when we vary the parameters $k_A, k_B$ and $k_C$ subject to $k_A+k_B+k_B=1/2$.}
	\label{fig:simple_model_phi_cost_plot}
\end{figure}

What we find is there does seem to be a relation between the expected waste and $\mathbb{E}[\Phi]$. When we look at figure, we see what the points lie along a shape which resembles a quadratic function with respect to expected waste. This is ideal from the perspective that it leads us to believe that these values are not independent of each other. On the other hand, we can't express Expected Waste as a function of $\mathbb{E}[\Phi]$ since, the shape bends back on itself. i.e. if we pick the value of $\mathbb{E}[\Phi]$ which corresponding to the point of minimal waste, there are other points that have considerably more waste, yet with the same value of $\mathbb{E}[\Phi]$.

While we could adjust the parameters to see how this shape evolves, instead we question whether this model is suitable, or should be added to. We identify the following flaws in this setup:

\begin{enumerate}
	\item As things stand, the project allocation process assumes that all three worker nodes are connected to each other, and hence communicating at all times. More interesting results might be obtained if the connectivity was more sparse.
	
	\item The current definition of waste is the value of the projects which can't be done because the workers are busy. However, this rather measures missed opportunities due to the size of the organisation, as opposed to communication errors. We're more interested in measuring the direct consequences of miscommunication.

\end{enumerate}

Motivated by these observations, we need to include more worker nodes into the model so that we can have sparser connections, without the system becoming trivial. 

\subsection{The 5-node Model}

The general design of this model is the same as that in section \ref{sec:3nodemodel}. We begin by listing the extensions/adjustments:



We extend the previous model as follows: 
\begin{enumerate}


	\item Before there were 2 types of skills: $\alpha$ and $\beta$. We now include a third: $\gamma$.
	
	\item As implied in the section title, we increase the size of the organization from 3 to 5 nodes. The first 3 nodes: $A$, $B$ and $C$ possess the same skills as in section \ref{sec:3nodemodel}. The two additional nodes $D$ and $E$ possess the skills $\alpha, \gamma$ and $\beta, \gamma$ respectively. We illustrate this in figure \ref{fig:diagram2}.
	
	\item We change our definition of waste to focus on errors due to miscommunication, as opposed to merely projects which can't be attempted.
	
	\item We adjust the project allocation procedure to be dependent on the connectivity matrix.
\end{enumerate}

\begin{figure}[ht]
	\centering	
	\includegraphics[]{Model2Diagram.png}
	\caption{We have 3 types of nodes: skill types ($\alpha$, $\beta$, and $\gamma$), teams ($A$, $B$, $C$, $D$ and $E$), and incoming project alerts ($P_\alpha$, $P_\beta$ and $P_\gamma$). If a team node is joined to a skill node by an edge, then the team possesses that skill. The teams receive inputs from the incoming project alert nodes, but the dependence is strictly one directional.
		Certain teams are connected, indicating that they are actively communicating with each other so to distribute work efficiently. Note that in this figure, we have 2 disconnected clusters of teams. This will give rise to waste.}
	\label{fig:diagram2}
\end{figure}

The increased size of this model allows us more realistic scenarios in which waste occurs due to miscommunication. The main question is: will $\Phi$ have a more obvious relation to this form of waste. Now we must define in detail: how allocate incoming projects, and how to define waste.


In the previous model, we allocated projects from a global perspective. We knew for any given project was the the best arrangement would be, and then chose this to happen. Since all the teams involved were in communication, this made sense. However, what happens if teams are not all communicating?. For this model, we establish the following localised decision making policy to determine whether or not a team decides to take on a project. In decreasing order of importance, each team should aim to:


\begin{enumerate}
	\item Ensure that a project is allocated if it is possible to do so.
	\item Ensure that if a project is being worked on, that only on set of teams is doing so. In other words, ensure that there doesn't exist any duplication of labour.
	\item Minimize the amount of excess skills possessed by the team/teams assigned to the project.
\end{enumerate}

When applying this policy, each individual team acts as if any team which it is not paying attention to does not exist. This means that if a team is disconnected from all other teams (meaning it does not know what any of the others are doing), then it will always take on an incoming project which it can do. This will happen independently of whether another team is also taking on the project, because the isolated team does not know this. 

Similarly, if a pair of strongly connected teams see a project which they are overqualified for, and can both see another pair of teams which can complete the project with less excess skills, then the first team will ignore the project. However, while the first pair of teams observed that the second pair were both idle, it couldn't observe whether the 2nd two were strongly connected. If the second team are not strongly connected, then the project will be missed entirely, due to lack of communication. We illustrate this phenomenon in figure \ref{fig:waste1demo1}.

\begin{figure}[ht]
	\centering	
	\includegraphics[scale=0.13]{Waste1demo1.png}
	\caption{In this example we have an incoming project which requires both skills $\alpha$ and $\beta$. Teams $D$ and $E$ would possess these skills if they collaborate which they can do as they are connected, even though they have 2 $\gamma$ skills in excess. However, both $D$ and $E$ can see that the collaboration of $A$ and $B$ can complete the project more efficiently. Thus $D$ and $E$ do not take on the project as they do not know that $A$ and $B$ are not collaborating, and thus won't take the project either. Due to this lack of communication, even though there were plenty of ways that the project might have been done, the project is wasted.}
	\label{fig:waste1demo1}
\end{figure}

Ultimately, this procedure precisely determines a $2^8 \times 8$ transition probability matrix, which for obvious reasons is not presented here. Next we turn our attention exclusively to the classical solution, which is where we will redefine the notion of waste.

\subsubsection{Classical Solution}

In this section, we compute the expected waste which will result from a particular connectivity matrix. However, we first must lay out what we mean by `waste'. In the context of this model, there are 3 different types of inefficiencies that can occur in the distribution of projects:

\begin{enumerate}
	\item \textbf{Unnecessary dismissal of project}\\
	If there exists a minimal subset of idle teams which possess the required skills to take on an incoming project, and yet the project is not assigned to anyone, then this is wasteful of the project itself.
	
	\item \textbf{Duplication of work}\\
	If there exists multiple minimal subsets of idle teams which possess the required skills to take on an incoming project, and multiple of these groups of teams are assigned to the project, then this is an unnecessary duplication of labour.
	
	\item \textbf{Excess Skills}
	If there exists an idle team which possesses skills beyond the requirements of an incoming project, and this team is assigned to the project, then this wasteful of these excess skills.
\end{enumerate}

Of these 3 sources of waste, we arbitrarily view type 1 to be 10 times worse than type 2 which is again 10 times worse than type 3. However, what is the numerical value of these costs?

For this we take a simplistic approach. We assign the values $W_\alpha, W_\beta$ and $W_\gamma$ to be the values of each skill type. When counting type 1 waste (a doable project is ignored), we add the values of all skills required and scale by 10. Hence, a project requiring all 3 skills would have a cost of $10(W_\alpha+W_\beta+W_\gamma)$.

With type 2 waste (a project being worked on by more than one team), we count the skills possessed by all teams which are assigned to the project. Then we determine how many times the project could be completed form this pool of skills. We assign the cost in this case to be the sum of the costs applying to the skills required by the project, multiplied by the number of times we find this 

When counting type 3 waste, we count how many excess skills are possessed by the assigned teams, and then add up the values of these skills. Finally we scale this value by $1/10$.

\begin{remark}
	In section \ref{sec:3nodemodel}, we assigned a distinct cost to each type of project. Here we simplify that approach as otherwise we would be left with 8 parameters.
\end{remark}

By applying this definition of waste to all states of the system, we construct the vector function $\mathbf{q}(W_\alpha, W_\beta, W_\gamma)$ so that each value in the vector refers to the waste given the corresponding state and parameters. From this, we construct our function:

\begin{equation}
\label{eq:cost_function}
Cost(k_A, k_B, k_C) = \mathbf{q}(W_A, W_B, W_C) \cdot \mathbf{v}(k_A, k_B, k_C,k_E, k_F, p_\alpha, p_\beta, p_\gamma)
\end{equation}

where $\mathbf{v}$ is the same vector function defined in section \ref{sec:3nodemodel} appropriately adjusted for the additional nodes and skill type.

\subsubsection{IIT Comparison}

When comparing $\mathbb{E}[Cost]$ to $\mathbb{E}[\Phi]$, we first need to decide the context in which we are doing do. The approach we took was to keep the parameters $k_i, p_i$ and $W_i$ all fixed, and instead to vary the connectivity matrix. We justify this choice on grounds that: in an existing organisation, these values would be difficult to change. What could change more easily is who talks to whom. Thus we view that choosing the connectivity matrix to be our variable is more relevant to the problem.

However, we still need to be more specific as there are exactly $2^{64}$ $8\times 8$ connectivity matrices. Thus we restrict our attention to connectivity matrices which have exactly 10 directed edges. There are still a vast number of such matrices, roughly 180,000. Therefore, due to computational time restrictions, we randomly select 200 of these matrices and plot the results in figure \ref{fig:model_costvsphi}.

\begin{figure}[h!]
	\centering
	\includegraphics[scale = 0.5]{maxvscost_random.pdf}
	\caption{We plot $\mathbb{E}[Cost]$ against $\mathbb{E}[\Phi]$ for 200 randomly selected connectivity matrices with precisely 10 directed edges.}
	\label{fig:model_costvsphi}
\end{figure}

Having plotted $\mathbb{E}[Cost]$ as a function of $\mathbb{E}[\Phi]$, we see a linear correlation. Even more importantly though, we observe that maximising $\mathbb{E}[\Phi]$ also results in minimizing $\mathbb{E}[Cost]$. This looks ideal, but we must remind ourselves that a sample of size 200 out of 180,000 is by no means conclusive. Unfortunately, the time required to compute each data point prevents us from repeating this experiment. 


Therefore, we set up a smaller problem which can be solved exhaustively. Instead of starting with an empty connectivity matrix, and adding 10 directed edges to it, now we start with a developed matrix. Specifically, we consider the matrix which applies to figure \ref{fig:diagram2}, in that the nodes $A$, $B$ and $C$ are completely connected to each other, which being entirely disconnected from $D$ and $E$. This matrix is a $5\times 5$ block diagonal matrix consisting of a $3 \times 3$ and $2 \times 2$ matrix of 1's along the diagonal. Next we introduce an addition 4 directed edges with which we want to join these 2 clusters.

Intuitively, this problem can be though of as forcing two distinct department to talk to each other, and searching for the best way that this can be accomplished. In this setup, there are only 495 different connectivity matrices, and hence an exhaustive search is achievable.

We plot $\mathbb{E}[Cost]$ against $\mathbb{E}[\Phi]$ for this case, showing the result in figure \ref{fig:maxvscost_small}.

\begin{figure}
	\centering
	\includegraphics[scale=0.5]{maxvscost_small.pdf}
	\caption{We plot  $\mathbb{E}[Cost]$ against $\mathbb{E}[\Phi]$ for connectivity matrices where we add 4 directed edges to the network shown in figure \ref{fig:diagram2}}
	\label{fig:maxvscost_small}
\end{figure}

Now I discuss the content of the figure which I have not yet generated as I don't have all of the data yet.

I will also show what the best network in these setup is

\section{IIT revisited}
In section \ref{sec:iit}, we presented the definitions of Integrated Information Theory as defined by Oizumi et al \cite{oizumi2014phenomenology}, while using a modification of the notation presented by \cite{krohn2016computing}. In this section, we will critique the mathematical implementation of IIT, and consider whether it is indeed applicable to the problem of consideration: communication within an organisation.

\subsection{Distance Between Repertoires}
In this section, we examine the process of computing distances between effect repertoires. In particular, let $Z$ be a system of mechanisms, and $W$ a particular mechanism. Consider the computation of: $\varphi^{M,N}_{cause}(W_t = X, Z)$. This value is equal to the distance between two repertoires: $p_e(Z_{t+1}|W_t = X)$ and $p_e(N_{t+1}|N_t = X)p_e(Z\setminus N_{t+1}|W \setminus M _t = X)$.

We can break down the first of these repertoires using conditional independence:

\begin{equation}
\label{eq:dist_argument_1}
p_e(Z_{t+1}|W_t = X)=\prod \limits_{i=1}^{n} p(z^i_{t+1}|W_t=X)
\end{equation}

Denote by $\mathbf{x}(Z_{t+1}|W_t = X)$ the vector function such that:
$x_i(Z_{t+1}|W_t = X) = p(z^i_{t+1}|W_t=X)$ for $i = 1, 2, \ldots, n$.

Next we break down the second repertoire in a similar fashion:

\begin{align}
\label{eq:dist_argument_2}
p_e(N_{t+1}|M_t = X)&=\prod \limits_{i\in N} p(z^i_{t+1}|M_t=X)\\
p_e(Z\setminus N_{t+1}|W \setminus M_t = X)&=\prod \limits_{i\in Z \setminus N} p(z^i_{t+1}|Z \setminus M_t=X)
\end{align}

Denote by $\mathbf{y}(Z_{t+1}|W_t = X, M,N)$ the vector function such that $y_i(Z_{t+1}|W_t = X, M,N) = p(z^i_{t+1}|M_t=X)$ if $i \in N$ and otherwise is $p(z^i_{t+1}|Z \setminus M_t=X)$. For convenience we now refer to these vectors merely as $\mathbf{x}$ and $\mathbf{y}$.

When computing a repertoire in practice, one first compute the generating vector, of which $\mathbf{x}$ and $\mathbf{y}$ are examples. If the system has $n$ nodes, then these vectors are of length $n$. Next we consider all possible states of the system. We compute the probabilities of each of these states occurring by multiplying values of $x_i$ and $1-x_i$ together. For example, if we wanted to compute the probability that the future state of a 3 node mechanism would be $101$, we would obtain this by computing $x_1 (1-x_2)x_3$.

This procedure is in essence a function: $R: [0,1]^n \rightarrow [0,1]^{2^n}$ which converts the generating vectors into the actual effect repertoires. The last step in computing  $\varphi^{M,N}_{cause}(W_t = X, Z)$ is to use the earth mover's distance to find $\text{EMD}(R(\mathbf{x}), R(\mathbf{y}))$.

Is this entire process really necessary? First we compute $\mathbf{x}$ and $\mathbf{y}$, next convert to $R(\mathbf{x})$ and $R(\mathbf{y})$, and finally compute the distances between these. The step where $R$ is applied scales with $O(2^n)$, and the EMD scales with the size of the vectors its comparing, which is in this case $O(n^3 2^{3n})$. What if instead we used a different distance measurement, and used it on $\mathbf{x}$ and $\mathbf{y}$ directly instead of bothering to apply $R$?

\begin{prop}
	\label{prop:alternative}
	Let $p_1$ and $p_2$ be multivariate Bernoulli distributions equipped with vectors $\mathbf{x}$ and $\mathbf{y}$ such that $p_1(z^i=1) = x_i$ and $p_2(z^i = 1) = y_i$ for $y = 1, 2, \ldots, n$. We further assume that $p_k(z^i, z^j = 1,1) = p_k(z^i = 1) p_k(z^j=1)$ for all $i,j,k$. Then:
	\begin{equation}
	\text{EMD}(p_1, p_2) = ||\mathbf{x} - \mathbf{y}||_1
	\end{equation}
	where the earth mover's distance operates by using the Hamming distance to measure distance between states.
	
	
\end{prop}

\begin{remark}
	For more information on multivariate Bernoulli distributions, see Teugels \cite{teugels1990some}.
\end{remark}

We have verified proposition \ref{prop:alternative} for multivariate distribution with up to 8 variables numerically, and have confirmed the statement to be true with 2 and 3 variable distributions analytically. However, a full proof has not yet been found. 

Regardless of this, by measuring the $||\cdot||_1$ distance between $\mathbf{x} $ and $\mathbf{y}$, we use a process the cost of which scales with $O(n)$. In short, instead of computing distributions from generating vectors, and then finding the distance between these distributions, we simply find the distance between the generating vectors.


\subsection{Computation of Effect Repertoires.}

In this section, we will examine exactly how the effect repertoire $p_e$ is defined, and how it differs from true conditional probability. Recall the definition of the effect repertoire:

\begin{definition}
Let $Z$ be a mechanism with $W\subset Z$, and suppose that the current state of $W$ is known, that is: $W_t = X$. Then the \textit{effect repertoire} of the state $W_t = X$ is the conditional probability distribution for the future states of $Z$ given our current knowledge.
\end{definition}

Based on the description, we should expect $p_e(Z_t|W_t = X)$ the repertoire to be exactly the same as $p(Z_t|W_t = X)$, the probability. 

In section \ref{sec:conditional_independence} we state the assumption of conditional independence with respect to the system. With this states, we should now expect $p_e$ to be the same as $p$ given that conditional independence holds.

...paused here. I had a thought that might explain this. Emailed the makers to IIT3 to check...


\subsection{Alternative $\Phi$'s}
Discuss the work of \cite{tegmark2016improved} and mention other options of $\Phi$. Explain why $IIT3$ was used.

\section{Conclusions}

1. IIT is correlated with a tangible cost of waste

2. IIT has the potential to be sped up considerably by removing redundant steps

3. IIT currently is computationally intractable for large systems

4. IIT is justified philosophically, hence we are restricted to what the philosophers consider the most up to date version.

conclude that until progress has been made on 2., there is no hope for practical application of IIT
