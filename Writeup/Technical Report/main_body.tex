 


\section{Introduction}
Within any organisation, no matter what the type, communication must be present. If members of a company do not communicate, then there is no way for a worker to know what they should be doing, or if what they are doing is actually important to the company. At the same time, if all members of an organisation are talking to each other there this may damage productivity, as well as giving rise to redundant communication. We investigate models of organisational structures that maximise productivity and flexibility.

This problem is an specific example from the wider context of social network theory. Zhang and van der Schaar \cite{zhang2015reputational} looked at a similar problem,  creating a model where each agent in their network decides which connections are of value to it based on limited information of their value, and how this affects the welfare of both the individual agent, and the network as a whole. This approach would be applicable to the problem, when thinking of the value of a connection between agents, as the importance of them communicating.

However, we approach the problem from a very different angle. Specifically we identify the brain as a biological example of effective communication between individual neurons. If we think of the neurons within the brain passing information between each other as being equivalent to individual workers/teams within an organisation talking to each other, then this becomes a similar problem in theory. Motivated by this, we attempt to apply Integrated Information theory to the problem.

What is integrated information theory? Originally present in 2004 by Tononi \cite{tononi2004information}, this is the most recent attempt to rigorously define consciousness. Since its first appearance it presents the function $\Phi$ which computes the integrated information of a system of mechanism. The main claim of integrated information theory is that consciousness and integrated information are the same thing, and hence computing $\Phi$ is computing consciousness. The arguments used to justify this claim are primarily philosophical in nature, and thus will not be discussed in this report. 

Since 2004, IIT has received multiple updates and adjustments \cite{tononi2011integrated,balduzzi2008integrated,tononi2016consciousness} each of which resolve issues found in the previous definition. Currently the most up to date version of IIT is version 3.0 \cite{oizumi2014phenomenology}, and hence we will primarily focus on that version in this report.

While IIT has developed from version 1.0 to 3.0 by its inventor Giulio Tononi, at the same time other authors have developed the theory in different directions. For example Barrett and Smith \cite{barrett2011practical} designed an alternative definition which was applicable to time series data. This $\Phi_e$ as they called it, has similar behaviour to the original $\Phi$ in settings where both could be applied, but can be used in more contexts. A list of such alternative definitions was compiled by Tegmark \cite{tegmark2016improved} for the purpose of considering their relative mathematical merits.

Our focus is to investigate whether the computation of $\Phi$ for a network model of an organisation might give any insight into the efficiency of communication within the organisation. As $\Phi$ is expensive to compute (as will be discussed in greater detail in section \ref{sec:cost}), we restrict our attention to a small scale toy model which we derive for the purpose of capturing the effects of poor communication within an organisation. Despite the greater cost of using IIT 3.0 than 2.0, we choose to use the most up-to-date version, as we wish to avoid the flaws which have previously been identified in older editions.

\section{Integrated Information Theory}
\label{sec:iit}

In this section, we present an overview of Integrated Information Theory 3.0 as presented by Oizumi et all \cite{oizumi2014phenomenology}, while adjusting the notation in order to make it mathematically consistent.
	
\subsection{Definitions and Notation}

Integrated Information Theory proposes a function called $\Phi$ which is defined based on the notions of \textit{mechanisms} and \textit{systems} \cite{oizumi2014phenomenology}. However, these notions are not given a rigorous mathematical definition. Hence we introduce our own mathematical definition with the aim of staying loyal to the notation in used in \cite{krohn2016computing} so far as is possible.

Let $Z_t$ be a discrete time multivariate stochastic process which takes values from $[0,1]^n$.  The stochastic process $Z_t$ is assumed to be a markov process, and it thus equipped with a transition probability matrix $\mathbf{M}$. We relate this stochastic process to a graph containing $n$ nodes. Each node refers to one of the individual random variables and has two \textit{states}: \textit{off}  and \textit{on}. Within this report, we abuse notation by allowing $Z$ to refer to the multivariate random process, and the set of all nodes in the graph simultaneously. 

\begin{definition}
	The \textit{state} of a node simply refers to whether that node is \textit{on} or \textit{off}. We denote \textit{on} with a 1, and \textit{off} with a 0.
\end{definition}

\begin{definition}
	\label{def:element}
	An \textit{elementary mechanism} doubly refers to a node in the graph $Z$, as well as a Bernoulli random variable. It has two states: \textit{off}, which corresponds to when the random variable takes the value 0, and \textit{on}, which corresponds to when the random variable takes the value 1. We denote an \textit{elementary mechanism} by $z^i$, and refer to its state at time $t$ by $z^i_t$.
\end{definition}
	
\begin{definition}
	\label{def:mech}
	A $m$-th order \textit{mechanism} is a set of $m$ distinct \textit{elementary mechanisms}. As such, it also has the double meaning referring both to a subset of nodes in the graph $Z$, as well as the corresponding random variables. The state of a mechanism is given by the states of all \textit{elementary mechanisms} within it. Hence a $m$th order \textit{mechanism} has $2^m$ distinct states. We denote the state of $W$ at time $t$ as $W_t$.
\end{definition}

\begin{definition}
	\label{def:system}
	A \textit{system} is the combination of a directed graph $Z$ with $n$ nodes, and the stochastic process $Z_t$. Therefore, all \textit{mechanisms} are contained within the \textit{system}.
\end{definition}
	
The graph $Z$ is directed and has edges, so what do these mean in the context of the stochastic process? We join $z^i$ to $z^j$ with a directed edge if the $z^i_{t+1}$ depends in some way on $z^j_t$. 

\begin{definition}
	\label{def:distributions}
	Let $A$ and $B$ be $i$-th and $j$-th order \textit{mechanisms}, $\mathbf{s} \in \mathbb{S}(A)$ and $\mathbf{r} \in \mathbb{S}(B)$. Then we define the
	\begin{enumerate}
		\item \textit{Forward Distribution}, $p(A_{t+1}|B_t = r)$ to be the probability distribution that each state of $A$ occurs. This distribution contains $2^i$ values.
		\item \textit{Backward Distribution}, $p(A_{t}=\mathbf{s}|\mathbf{B}_{t-1})$ to be the probability of each previous state of $B$ leading to $A_t = \mathbf{s}$. This distribution contains $2^j$ values.
	\end{enumerate}
\end{definition}



\begin{definition}
	{IIT \cite{oizumi2014phenomenology} uses the names of \textit{effect repertoire} and \textit{cause repertoire} for specific distributions. Denoted as $p_e$ and $p_c$, these are similar to the forward and backward distributions, but rely on assumption \ref{asmp:cond_independence} which we will describe later. }
\end{definition}


\begin{remark}
	In this document, we use Krohn and Ostwalds  \cite{krohn2016computing} notation: $W_{t-1}, W_t, W_{t+1}$ to denote the past, present, and future states of a \textit{mechanism}. In \cite{oizumi2014phenomenology} however, these are denoted by $W^p, W^c$ and $W^f$ respectively.
\end{remark}

\begin{tabularx}{\textwidth}{ll X}
	Term & Usual Notation & Notes \\
	\hline
	\endfirsthead
	\hline
	\endhead
	\endfoot
	\hline
	\caption{Key Definitions and Notation} 
			%\addcontentsline{lot}{table}{\numberline{}Common abbreviations} % For use with fancy header package. 
	\label{tab:defs}
	\endlastfoot
	\textit{System} & $Z$ & A system is a set of \textit{elementary mechanisms}. We usually take the size to be $n$. For details see \ref{def:system}.\\
		\hline
	\textit{Mechanism} & $W$ & A $m$-order \textit{mechanism} is a size $m$  subset of a system $Z$. We usually take the size to be $m$. For details, see Definition \ref{def:mech}. \\
		\hline
	\textit{Elementary Mechanism} & $w^i$ & An \textit{elementary mechanism} consists of a single node, random variable pair. For details see \ref{def:element}.\\
		\hline
	\textit{Null Mechanism} & $\emptyset$ & The \textit{null mechanism} exists for the purpose of saying that nothing is known.\\
		\hline
	\textit{State Set} & $\mathbb{S}(W)$ & A $m$-th order \textit{mechanisms} \textit{state set} is the set of all possible \textit{states} of that \textit{mechanism}. \\
		\hline
	\textit{State} & $\mathbf{s}$ & We usually write the state of a \textit{mechanism} as $\mathbf{s}$.\\
		\hline
	Power Set & $\mathbb{P}(W)$ & The set of all subsets of a \textit{mechanism}.\\
		\hline
	Forward Distribution & $p(W_{t+1}|V_t=\mathbf{s})$ &The distribution of future states of $W$ given present knowledge of $V$. See Definition \ref{def:distributions}. \\
		\hline
	Backward Distribution & $p(W_{t}=\mathbf{s}|V_{t-1})$ & The distribution of past states of $V$ given present knowledge of $W$. See Definition \ref{def:distributions}.\\
\end{tabularx}









\subsection{Computation of Repertoires}
\label{sec:cost}
In this section, we construct each of the previously defined repertoires from $\mathbf{M}$, the transition probability matrix. For later use, we define the product of probability distributions.

%{First however, we need to introduce both the \textit{perturb function}, and the assumption of conditional independence, as all future definitions rely on these.

%\begin{definition}
%	{Let $S$ be a set such that $|S| = n$, and its elements are indexed by $s_1, s_2, \ldots, s_n$. Further let $f$ be a function which operates on the elements of $S$. Then we write the perturbation function as:
%	\[per(f(a, S), S) = \left(\begin{array}{cccc}f(a,s_1)&f(a,s_2)&\ldots&f(a,s_n) \end{array}\right)^T\]
%	That is, the perturbation function returns a vector where each of its entries corresponds to the $f$ taking a different input from $S$.}
%\end{definition} 

\begin{definition}
	Let $A, B \subset Z$ such that $A$ and $B$ are disjoint. Then we define the \textit{distribution product} of $A$ and $B$ by:
	\[p(A_{t+1}|Z_t)p(B_{t+1}|Z_t):=p(A_{t+1} \cup B_{t+1}|Z_t).\]
	In other words the product of the distributions is the distribution for the union of the sets $A$ and $B$.
\end{definition} 

\subsubsection{Conditional Independence}
\label{sec:conditional_independence}
In order to simplify all computations, IIT \cite{oizumi2014phenomenology} assumes the following theorem to hold.

\begin{assumption}
	\label{asmp:cond_independence}
	Let $Z$ be a \textit{system}. Then it holds that:
	\begin{equation}
	\label{eq:cond_independence}
	p(Z_{t+1}|Z_t = \mathbf{s}) = \prod \limits_{i=1}^{n} p(z^i_{t+1}|Z_t=\mathbf{s})
	\end{equation}
	
	where we have reduced the probability distribution for future states of $Z$ to the products of the distributions for each of its \textit{elementary mechanisms}. 
\end{assumption}

Theorem \ref{thm:cond_independence} motivates the following definition.

\begin{definition}
	\label{thm:bijection}
	Let $p(Z_{t+1}|Z_t = X)$ be a probability distribution. We define the row vector $\mathbf{q}(Z_{t+1}|Z_t = X)$ such that $q_i = p(z^i_{t+1}=1|Z_t=X), \quad \forall i \in 1, 2, \ldots, n$. We call $\mathbf{q}$ the \textit{distribution generator}.
\end{definition}

Now we present following key theorem which reduces the storage space required for future computations:

\begin{theorem}
	Let $A$ be the set of distributions for the system $Z$, and $B$ be the set of \textit{distribution generators} for the same system. Then there exists a bijection between between $A$ and $B$.
\end{theorem}

\begin{proof}
	We prove this bijection by construction the function which converts a distribution into its \textit{generator}, and its inverse.
	
	Let $p$ be a probability distribution of length $2^n$ that applies to the system $Z$, such that $p_i$ is the probability of $i \in \mathbb{S}(Z)$ occurring. We order the \textit{states} of $\mathbb{S}(Z)$ in order to write $p$ as a vector, which we now write as $\mathbf{p}$. 
	
	Next we construct the $2^n \times n$ state matrix $\mathbf{S}$. Each row of this matrix is a state of the \textit{system}, which in turn is a row vector. To map from $\mathbf{p}$ to its generator $\mathbf{q}$, we simply write: $\mathbf{q} = \mathbf{p} \mathbf{S}$. We demonstrate this transformation in equation \ref{eq:matrix_tranform_demo}. Naturally, $\mathbf{q}$ is dependent on the ordering of states.
	
	To go back, we write:
	
	\begin{equation}
	\label{eq:map_inv}
	p_i := \prod \limits_{j=1}^{n} q_j^{S_{ij}} (1-q_j)^{1-S_{ij}}\quad \forall i \in \mathbb{S}(Z)
	\end{equation}
	
	where  $S_{ij}$  indexes the state matrix and specifically says whether the $j$th node in the $i$ state is \textit{on} or \textit{off}. Hence we can compute $\mathbf{p}$ from $\mathbf{q}$, and go back. Thus this is a bijection.
\end{proof}

Theorem \ref{thm:bijection} enables us to condense $\mathbf{M}$ by converting each of its rows into the corresponding \textit{distribution generator}. We define the condensed matrix:

\begin{equation}
\label{def:generators}
\mathbf{T}_{i} := \mathbf{q}(Z_{t+1} = j| Z_t = i) , \quad \forall i \in \mathbb{S}(Z).
\end{equation}

We demonstrate transforming the transition probability matrix into the \textit{condensed matrix} in equation \ref{eq:matrix_tranform_demo}. In practice this is done by multiplying $\mathbf{M}$ to the $2^n \times n$ matrix whose rows are the elements of $\mathbb{S}(Z)$ appearing in chosen ordering:



\begin{equation}
\label{eq:matrix_tranform_demo}
\left( \begin{array}{cccc} 0&0&0.25&0.75\\
							0.35&0.15&0.35&0.15\\
							0.1&0&0.9&0\\
							0&0.6&0&0.4
							\end{array} \right) 							
\left(\begin{array}{cc}0&0\\
1&0\\
0&1\\
1&1 \end{array} \right)
\rightarrow \left( \begin{array}{cc}.75&1\\
											.3&.5\\
											0&.9\\
											1&.4 \end{array} \right).
\end{equation}

\begin{remark}
	In IIT 3.0 \cite{oizumi2014phenomenology}, the \textit{condensed matrix} $\mathbf{T}$ is incorrectly referred to a transition probability matrix. This name is incorrect as $\mathbf{T}$ is not a stochastic matrix. Hence we rename it for the purpose of mathematical consistency.
\end{remark}

\subsubsection{Effect repertoire}

Let $Z$ a \textit{system} and $W$ a $m$-th order mechanism, and suppose that the state of $W \subset Z$ is known, $W_t = \mathbf{s}$. Then the  \textit{effect repertoire} is defined by IIT \cite{oizumi2014phenomenology} to have the property of factorisation, that is:

\begin{equation}
\label{def:controversial}
p_e(Z_{t+1}|W_t = \mathbf{s}) = \prod \limits_{i= 1}^n p(z^i_{t+1}|W_t = \mathbf{s}).
\end{equation}

It is important to note that this factorisation does not follow generally from equation \ref{eq:cond_independence}, as it is much stronger. It was only assumed that future state of each node was conditionally independent with respect to the current states of the entire system, as opposed to with respect to all possible subsets of this system as well.

This is justified by Oizumi et al \cite{oizumi2014phenomenology} in their supplementary methods document on the grounds that they are interested in how $W_t=X$ affects each $z^i_{t+1}$ individually and thus factorise as above in order to remove correlations.


Finally, let $W$ be a $m$-th order \textit{mechanism} of the \textit{system} $Z$, the current state of which is known, and let $z^{i_0}$ be a particular node in $Z$. The mathematical definition \cite{krohn2016computing} of $p_e$ is
\begin{equation}
\label{def:effect_repertoire}
p_e(z_{t+1}^{i_0}|W_t = \mathbf{s}) = 2^{-|n-m|}\sum \limits_{\mathbf{r} \in \mathbb{S}(Z\setminus W)} p(z_{t+1}^{i_0}|W_t = X, (Z\setminus W)_t = \mathbf{r}).
\end{equation}

This is equivalent to averaging over all rows of the TPM which corresponds to states of $Z_t$ such that $ W_t = \mathbf{s} $.


\subsubsection{Cause repertoire}

Just as the effect repertoire is broken into a smaller problem in equation \ref{def:controversial}, there exists an equivalent simplification for computing the cause repertoire. Let the state of the $m$-order \textit{mechanism} $W \subset Z$ be known, and $V$ be another $k$-th order \textit{mechanism}. Then the mathematical definition \cite{krohn2016computing} of $p_c$ is

\begin{equation}
\label{def:cause_rep1}
p_c(V_{t-1} | W_t=\mathbf{s}) = \prod \limits_{i = 1}^{m} p_c(V_{t-1}|w^i_{t} = s_i).
\end{equation}

We define $p_c$ given knowledge of a single \textit{elementary mechanism}

\begin{equation}
\label{def:cause_rep2}
p_c(V_{t-1}| w_t = x) = \frac{\sum \limits_{\mathbf{r} \in \mathbb{S}(Z\setminus V)} p_e(w_t = x| V_{t-1}, (Z \setminus V)_t = \mathbf{r})}{p(w_t = x)}.
\end{equation}

In short, we add up the probabilities of each individual previous state that results in our current information ($w_t = x)$, and then scale by the overall probability that we observe $w_t = x$ in the first place. Note that equation \ref{def:cause_rep2} features the effect repertoire $p_e$ on the right hand side, not $p_c$.

\begin{remark}
	Equation \ref{def:cause_rep1} does not require additional assumption, because it is a consequence from equation \ref{def:controversial}.
\end{remark}



\subsection{The Earth Mover's Distance }
In the context of this document, we calculate the distance between two probability distributions $p1$ and $p1$ using $D(p1,p2)$, where $D$ is referring to the Earth Mover's Distance (EMD) \cite{rubner1998metric}.

To use this distance, we require the existence of another metric which measures the distance between any pair of states. For this we use the Hamming distance (see \cite{hill1986first} for more details) which is the number of individual bytes that disagree when comparing two states. (i.e. the hamming distance between 001 and 101 is 1, as the have 1 disagreement in the first digit)

In simple terms, if we think of each distribution as piles of dirt on top of each given state. The earth mover's distance is the product of how much dirt needs to moved by how far this dirt needs to go. 

\begin{description}
	\item[EMD] Let $S$ be a set of $n$ states, $s_i, s_j \in S$, $\mathbf{D} = \left[ D_{ij}\right]$ where $D_{ij}$ is the distance between $s_i$ and $s_j$, $P$ and $Q$ be two probability distributions over $S$ such that $P(X = s_i) = p_i$ and $Q(X=s_j) = q_j$, $\forall s_i, s_j \in S$. 
	
	Calculate the $n\times n$ matrix $\mathbf{F}$ which solves the following optimization problem:
	
	\begin{align}
	\label{eq:EMD1}
	\min \limits_{\mathbf{F}}\sum \limits_{i,j=1}^n &F_{ij} D_{ij}\quad \text{subject to}\\
	&F_{ij}\geq 0,\quad \forall 1 \leq i,j \leq n\\
	\sum \limits_{j=1}^n &F_{ij} = p_i,\quad 1 \leq i \leq n\\
	\sum \limits_{i=1}^n &F_{ij} = q_j,\quad 1 \leq j \leq n
	\end{align}
	
	Finally, we say that the distance between $p$ and $q$ is: 
	
	\begin{equation}
	\label{def:EMD}
	\text{EMD}(P, Q) = \sum \limits_{i,j=1}^{n} F_{ij} D_{ij}
	\end{equation}
\end{description}

From now on, we'll use the notation $D(P,Q)$ to denote the earth mover's distance.

\subsection{Calculations for Mechanisms}\label{sec:little_phi}
There are 3 functions which operate over mechanisms: cei, $\varphi^{\text{MIP}}$ and $\varphi^{\text{Max}}$. When applying these functions to a \textit{mechanism} $W$ within the system \textit{system} $Z$, they treat nodes differently depending on whether the nodes are found within the \textit{mechanism} itself, the \textit{consideration set} but not the \textit{mechanism}, or the \textit{system} but not the \textit{consideration set}.

We have not yet defined the \textit{consideration set}, and will not do so rigorously until section \ref{sec:systems}, as they are not important until then. For now, we merely define a consideration set $Y$ as a subset of the \textit{system} $Z$ such that $W \subset Y$, where $W$ is the $m$-th order mechanism. Figure \ref{fig:IIT_illustration1} illustrates this.

\begin{figure}[ht]
	\centering
	
	\includegraphics[scale = 0.12]{IITexplanationdiagram1.png}
	\caption{In this illustration, we identify the mechanism $CD$ by circling it in red. The \textit{consideration set} is similarly circled in green. Finally, all remaining nodes of the system which lie outside of the \textit{consideration set} are external inputs/outputs.}
	\label{fig:IIT_illustration1}
\end{figure}

When we compute cei, $\varphi^{\text{MIP}}$ or $\varphi^{\text{Max}}$, we are computing the effect of knowing the state of the \textit{mechanism}, $W_t = \mathbf{s}$. However, we do not know the state of the nodes in $Y\setminus W$, and we thus assume they could be \textit{on} or \textit{off} with equal probability. Finally all nodes in $Z \setminus Y$ are considered as background conditions. These calculations require that the past and present states of such nodes are known. 

In summary, cei, $\varphi^{\text{MIP}}$ and $\varphi^{\text{Max}}$ measure an effect that knowing the state of $W$ has on the \textit{consideration set}, given the background conditions of external inputs/outputs.

\subsubsection{Cause-Effect Information}
\label{sec:cei}
The \textit{cause-effect information} (cei) is a measurement of the significance of a piece of information. It is calculated in two parts. First we have the \textit{cause information} (ci), which measures how the past can be constrained given knowledge of the present. 

Let $W$ and $V$ be $m$-th and $k$-th order \textit{mechanisms} respectively such that $W,V \subset Y$, the \textit{consideration set}. Then \textit{cause information} is defined \cite{oizumi2014phenomenology} by:

\begin{equation}
\label{def:ci}
\text{ci}(W_{t} = X, V) = D\left(p_c(V_{t-1}|W_{t} = X),p_c(V_{t-1}|\emptyset)\right)
\end{equation}

What we do is compare using the earth mover's distance the probability distribution of future states of the  $V $ given knowledge of the present, to the distribution of future states given no knowledge of the present. The bigger this difference is, the more information is generated. 

Second the \textit{effect information} (ei) measures how the future is constrained given knowledge of the present. It is defined in IIT \cite{oizumi2014phenomenology} as:
\begin{equation}
\label{def:ei}
\text{ei}(W_{t} = \mathbf{s}, V) = D\left(p_e(V_{t+1}|W_{t} = \mathbf{s}),p_{e}(V_{t+1}|\emptyset)\right).
\end{equation}

Finally, we define the cause-effect information ($cei$) to be the minimum between the cause information and effect information:

\begin{equation}
\label{def:cei}
\text{cei}(W_{t} = \mathbf{s}, V) = \min\left(\text{ci}(W_{t} = \mathbf{s}, V), \text{ei}(W_{t} = \mathbf{s}, V) \right)
\end{equation}

The minimum of these two functions is taken in order to ensure that knowledge which generates either no \textit{cause information} or no \textit{effect information} will thus generate no \textit{cause effect information}. Intuitively, cei measures how much $W$ effects, and is effected by $V$.

\subsubsection{Integrated Information}
\label{sec:mech_integration}
The function $\varphi^{\text{MIP}}$ measures the \textit{irreducibility} of the information generated by knowledge of a \textit{mechanism}. Specifically this function questions whether the same information might have been generated if the graph was cut into bipartitions. 

Intuitively, if a mechanism can be split into disjoint parts and these generate the same result, then the mechanism is reducible and $\varphi=0$. In contrast, the larger $\varphi$ is, the more information the mechanism has beyond the sum of its parts. In order to make IIT's definition of $\varphi^{\text{MIP}}$ easier, we define some intermediate calculations, the first of which is the \textit{partitioned cause repertoire} as

\begin{equation}
\label{def:preMIP}
p_c^{M,N}(A_{t-1}|B_t ):= p(N_{t-1}|M_t) p((A \backslash N)_{t-1} |(B \backslash M)_t).
\end{equation}

In other words, we partition the information of the present into $M$ and $B\setminus M$, and possibilities of the past into $N$ and $A \setminus N$. Then instead of determining the distribution of past states of $A$ given $B$, we compute it for $N$ given $M$ and $A\setminus N$ given $B \setminus M$ separately. We then multiply these distributions together to get the \textit{partitioned cause repertoire}.

Next, we define the \textit{partitioned cause information}:

\begin{equation}
\label{def:phi2}
\varphi_{cause}^{M,N}(W_t=\mathbf{s}, V) := D \left( p_c(V_{t-1}|W_t=\mathbf{s}) ,p^{M,N}_c(V_{t-1}|W_{t} = \mathbf{s})  \right).
\end{equation}.

where as in section \ref{sec:cei}, $V, W \subset Y$ are $k$-th and $m$-th order \textit{mechanisms} respectively. What this measures, is the difference between the distribution of future states of the $V$ , and the \textit{partitioned cause repertoire} using the EMD. In other words, we measure the difference made by partitioning our system.

We then define the \textit{partitioned cause information} as below.

\begin{equation}
\label{def:phi3}
\varphi_{cause}^{\text{MIP}}(W_t=\mathbf{s}, V)  =\min \limits_{M \in \mathbb{P}(V), N \in \mathbb{P}(W)} \varphi_{cause}^{M,N}(W_t=\mathbf{s}, V) 
\end{equation}

We call the sets $M$ and $N$ which gave rise the minimum the \textit{minimum information partition} (MIP) \cite{oizumi2014phenomenology}. We compute \textit{partitioned cause information} because the information we are measuring is only irreducible if a partition makes a difference even in the worst case scenario.


To compute the analogous MIP for effects and $\varphi^{\text{MIP}}_{effect}$, We need only to swap $p_c$ for $p_e$. This allows us to define integrated information $\varphi^{\text{MIP}}$ \cite{oizumi2014phenomenology}:
\begin{equation}
\label{def:phi}
\varphi^{\text{MIP}}(W_t=\mathbf{s}, V) = \min \left( \varphi_{cause}^{\text{MIP}}(W_t=\mathbf{s}, V), \varphi_{effect}^{\text{MIP}}(W_t=\mathbf{s}, V)  \right) 
\end{equation}



It is useful to recognise the relation between $\varphi^{\text{MIP}}$ and $cei$. Specifically we have following result which was established by Marshall et all \cite{marshall2016integrated}:
\begin{equation}
\label{eq:bound_phi_cei}
\varphi^{\text{MIP}}(W_t=\mathbf{s}, V) \leq cei(W_t=\mathbf{s},V) 
\end{equation}

This implies that the biggest difference we can make to $\varphi^{\text{MIP}}$ by partitioning a mechanism occurs when the partitioned repertoire is precisely the unconstrained repertoire. 



\subsubsection{Maximally Integrated Information}
The last function on a \textit{mechanism} level to define is $\varphi^{\text{Max}}$. Let $W_t = \mathbf{s}$ be a $m$-th order mechanism, and $Y$ be the \textit{candidate set}, such that $W \subset Y$. We define $\varphi^{\text{Max}}$, the maximally integrated information \cite{oizumi2014phenomenology} as: 
\begin{equation}
\label{def:core_cause}
\varphi^{\text{Max}}_{\text{cause}}(W_t = \mathbf{s}):=\max \limits_{V \in \mathbb{P}(Y)}\varphi^{\text{MIP}}_{\text{cause}}(W_t = \mathbf{s}, V).
\end{equation}

What $\varphi^{\text{Max}}$ determines is how much integrated information is generated by $W$ on the subset of the \textit{candidate set} for which it generates the most integrated information. The \textit{mechanism} $V$ which gave rise to the maximum is called the \textit{core cause} of $W_t = \mathbf{s}$.

The \textit{core effect} and  $\varphi^{\text{Max}}_{\text{effect}}$ are defined similarly. Finally we finish  by setting $\varphi^{\text{Max}}$ to be the minimum of the two as before. It is important to note that we find the \textit{core cause} and \textit{effect separately}, and that these need not be the same set.

As with $\varphi^{\text{MIP}}$ we bound $\varphi^{\text{Max}}$ \cite{marshall2016integrated}. 

\begin{equation}
\label{eq:bound_phimax}
\varphi^{\text{MIP}}(W_t = \mathbf{s}, V) \leq \varphi^{\text{Max}}(W_t = \mathbf{s})\leq cei(W_t = \mathbf{s}, V) \quad \forall V \in \mathbb{P}(Y).
\end{equation}

If we find that $\varphi^{\text{Max}}(W_t =\mathbf{s})>0$, then we call the combination of $\varphi^{\text{Max}}(W_t = \mathbf{s})$ with its core cause and effect a \textit{concept}. This allows us to define a \textit{maximally integrated cause effect repertoire}.

\begin{definition}
	{The \textit{maximally integrated cause effect repertoire} of a piece of information, or MICE, refers to the combination of the cause repertoire $p_c(C_{t-1}|W_t = \mathbf{s})$, where $C$ is the core cause of $W_t=\mathbf{s}$ along with the effect repertoire $p_e(E_{t+1}|W_t = \mathbf{s})$, where $E$ is the core effect of $W_t = \mathbf{s}$.}
\end{definition}

\subsection{Calculations for Systems of Mechanisms}
\label{sec:systems}
Thus far calculations have been restricted to a single mechanism, whether 1st, 2nd, or $n$th order. However, a network of more than one node may contain multiple mechanisms, which may overlap with each other. Specifically a system of $n$ nodes contains $2^n-1$ \textit{mechanisms}.

Now we focus our attention on computing integrated information in a system of mechanisms. 

\subsubsection{Conceptual Information}
\label{sec:CI}
The Conceptual Information (CI) extends the notion of cause-effect information to a system of nodes. Before we computed the distance between the repertoire specified by some information and the unconstrained repertoire. Now, instead of computing the distance between repertoires, we add up the distances between concepts.

The Conceptual Information is simply weighted sum of the distance between the MICE of each of its concepts, and the unconstrained MICE. We compute it below:

\begin{equation}
\label{def:CI}
CI(Z_t = X) = \sum \limits_{S \in \mathbb{P}(Z)} \varphi^{\text{Max}}(S_t=X) D(M^S, M^{uc})
\end{equation}

where $M^S$ refers to the MICE of the concept $S$, and $M^{uc}$ is the unconstrained MICE, which is just the unconstrained cause and effect repertoires. We measure the distance between $M^S$ and $M^{uc}$ by adding the distances between the two cause, and effect repertoires.

\begin{remark}
	Equation \ref{def:CI} uses Oizumi et all's \cite{oizumi2014phenomenology} definition of $CI$. However, it was pointed out by Krohn and Ostwald \cite{krohn2016computing} that this definition is not well defined. The MICE is defined as the set of cause and effect repertoires that maximize $\phi^{MIP}$. However, there may be two such MICE's: $M_1$ and $M_2$, which yield the same value for $\phi^{Max}$, and yet affect equation \ref{def:CI} differently. We show equation \ref{def:CI} as we used the software provided by Mayner et all \cite{pyphi} which follows the flawed definition. Krohn and Ostwald propose a simpler definition which fixes this issue, where they merely add up the values of $\varphi^{\text{Max}}$, and ignore the MICE.
\end{remark}

\subsubsection{Integrated Conceptual Information}
Now we measure the integration of a piece of information on the level of a system of mechanisms. Here it is useful to define the term \textit{constellation}.

\begin{definition}
	{A \textit{constellation} refers to the set of all concepts within a system, each concept equipped with its' MICE.}
\end{definition}

As before, we consider all ways to partition the system $Z$. However, on this occasions, each partition is a one directional cut. Hence there exist twice as many possible partitions as in section \ref{sec:mech_integration}. We compute the constellation for the partitioned system, labelling it as $M^p$. For this partitioned system, some of the concepts from the while system will remain intact, but others will have been destroyed by the partition.

Let the function $C(P)$ refer to the set of concepts, given the partition $P$. Then we define:

\begin{equation}
\label{def:Phi_integration1}
\Phi^P(Z_t = X) = \sum \limits_{S \in (Z \setminus C(p))} \varphi^{\text{Max}}(S_t = X)D(M^S, M^{uc})
\end{equation}

The difference between $\Phi^P$ and $CI$ is that while in $CI$ we sum over all concepts, in $\Phi^P$ we only sum over the concepts which have been destroyed by the partition.

As before we seek the minimum information partition (MIP). This time we define it as:

\begin{equation}
\label{def:Phi_integration2}
\Phi^{\text{MIP}} (Z_t = X) = \min \limits_{P} \Phi^P(Z_t = X)
\end{equation}

\begin{remark}
	As in section \ref{sec:CI}, the value specified in equation \ref{def:Phi_integration2} is not defined, for the same reason as previously. Krohn and Ostwald present the same solution as before: they remove the $D(M^S, M^{uc})$ term from the equation, leaving only the $\varphi^{\text{Max}}$ terms.
\end{remark}

\subsubsection{Maximally Irreducible Conceptual Structure}

Thus far in how $\Phi$ is defined, there exists an intuitive example which breaks the definition. Consider a network consisting of a dense cluster of nodes which has a large value of $\Phi$. Next, add a single node to this cluster, which we connect to the cluster with a single edge. If we compute $\Phi$ now, find a partition which makes almost no difference at all (when we eliminate the single node), which results in the new system having a small $\Phi$ value. 

Intuitively we understand that the conclusion: `adding a single extra neuron to the brain destroys all consciousness' is ridiculous. Hence we need the value $\Phi^{\text{Max}}$ to finish our definition of Integrated Information Theory. We define:

\begin{equation}
\label{def:Phimax}
\Phi^{\text{Max}}(Z_t = X) := \max \limits_{W \in \mathbb{P}(Z)}\Phi^{\text{MIP}} (W_t = X)
\end{equation}

\begin{remark}
	When we compute $\Phi^{\text{MIP}} $ for all subsets $W$ of $Z$, we are not computing it over the \textit{mechanism} $W$ but rather over the \textit{system} $W$. This means that all nodes in $Z \setminus W$ are now treated as external inputs/outputs, instead of unknown nodes in system.
\end{remark}

\subsection{Computational Cost}
We now ask how expensive is the computation of $\Phi^{Max}$. Let $Z$ refer to a system of nodes such that $|Z| = n$.

\begin{enumerate}
	\item To compute $\Phi^{\text{Max}}$, we must calculate $\Phi$ for possible subsets of our system. There are at most $2^n$ such subsets, and hence we must compute $\Phi$ this many times.
	\item For a particular subset of consideration, we must determine the Minimum information partition of one directional cuts. If the subset is of size $m$, then there at most $2^{m+1}$ ways to do this (if the connectivity matrix is sparse, then there are considerably less). $m$ itself is bounded by $n$, so we say that this step must occur at most $2^{n+1}$ times.
	\item Each computation of $\Phi$ for a particular partition requires the calculation of all values of $\varphi^{\text{Max}}$. As each element of the power set may have a positive value of such, we must carry out this computation up to $2^n$ times.
	\item Each computation of $\varphi^{\text{Max}}$ requires both the core cause and core effect to be identified. This involves calculation $\varphi^{\text{MIP}}_{cause}$ and $\varphi^{\text{MIP}}_{effect}$ each over the entire power set, resulting in a further $2^{n+1}$ computations.  
	\item To compute $\phi_{cause}^{\text{MIP}}$, we must search over all possible partitions. There are $2^n$ of these.
	\item Finally, when measuring the difference made by a partition, we must measure the distance between probability distributions. This is done using the Earth Mover's Distance, which scales $O(N^3 \log N)$, where $N$ is the number of states found in the distributions the distance is being measured between. As there are $2^n$ of these, this step scales with $O(2^{3n} (\log n)^3)$
\end{enumerate}

When we put this all together, we conclude that the calculation of $\Phi^{Max}$ scales with $O(n^3 2^{8n})$.


\section{Modelling an Organisation}

In this section, we seek to model communication flow within an organisation. To do this, the first step is to specify the type of organisation that we're referring to. 

\begin{enumerate}
	\item The organisation is a company which generates revenue by completing projects.
	
	\item Each project requires the application of certain skills in order to be completed.
	
	\item The organisation consists of a fixed number of teams, each possessing one or more skill.
	
	\item Projects are completed by assigning sufficiently many teams to the project which possess all skills required to complete the project.
\end{enumerate} 

Within this framework, where does communication come in? Suppose that a project appears which requires python programming skills. Further, let there be 2 distinct teams which have this skill. What happens now? If these teams are not communicating, then they might both take on the same project, depending on the policy by which they decide what to do. Alternatively, if they are communication, not only can they guarantee that they don't do the same thing, but they can also collaborate with each other, thus finishing the project faster than otherwise.

Suppose we have $n$ teams. We represent these teams in mathematics as nodes in a graph. Each of these nodes has 2 states: `on' and `off'. A team is active if its node is `on', and is idle if the node is `off'. Next we say that one team $v_1$ is paying attention to another team $v_2$ if there exists a directed edge from $v_1$ to $v_2$. Furthermore, these teams are said to be communicating both teams are paying attention to each other.

With this structure defined, we now need to consider how to build dynamics into the model. In particular we must define the following:

\begin{itemize}
	\item Progression of time. We take our model to be a discrete iterative process. Each iteration marks the passage of a fixed time period. 

	\item Arrival of Projects. We model projects such that with each time step, a single project might arrive. The nature of the project which arrives we determine using a multivariate Bernoulli distribution.
	
	\item Completion of Projects. We arbitrarily decide that the duration of a project will be distributed exponentially. This is equivalent to saying that each project has an identical chance of completion following each iteration.
\end{itemize}


\subsection{The Small 3-node Model}
\label{sec:3nodemodel}
In this model, we consider there to be 3 teams, and 2 skill types. We label the teams as $A$, $B$ and $C$, and the skill types as $\alpha$ and $\beta$. We decide arbitrarily that teams $A$ and $C$ have skill $\alpha$, while teams $B$ and $C$ have skill $\beta$. This arrangement is illustrated in figure \ref{fig:diagram1}.

\begin{figure}[ht]
	\centering

	\includegraphics[]{ModelDiagram.png}
	\caption{We have 3 types of nodes: skill types ($\alpha$ and $\beta$), teams ($A$, $B$ and $C$), and incoming project alerts ($P_\alpha$ and $P_\beta$). If a team node is joined to a skill node by an edge, then the team possesses that skill. All of the teams have one way connections with the incoming project alerts nodes because the teams respective state do not effect incoming projects' state, but are effected by them.}
	\label{fig:diagram1}
\end{figure}

With the teams, skills and assignment of these defined, we specify the details of the model dynamics in the following three steps.

\begin{steps}
	
	\item \textbf{Arrival of projects}\\
	Earlier we stated that this process was based on a multivariate Bernoulli distribution. Specifically we use the 2-dimensional version, as we are working with 2 types of skills. We specify the vector of probabilities: $\mathbf{p} = (p_\alpha, p_\beta)$ such that an incoming project requires skill $\alpha$ with probability $p_\alpha$ and similarly for skill $\beta$.
	
	We create 2 `incoming project alert' nodes which we label as $P_\alpha$ and $P_\beta$. The state of these nodes is determined only by the previously mentioned probability distribution. Hence these nodes transition states independently of any other node. 
	
	\item \textbf{Assignment of projects}\\
	First are the 3 simple cases. If a project which requires skill $\alpha$ but not $\beta$ arrives, and team $A$ is idle, then the project is assigned to $A$, resulting in team $A$ turning on. Similarly teams $B$ and $C$ will turn on if a project arrives tailored to their abilities while they are not already active.	
	
	2 more cases exist: If a project suitable for team $A$ arrives while $A$ is busy and $C$ is idle, then $C$ will be assigned $A$'s task. The same will apply if $B$ is busy when such a project arrives. Finally, if a project requiring both skills arrives while $C$ is busy while $A$ and $B$ are both idle, then $A$ and $B$ will be assigned the project, resulting in both of them transitioning to a state of `on'.
	
	\item \textbf{Completion of projects}\\
	We already stated the time required to complete a project to be modelled by th exponential distribution. This was so we could use a simple Bernoulli process to determine when a project is completed. This means that the probability of completing a project is constant w.r.t. time. However, to make this process more realistic, we decide that the probability of completing a project will not be independent of active working connections.
	
	We define the parameters $k_A$, $k_B$ and $k_C$ to represent the effectiveness of each team. If $A$ is active, then it will complete its task with probability $k_A$ after each time-step, and so on. 
	
	However, when teams are working on similar tasks, then collaboration occurs. Specifically, if teams $A$ and $C$ are both active, since skill $\alpha$ is required for both projects, $C$ will assist $A$. However, as $C$'s project also involved skill $\beta$, $A$ will be unable to return the assistance. In this case, $A$ will finish its task after the next time-step with probability $k_A + k_B$, which for $C$ things are unchanged. 
	
	$C$ can only receive assistance when all teams are active, since together $A$ and $B$ account for all required skills. In this final case, $C$ will complete its task with probability $k_A+k_B+k_C$.
\end{steps}


Now we can put this all together to form the state by node transition probability matrix: $\mathbf{T}$, defined as:
\begin{equation}
\mathbf{T}_{ij}= P(z^j_{t+1}=1 | Z_t = i)
\end{equation}

where $Z$ refers to the entire network with $z^j$ standing for $A$, $B$, and $C$ (the team nodes) in addition to $P_\alpha$ and $P_\beta$, (the incoming project alert nodes) for $j=1,2, \ldots, 5$. $\mathbf{T}$ is the \textit{state by node} transition probability matrix, as previous described in section \ref{sec:conditional_independence} having 32 rows and 5 columns. We present this matrix in table \ref{mat:simple_system}.


\begin{table}[h!]
	\centering
	$
	\begin{array}{|l|ccccc}
		\hline
		\multicolumn{1}{|r|}{\text{State}} & \multicolumn{1}{c|}{A} & \multicolumn{1}{c|}{B} & \multicolumn{1}{c|}{C} & \multicolumn{1}{c|}{P_\alpha} & \multicolumn{1}{c|}{P_\beta} \\ \hline
		000 00                      & 0                      & 0                      & 0                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		100 00                      & 1-k_A                 & 0                      & 0                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		010 00                      & 0                      & 1-k_B                 & 0                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		110 00                      & 1-k_A                 & 1-k_B                 & 0                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		001 00                      & 0                      & 0                      & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		101 00                      & 1-k_A-k_C            & 0                      & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		011 00                      & 0                      & 1-k_B-k_C            & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		111 00                      & 1-k_A-k_C            & 1-k_B-k_C            & 1-k_A-k_B-k_C       & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		000 10                      & 1                      & 0                      & 0                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		100 10                      & 1-k_A                 & 0                      & 1                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		010 10                      & 1                      & 1-k_B                 & 0                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		110 10                      & 1-k_A                 & 1-k_B                 & 1                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		001 10                      & 1                      & 0                      & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		101 10                      & 1-k_A-k_C            & 0                      & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		011 10                      & 1                      & 1-k_B-k_C            & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		111 10                      & 1-k_A-k_C            & 1-k_B-k_C            & 1-k_A-k_B-k_C       & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		000 01                      & 0                      & 1                      & 0                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		100 01                      & 1-k_A                 & 1                      & 0                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		010 01                      & 0                      & 1-k_B                 & 1                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		110 01                      & 1-k_A                 & 1-k_B                 & 1                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		001 01                      & 0                      & 1                      & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		101 01                      & 1-k_A-k_C            & 1                      & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		011 01                      & 0                      & 1-k_B-k_C            & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		111 01                      & 1-k_A-k_C            & 1-k_B-k_C            & 1-k_A-k_B-k_C       & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		000 11                      & 0                      & 0                      & 1                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		100 11                      & 1-k_A                 & 0                      & 1                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		010 11                      & 0                      & 1-k_B                 & 1                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		110 11                      & 1-k_A                 & 1-k_B                 & 1                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		001 11                      & 1                      & 1                      & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		101 11                      & 1-k_A-k_C            & 0                      & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		011 11                      & 0                      & 1-k_B-k_C            & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		111 11                      & 1-k_A - k_C          & 1-k_B-k_C            & 1-k_A-k_B-k_C       & p_\alpha                      & p_\beta                      \\ \cline{1-1}
	\end{array}
	$
	\caption{Above is the Transition Probability Matrix for the small 3-node model. We represent each state of the system as a length 5 binary string, where the 1's and 0's refer to `on' and `off' respectively. We list nodes in the order: $A, B, C, P_\alpha, P_\beta$. Hence, 10010 means that nodes $A$ and $P_\alpha$ are active, while the rest are idle.}
	\label{mat:simple_system}
\end{table}



Finally, for this model to be interesting, we need to have some control over the parameters. For this, we think of $k_A$, $k_B$ and $k_C$ of being directly related to the funding invested in each team. Hence we assume $k_A+k_B+k_C = K$, where $K$ is a constant which refers to the total amount of funding at the organisations disposal. $k_i$'s refer to how we allocate that funding.

When solving for this model, we will employ two methods: IIT and a classical approach. For IIT, we will compute the value of $\Phi$, while for the classical approach, we instead will introduce the notion of costs, and from this compute the economic performance with respect to the parameters $k_A$, $k_B$ and $k_C$. 

\subsubsection{Classical Solution}
Currently in our model a project will definitely be completed, the question is how long it will take. Thus we don't have to worry about the cost of failed projects. Instead, we concern ourselves with the value of missed projects: those which arrive when there is no suitable team or combination of team available to be assigned to it. Define $W_A$, $W_B$ and $W_C$ to be the waste incurred when a project requiring skills $\alpha$, $\beta$ and both  is missed respectively.

When does this waste happen? Look back at table \ref{mat:model1}. Based on how we've define the allocation process, the only states at which waste can occur are: $10110$, $11110$, $01101$, $11101$, $10111$, $01111$ and $11111$. If the last two digits of the state is $10$, then a project requiring skill $\alpha$ is lost, resulting in waste of $W_A$. $01$ means that a project needing skill $\beta$ is lost, resulting in waste of $W_C$. The rest refer to a project needing both skills, for which the waste is $W_C$. In short, waste results from exactly 7 different states, and can be either $W_A$, $W_B$ or $W_C$.

So we know how much money we expect to waste for each state. Now the question is: how often do we expect to be at each state? We can take two approaches: either we can simulate the system and compute waste from the time series, or else we can compute the expected waste per iteration by finding the stationary distribution of the system. We take the latter approach.

When the values of $k_i \in (0,1)$, then the $32\times32$ state by state transition probability matrix $\mathbf{M}$ will have an eigenvalue of 1 with geometric multiplicity 1. Furthermore, $-1$ will not be an eigenvalue. Hence the left eigenvector with eigenvalue 1 will the be stationary distribution of the system, which precisely describes the long term behaviour of the system. 

Hence our cost function is:
\begin{equation}
\label{eq:simple_model_cost_function}
f(k_A, k_B, k_C) = \mathbf{q}(W_A, W_B, W_C) \cdot \mathbf{v}(k_A, k_B, k_C, p_\alpha, p_\beta)
\end{equation}

where $\mathbf{v}$ is the stationary distribution of the system, which depends on $k_A$, $k_B$, $k_C$, $p_\alpha$ and $p_\beta$ while $\mathbf{q}$ is a vector which contains the cost of each state hence depending on $W_A$, $W_B$ and $W_C$. In short, given the 5 constants: $p_\alpha$, $p_\beta$, $W_A$, $W_B$ and $W_C$, we can express cost as a function of $k_A$, $k_B$ and $k_C$. 

\subsubsection{IIT Comparison}

In this section we compare the results of IIT with the expected waste of the network. $\Phi$ depends on the matrix $\mathbf{M}$ and the initial state. However, we would prefer to have a function which is independent of state like our cost function. Thus, just as we computed cost in equation \ref{eq:simple_model_cost_function} by taking the inner project of the cost vector with the stationary distribution, we take a similar approach here.
Define $\mathbf{\Phi}$ the length $2^n$ vector containing the values of $\Phi$ at each state of the system. Using this, we compute:

\begin{equation}
\mathbb{E}[\Phi]:= \mathbf{\Phi}\cdot \mathbf{v}(k_A, k_B, k_C, p_\alpha, p_\beta)
\end{equation}

Using $\mathbb{E}[\Phi]$ instead of $\Phi$ given a particular state makes sense intuitively. Suppose $\Phi$ measured in some what the quality of the project allocation process at a particular step. Then its is possible that the reason it was a good step was because it will create opportunities in the future by taking on costs in the present. Thus we would be more interested in the average value of $\Phi$ if it were to have this meaning, which is what we hope.

Finally we compare $\mathbb{E}[\Phi]$ against expected waste. We arbitrarily choose $p_\alpha$ and $p_\beta$ to both be $0.5$, while we pick $W_A=0.3$, $W_B = 0.5$ and $W_C = 0.2$. Finally we set $K = k_A+k_B+k_C = 0.5$, and vary the parameters according to this constraint. We present our results in figure \ref{fig:simple_model_phi_cost_plot}.

\begin{figure}[!ht]
	\centering
	\includegraphics[scale = 0.5]{phicostplot.pdf}
	\caption{We present a scatter-plot of the values for $\mathbb{E}[\Phi]$ and expected waste, when we vary the parameters $k_A, k_B$ and $k_C$ subject to $k_A+k_B+k_B=1/2$.}
	\label{fig:simple_model_phi_cost_plot}
\end{figure}

What we find is there does seem to be a relation between the expected waste and $\mathbb{E}[\Phi]$. When we look at figure, we see what the points lie along a shape which resembles a quadratic function with respect to expected waste. This is ideal from the perspective that it leads us to believe that these values are not independent of each other. On the other hand, we can't express Expected Waste as a function of $\mathbb{E}[\Phi]$ since, the shape bends back on itself. i.e. if we pick the value of $\mathbb{E}[\Phi]$ which corresponding to the point of minimal waste, there are other points that have considerably more waste, yet with the same value of $\mathbb{E}[\Phi]$.

While we could adjust the parameters to see how this shape evolves, instead we question whether this model is suitable, or should be added to. We identify the following flaws in this setup:

\begin{enumerate}
	\item As things stand, the project allocation process assumes that all three worker nodes are connected to each other, and hence communicating at all times. More interesting results might be obtained if the connectivity was more sparse.
	
	\item The current definition of waste is the value of the projects which can't be done because the workers are busy. However, this rather measures missed opportunities due to the size of the organisation, as opposed to communication errors. We're more interested in measuring the direct consequences of miscommunication.

\end{enumerate}

Motivated by these observations, we need to include more worker nodes into the model so that we can have sparser connections, without the system becoming trivial. 

\subsection{The 5-node Model}

The general design of this model is the same as that in section \ref{sec:3nodemodel}. We begin by listing the extensions/adjustments:



We extend the previous model as follows: 
\begin{enumerate}


	\item Before there were 2 types of skills: $\alpha$ and $\beta$. We now include a third: $\gamma$.
	
	\item As implied in the section title, we increase the size of the organization from 3 to 5 nodes. The first 3 nodes: $A$, $B$ and $C$ possess the same skills as in section \ref{sec:3nodemodel}. The two additional nodes $D$ and $E$ possess the skills $\alpha, \gamma$ and $\beta, \gamma$ respectively. We illustrate this in figure \ref{fig:diagram2}.
	
	\item We change our definition of waste to focus on errors due to miscommunication, as opposed to merely projects which can't be attempted.
	
	\item We adjust the project allocation procedure to be dependent on the connectivity matrix.
\end{enumerate}

\begin{figure}[ht]
	\centering	
	\includegraphics[]{Model2Diagram.png}
	\caption{We have 3 types of nodes: skill types ($\alpha$, $\beta$, and $\gamma$), teams ($A$, $B$, $C$, $D$ and $E$), and incoming project alerts ($P_\alpha$, $P_\beta$ and $P_\gamma$). If a team node is joined to a skill node by an edge, then the team possesses that skill. The teams receive inputs from the incoming project alert nodes, but the dependence is strictly one directional.
		Certain teams are connected, indicating that they are actively communicating with each other so to distribute work efficiently. Note that in this figure, we have 2 disconnected clusters of teams. This will give rise to waste.}
	\label{fig:diagram2}
\end{figure}

The increased size of this model allows us more realistic scenarios in which waste occurs due to miscommunication. The main question is: will $\Phi$ have a more obvious relation to this form of waste. Now we must define in detail: how allocate incoming projects, and how to define waste.


In the previous model, we allocated projects from a global perspective. We knew for any given project was the the best arrangement would be, and then chose this to happen. Since all the teams involved were in communication, this made sense. However, what happens if teams are not all communicating?. For this model, we establish the following localised decision making policy to determine whether or not a team decides to take on a project. In decreasing order of importance, each team should aim to:


\begin{enumerate}
	\item Ensure that a project is allocated if it is possible to do so.
	\item Ensure that if a project is being worked on, that only on set of teams is doing so. In other words, ensure that there doesn't exist any duplication of labour.
	\item Minimize the amount of excess skills possessed by the team/teams assigned to the project.
\end{enumerate}

When applying this policy, each individual team acts as if any team which it is not paying attention to does not exist. This means that if a team is disconnected from all other teams (meaning it does not know what any of the others are doing), then it will always take on an incoming project which it can do. This will happen independently of whether another team is also taking on the project, because the isolated team does not know this. 

Similarly, if a pair of strongly connected teams see a project which they are overqualified for, and can both see another pair of teams which can complete the project with less excess skills, then the first team will ignore the project. However, while the first pair of teams observed that the second pair were both idle, it couldn't observe whether the 2nd two were strongly connected. If the second team are not strongly connected, then the project will be missed entirely, due to lack of communication. We illustrate this phenomenon in figure \ref{fig:waste1demo1}.

\begin{figure}[ht]
	\centering	
	\includegraphics[scale=0.13]{Waste1demo1.png}
	\caption{In this example we have an incoming project which requires both skills $\alpha$ and $\beta$. Teams $D$ and $E$ would possess these skills if they collaborate which they can do as they are connected, even though they have 2 $\gamma$ skills in excess. However, both $D$ and $E$ can see that the collaboration of $A$ and $B$ can complete the project more efficiently. Thus $D$ and $E$ do not take on the project as they do not know that $A$ and $B$ are not collaborating, and thus won't take the project either. Due to this lack of communication, even though there were plenty of ways that the project might have been done, the project is wasted.}
	\label{fig:waste1demo1}
\end{figure}

Ultimately, this procedure precisely determines a $2^8 \times 8$ transition probability matrix, which for obvious reasons is not presented here. Next we turn our attention exclusively to the classical solution, which is where we will redefine the notion of waste.

\subsubsection{Classical Solution}

In this section, we compute the expected waste which will result from a particular connectivity matrix. However, we first must lay out what we mean by `waste'. In the context of this model, there are 3 different types of inefficiencies that can occur in the distribution of projects:

\begin{enumerate}
	\item \textbf{Unnecessary dismissal of project}\\
	If there exists a minimal subset of idle teams which possess the required skills to take on an incoming project, and yet the project is not assigned to anyone, then this is wasteful of the project itself.
	
	\item \textbf{Duplication of work}\\
	If there exists multiple minimal subsets of idle teams which possess the required skills to take on an incoming project, and multiple of these groups of teams are assigned to the project, then this is an unnecessary duplication of labour.
	
	\item \textbf{Excess Skills}
	If there exists an idle team which possesses skills beyond the requirements of an incoming project, and this team is assigned to the project, then this wasteful of these excess skills.
\end{enumerate}

Of these 3 sources of waste, we arbitrarily view type 1 to be 10 times worse than type 2 which is again 10 times worse than type 3. However, what is the numerical value of these costs?

For this we take a simplistic approach. We assign the values $W_\alpha, W_\beta$ and $W_\gamma$ to be the values of each skill type. When counting type 1 waste (a doable project is ignored), we add the values of all skills required and scale by 10. Hence, a project requiring all 3 skills would have a cost of $10(W_\alpha+W_\beta+W_\gamma)$.

With type 2 waste (a project being worked on by more than one team), we count the skills possessed by all teams which are assigned to the project. Then we determine how many times the project could be completed form this pool of skills. We assign the cost in this case to be the sum of the costs applying to the skills required by the project, multiplied by the number of times we find this 

When counting type 3 waste, we count how many excess skills are possessed by the assigned teams, and then add up the values of these skills. Finally we scale this value by $1/10$.

\begin{remark}
	In section \ref{sec:3nodemodel}, we assigned a distinct cost to each type of project. Here we simplify that approach as otherwise we would be left with 8 parameters.
\end{remark}

By applying this definition of waste to all states of the system, we construct the vector function $\mathbf{q}(W_\alpha, W_\beta, W_\gamma)$ so that each value in the vector refers to the waste given the corresponding state and parameters. From this, we construct our function:

\begin{equation}
\label{eq:cost_function}
Cost(k_A, k_B, k_C) = \mathbf{q}(W_A, W_B, W_C) \cdot \mathbf{v}(k_A, k_B, k_C,k_E, k_F, p_\alpha, p_\beta, p_\gamma)
\end{equation}

where $\mathbf{v}$ is the same vector function defined in section \ref{sec:3nodemodel} appropriately adjusted for the additional nodes and skill type.

\subsubsection{IIT Comparison}

When comparing $\mathbb{E}[Cost]$ to $\mathbb{E}[\Phi]$, we first need to decide the context in which we are doing do. The approach we took was to keep the parameters $k_i, p_i$ and $W_i$ all fixed, and instead to vary the connectivity matrix. We justify this choice on grounds that: in an existing organisation, these values would be difficult to change. What could change more easily is who talks to whom. Thus we view that choosing the connectivity matrix to be our variable is more relevant to the problem.

However, we still need to be more specific as there are exactly $2^{64}$ $8\times 8$ connectivity matrices. Thus we restrict our attention to connectivity matrices which have exactly 10 directed edges. There are still a vast number of such matrices, roughly 180,000. Therefore, due to computational time restrictions, we randomly select 200 of these matrices and plot the results in figure \ref{fig:model_costvsphi}.

\begin{figure}[h!]
	\centering
	\includegraphics[scale = 0.5]{maxvscost_random.pdf}
	\caption{We plot $\mathbb{E}[Cost]$ against $\mathbb{E}[\Phi]$ for 200 randomly selected connectivity matrices with precisely 10 directed edges.}
	\label{fig:model_costvsphi}
\end{figure}

Having plotted $\mathbb{E}[Cost]$ as a function of $\mathbb{E}[\Phi]$, we see a linear correlation. Even more importantly though, we observe that maximising $\mathbb{E}[\Phi]$ also results in minimizing $\mathbb{E}[Cost]$. This looks ideal, but we must remind ourselves that a sample of size 200 out of 180,000 is by no means conclusive. Unfortunately, the time required to compute each data point prevents us from repeating this experiment. 


Therefore, we set up a smaller problem which can be solved exhaustively. Instead of starting with an empty connectivity matrix, and adding 10 directed edges to it, now we start with a developed matrix. Specifically, we consider the matrix which applies to figure \ref{fig:diagram2}, in that the nodes $A$, $B$ and $C$ are completely connected to each other, which being entirely disconnected from $D$ and $E$. This matrix is a $5\times 5$ block diagonal matrix consisting of a $3 \times 3$ and $2 \times 2$ matrix of 1's along the diagonal. Next we introduce an addition 4 directed edges with which we want to join these 2 clusters.

Intuitively, this problem can be though of as forcing two distinct department to talk to each other, and searching for the best way that this can be accomplished. In this setup, there are only 495 different connectivity matrices, and hence an exhaustive search is achievable.

We plot $\mathbb{E}[Cost]$ against $\mathbb{E}[\Phi]$ for this case, showing the result in figure \ref{fig:maxvscost_small}.

\begin{figure}
	\centering
	\includegraphics[scale=0.5]{maxvscost_small.pdf}
	\caption{We plot  $\mathbb{E}[Cost]$ against $\mathbb{E}[\Phi]$ for connectivity matrices where we add 4 directed edges to the network shown in figure \ref{fig:diagram2}}
	\label{fig:maxvscost_small}
\end{figure}

Now I discuss the content of the figure which I have not yet generated as I don't have all of the data yet.

I will also show what the best network in these setup is

\section{IIT revisited}
In section \ref{sec:iit}, we presented the definitions of Integrated Information Theory as defined by Oizumi et al \cite{oizumi2014phenomenology}, while using a modification of the notation presented by \cite{krohn2016computing}. In this section, we will critique the mathematical implementation of IIT, and consider whether it is indeed applicable to the problem of consideration: communication within an organisation.

\subsection{Distance Between Repertoires}
In this section, we examine the process of computing distances between effect repertoires. In particular, let $Z$ be a system of mechanisms, and $W$ a particular mechanism. Consider the computation of: $\varphi^{M,N}_{cause}(W_t = X, Z)$. This value is equal to the distance between two repertoires: $p_e(Z_{t+1}|W_t = X)$ and $p_e(N_{t+1}|N_t = X)p_e(Z\setminus N_{t+1}|W \setminus M _t = X)$.

We can break down the first of these repertoires using conditional independence:

\begin{equation}
\label{eq:dist_argument_1}
p_e(Z_{t+1}|W_t = X)=\prod \limits_{i=1}^{n} p(z^i_{t+1}|W_t=X)
\end{equation}

Denote by $\mathbf{x}(Z_{t+1}|W_t = X)$ the vector function such that:
$x_i(Z_{t+1}|W_t = X) = p(z^i_{t+1}|W_t=X)$ for $i = 1, 2, \ldots, n$.

Next we break down the second repertoire in a similar fashion:

\begin{align}
\label{eq:dist_argument_2}
p_e(N_{t+1}|M_t = X)&=\prod \limits_{i\in N} p(z^i_{t+1}|M_t=X)\\
p_e(Z\setminus N_{t+1}|W \setminus M_t = X)&=\prod \limits_{i\in Z \setminus N} p(z^i_{t+1}|Z \setminus M_t=X)
\end{align}

Denote by $\mathbf{y}(Z_{t+1}|W_t = X, M,N)$ the vector function such that $y_i(Z_{t+1}|W_t = X, M,N) = p(z^i_{t+1}|M_t=X)$ if $i \in N$ and otherwise is $p(z^i_{t+1}|Z \setminus M_t=X)$. For convenience we now refer to these vectors merely as $\mathbf{x}$ and $\mathbf{y}$.

When computing a repertoire in practice, one first compute the generating vector, of which $\mathbf{x}$ and $\mathbf{y}$ are examples. If the system has $n$ nodes, then these vectors are of length $n$. Next we consider all possible states of the system. We compute the probabilities of each of these states occurring by multiplying values of $x_i$ and $1-x_i$ together. For example, if we wanted to compute the probability that the future state of a 3 node mechanism would be $101$, we would obtain this by computing $x_1 (1-x_2)x_3$.

This procedure is in essence a function: $R: [0,1]^n \rightarrow [0,1]^{2^n}$ which converts the generating vectors into the actual effect repertoires. The last step in computing  $\varphi^{M,N}_{cause}(W_t = X, Z)$ is to use the earth mover's distance to find $\text{EMD}(R(\mathbf{x}), R(\mathbf{y}))$.

Is this entire process really necessary? First we compute $\mathbf{x}$ and $\mathbf{y}$, next convert to $R(\mathbf{x})$ and $R(\mathbf{y})$, and finally compute the distances between these. The step where $R$ is applied scales with $O(2^n)$, and the EMD scales with the size of the vectors its comparing, which is in this case $O(n^3 2^{3n})$. What if instead we used a different distance measurement, and used it on $\mathbf{x}$ and $\mathbf{y}$ directly instead of bothering to apply $R$?

\begin{prop}
	\label{prop:alternative}
	Let $p_1$ and $p_2$ be multivariate Bernoulli distributions equipped with vectors $\mathbf{x}$ and $\mathbf{y}$ such that $p_1(z^i=1) = x_i$ and $p_2(z^i = 1) = y_i$ for $y = 1, 2, \ldots, n$. We further assume that $p_k(z^i, z^j = 1,1) = p_k(z^i = 1) p_k(z^j=1)$ for all $i,j,k$. Then:
	\begin{equation}
	\text{EMD}(p_1, p_2) = ||\mathbf{x} - \mathbf{y}||_1
	\end{equation}
	where the earth mover's distance operates by using the Hamming distance to measure distance between states.
	
	
\end{prop}

\begin{remark}
	For more information on multivariate Bernoulli distributions, see Teugels \cite{teugels1990some}.
\end{remark}

We have verified proposition \ref{prop:alternative} for multivariate distribution with up to 8 variables numerically, and have confirmed the statement to be true with 2 and 3 variable distributions analytically. However, a full proof has not yet been found. 

Regardless of this, by measuring the $||\cdot||_1$ distance between $\mathbf{x} $ and $\mathbf{y}$, we use a process the cost of which scales with $O(n)$. In short, instead of computing distributions from generating vectors, and then finding the distance between these distributions, we simply find the distance between the generating vectors.


\subsection{Computation of Effect Repertoires.}

In this section, we will examine exactly how the effect repertoire $p_e$ is defined, and how it differs from true conditional probability. Recall the definition of the effect repertoire:

\begin{definition}
Let $Z$ be a mechanism with $W\subset Z$, and suppose that the current state of $W$ is known, that is: $W_t = X$. Then the \textit{effect repertoire} of the state $W_t = X$ is the conditional probability distribution for the future states of $Z$ given our current knowledge.
\end{definition}

Based on the description, we should expect $p_e(Z_t|W_t = X)$ the repertoire to be exactly the same as $p(Z_t|W_t = X)$, the probability. 

In section \ref{sec:conditional_independence} we state the assumption of conditional independence with respect to the system. With this states, we should now expect $p_e$ to be the same as $p$ given that conditional independence holds.

...paused here. I had a thought that might explain this. Emailed the makers to IIT3 to check...


\subsection{Alternative $\Phi$'s}
We have already mentioned how there exist multiple alternative definitions of $\Phi$. Here we take a closer look at them, and comment on their potential effectiveness beyond that of $\Phi$ as we've defined here.
Discuss the work of \cite{tegmark2016improved} and mention other options of $\Phi$. Explain why $IIT3$ was used.

\section{Conclusions}
In summary, the first focus of this project was to investigate whether or not IIT has any tangible meaning in the context of communication flow within an organisation. We approached the problem by construction a model for the purpose of measuring the cost of wasted opportunities due to poor communication. The cost of this waste as we defined it does correlate with $\Phi$. This correlation is rough, but it does exist, which justifies the theory that $\Phi$ does relate to communication within a company. 

However, while $\Phi$ does correlate with waste, the computational cost of $\Phi$ is large to the extent that it is not feasible to use, even which systems containing as few as 9 nodes. This computational expense is caused to iterating over the power set of nodes multiple times, in addition to searching all possible partitions repeatedly. Given how each of the steps in computing $\Phi$ seem to be quite similar, we expect that further mathematical scrutiny may result in reducing the size of the computation by locating and removing irrelevant steps. 

In particular, if an appropriate method could be found which made a good estimate as to the minimum information partition (MIP), this would speed up the process considerably. Furthermore, it might be possible to determine what types of networks generate large $\Phi$, and construct them directly.

However until either of these are accomplished and speed up is achieved, IIT is far too expensive to be used on models containing a realistic number of workers. Hence, while $\Phi$ correlates with effectiveness of the network, it doesn't provide any practical help in optimizing communication.

Does $\Phi$ need to be so computationally expensive? Unfortunately, we cannot answer this question. While certain phenomena observed in the brain are consistent with simple conclusions of IIT, the reality is that the computation of $\Phi$ is justified entirely with philosophical arguments, 

4. IIT is justified philosophically, hence we are restricted to what the philosophers consider the most up to date version.

conclude that until progress has been made on 2., there is no hope for practical application of IIT
