


\section{Introduction}
Within any organisation, no matter what the type, communication must be present. If members of a company don't communicate, then there is no way for a worker to know what they should be doing, or if what they are doing is actually important to the company. At the same time, if all members of an organisation are talking to each other there this may get in the way of actual work being done, as well as giving rise to redundant communication. We seek a way to model this phenomenon, and hence improve the efficiency of an organisation.

The approach taken in this project is inspired by the brain. The human brain consists of billions of neurons, which are constantly communication and hence passing information around the body. From comparing the human brain to that of animals, we see the decision making potential of the brain is not only related to its size, but also its internal structure. Philosophically, we identify consciousness as one of the 


\section{Integrated Information Theory}

In this section, we present an overview of Integrated Information Theory as presented by Oizumi et all \cite{oizumi2014phenomenology} using a combination of their notation as well as that of Krohn and Ostwald \cite{krohn2016computing}.

\subsection{Definitions and Notation}

Integrated Information Theory introduces a function $\Phi$ which measures the integrated information of a discrete time multivariate stochastic process. We write:

\begin{equation}
\label{def:1}
Z_t = \left(\begin{array}{cccc} z^1_t&z^2_t&\ldots&z^n_t\end{array}\right)
\end{equation}

to represent the multivariate random variable, where $z^i_t \in \{0,1\} \quad\forall i, t$. This stochastic process can be related to a graph containing $n = |Z_t|$ nodes. Each node refers to one of the $z^i$'s and can be in one of two states: `off' at time $t$ if $z^i_t=0$ and `on' if $z^i_t = 1$. We join $z^i$ to $z^j$ with a directed edge if the future state of $z^i$ depends in some way on $z^j$. From now on, we will refer to the $z^i$'s as `nodes'.

Before we proceed, we need to specify what is meant by the terms \textit{mechanism} and \textit{system of mechanism}.

\begin{figure}[ht]
	\centering
	
	\includegraphics[scale = 0.12]{IITexplanationdiagram1.png}
	\caption{In this illustration, we identify the mechanism $CD$ by circling it in red. The system of mechanisms in consideration is similarly circled in green. Finally, all nodes lying outside of the system are considered to be external inputs/outputs.}
	\label{fig:IIT_illustration1}
\end{figure}


\begin{definition}{A \textit{mechanism} refers to any non-empty set of nodes. The \textit{order} of a mechanism refers to the size of the set. A mechanism is \textit{elementary} if it is of order 1.}
\end{definition}

\begin{definition}{A \textit{system of mechanisms} is a set of mechanisms. The elements of this set may have non-empty intersections.}
\end{definition}


Just as each node can be in one of two states, so too can mechanisms and systems be in states. The state of a mechanism is the combination of the states of all nodes within it. For example, if we have $z^1=1$, $z^2=0$ and $z^3=0$, than the mechanism $Z = \left(\begin{array}{ccc}z^1&z^2&z^3\end{array}\right)$ has state $\left(\begin{array}{ccc}1&0&0\end{array}\right)$. 


The progression of $Z_t$ as time passes is dictated by the transition probability matrix (TPM) $\mathbf{M}$, which gives at $M_{ij}$ the probability of transitioning from state $i$ to state $j$ after a single time step. There are 3 points in time for which we consider a mechanism: the immediate past (time $t-1$), present (time $t$) and future (time $t+1$). Oizumi et all \cite{oizumi2014phenomenology} denote the state of a mechanism at these times by $Z^c$, $Z^p$ and $Z^f$ referring to the current, past and future states respectively. Alternatively, Krohn and Ostwald \cite{krohn2016computing} write $Z_{t-1}$, $Z_{t}$, and $Z_{t+1}$. In this document, we adopt the latter style.


\begin{definition}
	{Let $Z$ be a mechanism with $W\subset Z$, and suppose that the current state of $W$ is known, that is: $W_t = X$. Then the \textit{effect repertoire} of the state $W_t = X$ is the conditional probability distribution for the future states of $Z$ given our current knowledge. We write it as $p_e(Z_{t+1}|W_t=X)$. Similarly the \textit{cause repertoire} of the state $W_t = X$ is the conditional probability distribution for past states of $Z$ given our current knowledge. We write it as $p_c(Z_{t-1}|W_t = X)$.}
\end{definition}


\subsection{Computation of Repertoires}
In this section, we construct each of the previously defined repertoires from the TPM. First however, we need to introduce both the \textit{perturb function}, and the assumption of conditional independence, as all future definitions rely on these.

\begin{definition}
	{Let $S$ be a set such that $|S| = n$, and its elements are indexed by $s_1, s_2, \ldots, s_n$. Further let $f$ be a function which operates on the elements of $S$. Then we write the perturbation function as:
	\[per(f(a, S), S) = \left(\begin{array}{cccc}f(a,s_1)&f(a,s_2)&\ldots&f(a,s_n) \end{array}\right)^T\]
	That is, the perturbation function returns a vector where each of its entries corresponds to the $f$ taking a different input from $S$.}
\end{definition} 

\subsubsection{Conditional Independence}
\label{sec:conditional_independence}
In order to simplify all computations, IIT makes a large mathematical assumption. Specifically it assumes that the probability distributions for the future states of each node are conditionally independent with respect to the previous state of the system. i.e. if $Z$ is a mechanism, then:

\begin{equation}
\label{eq:cond_independence}
p(Z_{t+1}|Z_t = X) = \prod \limits_{i=1}^{n} p(z^i_{t+1}|Z_t=X)
\end{equation}

This assumption allows us to simplify the $2^n \times 2^n $ \textit{state by state} transition probability matrix $\mathbf{M}$ into the $2^n \times n$ \textit{state by node} transition probability matrix $\mathbf{T}$. As is, each row of $\mathbf{M}$ is a distribution containing the probabilities that any of $2^{|Z|}$ possible future state may be transitioned to. We replace this row with the values of $p(z^j_{t+1}=1|Z_t=X)$ where $j$ is a column index. Equation \ref{eq:cond_independence}, along with the fact that: \[p(z^i_{t+1}=1|Z_t=X)+p(z^i_{t+1} =0|Z_t=X) =1\]
allows this smaller row of only $n$ values to uniquely specify the larger row of length $2^n$.


\subsubsection{Effect repertoire}

Let $Z$ be a mechanism, and suppose that the state of the subset $W \subset X$ is known: $W_t = X$. Then we first define the \textit{effect repertoire} to have the property of factorisation, that is:

\begin{equation}
\label{def:controversial}
p_e(Z_{t+1}|W_t = X) = \prod \limits_{i= 1}^n p(z^i_{t+1}|W_t = X)
\end{equation}

It is important to note that this factorisation does not follow generally from equation \ref{eq:cond_independence}, as it was only assumed that future state of each node was conditionally independent with respect to the current states of the entire system, as opposed to with respect to all possible subsets of this system as well.

This is justified by Oizumi et all \cite{oizumi2014phenomenology} in their supplementary methods document on the grounds that they are interested in how $W_t=X$ affects each $z^i_{t+1}$ individually and thus factorise as above in order to remove correlations.


Finally, let $W$ be a subset of $Z$ which is known, and let $z^{i_0}$ be a particular node in $Z$. Then we have:
\begin{equation}
\label{def:effect_repertoire}
p_e(z_{t+1}^{i_0}|W_t = X) = 2^{-|Z\setminus W|}\sum \limits_{Z\setminus W} p(z_{t+1}^{i_0}|W_t = X, Z\setminus W)
\end{equation}

This is equivalent to averaging over all rows of the TPM which corresponds to states of $Z_t$ such that $Z_t \supset W_t = X$.

Hence, the generator \textit{unconstrained effect repertoire} $p(Z_t | \emptyset)$ is s

\subsubsection{Cause repertoire}

Just as the effect repertoire is broken into a smaller problem in equation \ref{def:controversial}, there exists an equivalent simplification for computing the cause repertoire. Let the state of $W \subset Z$ be known,$m:=|W|$, and $V$ be any other subset of $Z$. Then 

\begin{equation}
\label{def:cause_rep1}
p_c(V_{t-1} | W_t=X) = \prod \limits_{i = 1}^{m} p_c(V_{t-1}|w^i_{t} = x^i)
\end{equation}

We then complete the computation as follows:

\begin{equation}
\label{def:cause_rep2}
p_c(V_{t-1}| w_t = x) = \frac{\sum \limits_{Z\setminus V} p_e(w_t = x| V_{t-1}, Z \setminus V)}{p(w_t = x)}
\end{equation}

In short, we add up the probabilities of each individual previous state resulting in our current information ($w_t = x)$, and then scale by the overall probability that we observe $w_t = x$ in the first place. Note that equation \ref{def:cause_rep2} features the effect repertoire $p_e$ on the right hand side, not $p_c$.

\begin{remark}
	Equation \ref{def:cause_rep1} does not make an additional assumption, but rather follows as a consequence from equation \ref{def:controversial}.
\end{remark}



\subsection{The earth mover's distance (EMD)}
In the context of this document, we will frequently calculate the distance between two probability distributions $p1$ and $p1$. For this we will use the mathematical notation $D(p1,p2)$, where $D$ is referring to the earth mover's distance.

To use this distance measure, we require the existence of another metric which measures the distance between any pair of states. Here we use the Hamming distance for this purpose, that is the number of individual bytes which disagree when comparing two states. (i.e. the hamming distance between 001 and 101 is 1, as the have 1 disagreement in the first digit)

In simple terms, if we think of each distribution as piles of dirt on top of each given state. The earth mover's distance is the product of how much dirt needs to moved by how far this dirt needs to go. 

\begin{description}
	\item[EMD between Probability Distributions] Let $S$ be a set of $n$ states, $\mathbf{D} = \left[ D_{ij}\right]$ where $D_{ij}$ is the distance between $s_i$ and $s_j$, $P$ and $Q$ be two probability distributions over $S$ such that $P(X = s_i) = p_i$ and $Q(X=s_j) = q_j$, $\forall i,j$. 
	
	Calculate $\mathbf{F} = \left[F_{ij}\right]$ matrix which optimises the following problem:
	
	\begin{align}
	\label{eq:EMD1}
	\min \limits_{\mathbf{F}}\sum \limits_{i,j=1}^n &F_{ij} D_{ij}\quad \text{subject to}\\
	&F_{ij}\geq 0,\quad \forall 1 \leq i,j \leq n\\
	\sum \limits_{j=1}^n &F_{ij} = p_i,\quad 1 \leq i \leq n\\
	\sum \limits_{i=1}^n &F_{ij} = q_j,\quad 1 \leq j \leq n
	\end{align}
	
	Finally, we say: 
	
	\begin{equation}
	\label{def:EMD}
	\text{EMD}(P, Q) = \sum \limits_{i,j=1}^{n} F_{ij} D_{ij}
	\end{equation}
\end{description}

From now on, we'll use the notation $D(P,Q)$ to denote the earth mover's distance instead of bothering with $\text{EMD}(P,Q)$ each time.

\subsection{Calculations for mechanisms}\label{sec:little_phi}
When making a computation for a mechanism, we must be sure to treat each type of node appropriately. Let $G$ be the set of all nodes present, $Z$ be the system of nodes which we are considering, and $W$ the mechanism within the system. For an illustration of this, consider figure \ref{fig:IIT_illustration1}.

For all nodes in $G\setminus Z$, that is the external inputs/outputs, we treat their states as constant. We do not concern ourselves with their past or future states when computing repertoires. However, the state of these nodes may affect the nodes within the mechanism $W$.

In contrast, the state of nodes within $Z \setminus W$ are treated as unknown. While they do affect past and future repertoires, the do so differently than nodes within the mechanism. Finally, we are concerned with how the state of the mechanism constrains the past and future states of these nodes.

\subsubsection{cause-effect information}
The cause-effect information ($cei$) is a measurement of the significance which a piece of information has. It is calculated in 2 parts. First we have the cause information ($ci$), which measures how the past can be constrained given knowledge of the present. It is defined by:

\begin{equation}
\label{def:ci}
ci(W_{t} = X) = D\left(p_c(Z_{t-1}|W_{t} = X)||p_c(Z_{t-1}|\emptyset)\right)
\end{equation}


Next we have the effect information ($ei$), which measures how the future is constrained given knowledge of the present. We define it as:
\begin{equation}
\label{def:ei}
ei(W_{t} = X) = D\left(p_e(Z_{t+1}|W_{t} = X)||p_{e}(Z_{t+1}|\emptyset)\right)
\end{equation}

Finally, we define the cause-effect information ($cei$) to be the minimum between the cause information and effect information:

\begin{equation}
\label{def:cei}
cei(W_{t} = X) = \min\left(ci(W_{t} = X), ei(W_{t} = X) \right)
\end{equation}

\subsubsection{integrated information}
\label{sec:mech_integration}
IIT assumes that only information which is irreducible can contribute to consciousness. This motivates the calculation of $\varphi$, which calculates the distance between the cause-effect repertoires of an entire mechanism, and the cause-effect repertoires of the partitioned mechanism. 

Intuitively, if a mechanism can be split into parts and these smaller mechanisms generate the same result, then the mechanism is reducible and $\varphi=0$. In contrast, the larger $\varphi$ is, the more information the mechanism has beyond the sum of its parts.

As addition to $Z$ and $W$, we introduce the sets $N \in \mathbb{P}(W)$ and $M \in \mathbb{P}(Z)$.

\begin{equation}
\label{def:preMIP}
p_c(A_{t-1}|B_t ,M, N):= p(N_{t-1}|M_t) p(A_{t-1} \backslash N_{t-1} |B_t \backslash M_t)
\end{equation}

Then we define:

\begin{equation}
\label{def:phi2}
\varphi_{cause}^{M,N}(W_t=X, Z) := D \left( p_c(Z_{t-1}|W_t=X) ,p(Z_{t-1}|W_{t} = X,M,N)  \right)
\end{equation}.

With the benefit of this notation, we now introduce the notion of the minimum information partition (MIP). Specifically, the MIP refers to the sets $M'$ and $N'$ which minimise $\varphi_{cause}$. We then have:

\begin{equation}
\label{def:phi3}
\varphi_{cause}^{\text{MIP}}(W_t=X, Z)  = \varphi_{cause}^{M',N'}(W_t=X, Z) 
\end{equation}

$\varphi^{\text{MIP}}_{effect}$ is defined similarly. One need only swap $p_c$ for $p_e$ superscript. This allows us to define integrated information $\varphi$:
\begin{equation}
\label{def:phi}
\varphi^{\text{MIP}}(W_t=X, Z) = \min \left( \varphi_{cause}^{\text{MIP}}(W_t=X, Z), \varphi_{effect}^{\text{MIP}}(W_t=X, Z)  \right) 
\end{equation}



It is useful to recognise the relation between $\varphi^{\text{MIP}}$ and $cei$. Specifically we have following result which was established by Marshall et all \cite{marshal2016integrated}:
\begin{equation}
\label{eq:bound_phi_cei}
\varphi^{\text{MIP}}(W_t=X, Z) \leq cei(W_t=X) 
\end{equation}

This implies that the biggest different we can make to $\varphi$ by partitioning a mechanism occurs when the partitioned repertoire is precisely the unconstrained repertoire. 



\subsubsection{maximally integrated information}
It follows from the assumptions of IIT that a mechanism has a unique cause and effect. We identify these as the maximally irreducible causes and effects respectively. 

Let $W_t = X$. We now ask the question: what is the cause of $X$? Any element in $\mathbb{P}(Z)$ is a candidate, so we need to conduct an exhaustive search. Hence we define $\varphi^{\text{Max}}$, the maximally integrated information as: 
\begin{equation}
\label{def:core_cause}
\varphi^{\text{Max}}_{\text{cause}}(W_t = X):=\max \limits_{S \in \mathbb{P}(Z)}\varphi^{\text{MIP}}_{\text{cause}}(W_t = X|S)
\end{equation}

The particular set $S'$ which maximised the right hand side we call the \textit{core cause}. The \textit{core effect} and $\varphi^{\text{Max}}_{\text{effect}}$ are defined in the equivalent fashion. Finally we finish  by setting $\varphi^{\text{Max}}$ to be the minimum of the two as before. It is important to note that we find the core cause and effect separately, and that these need not be the same set.

As with $\varphi^{\text{MIP}}$ we can bound $\varphi^{\text{Max}}$. Specifically we have for any current state $X$ that:

\begin{equation}
\label{eq:bound_phimax}
\varphi^{\text{MIP}}(W_t = X, Z) \leq \varphi^{\text{Max}}(W_t = X)\leq cei(W_t = X)
\end{equation}

If we find that $\varphi^{\text{Max}}(W_t = X)>0$, then we call the combination of $\varphi^{\text{Max}}(W_t = X)$ with its core cause and effect a \textit{concept}. This allows us to define a MICE.

\begin{definition}
	{The maximally integrated cause effect repertoire of a piece of information, or MICE, refers to the combination of the cause repertoire $p_c(C_{t-1}|W_t = X)$, where $C$ is the core cause of $W_t=X$ along with the effect repertoire $p_e(E_{t+1}|W_t = X)$, where $E$ is the core effect of $W_t = X$.}
\end{definition}

\subsection{Calculations for systems of mechanisms}
Thus far calculations have been restricted to a single mechanism, whether 1st, 2nd, or $n$th order. However, a network of more than one node may contain multiple mechanisms, which may overlap with each other. For example, a system of 3 nodes could potentially contain 7 mechanisms (all possible subsets of nodes less the empty set).

Now we focus our attention on computing integrated information in a system of mechanisms. 

\subsubsection{conceptual information}
\label{sec:CI}
The Conceptual Information (CI) extends the notion of cause-effect information to a system of nodes. Before we computed the distance between the repertoire specified by some information and the unconstrained repertoire. Now, instead of computing the distance between repertoires, we add up the distances between concepts.

The Conceptual Information is simply weighted sum of the distance between the MICE of each of its concepts, and the unconstrained MICE. We compute it below:

\begin{equation}
\label{def:CI}
CI(Z_t = X) = \sum \limits_{S \in \mathbb{P}(Z)} \varphi^{\text{Max}}(S_t=X) D(M^S, M^{uc})
\end{equation}

where $M^S$ refers to the MICE of the concept $S$, and $M^{uc}$ is the unconstrained MICE, which is just the unconstrained cause and effect repertoires. We measure the distance between $M^S$ and $M^{uc}$ by adding the distances between the two cause, and effect repertoires.

\begin{remark}
	Equation \ref{def:CI} uses Oizumi et all's \cite{oizumi2014phenomenology} definition of $CI$. However, it was pointed out by Krohn and Ostwald \cite{krohn2016computing} that this definition is not well defined. The MICE is defined as the set of cause and effect repertoires that maximize $\phi^{MIP}$. However, there may be two such MICE's: $M_1$ and $M_2$, which yield the same value for $\phi^{Max}$, and yet affect equation \ref{def:CI} differently. We show equation \ref{def:CI} as we used the software provided by Mayner et all \cite{pyphi} which follows the flawed definition. Krohn and Ostwald propose a simpler definition which fixes this issue, where they merely add up the values of $\varphi^{\text{Max}}$, and ignore the MICE.
\end{remark}

\subsubsection{integrated conceptual information}
Now we measure the integration of a piece of information on the level of a system of mechanisms. Here it is useful to define the term \textit{constellation}.

\begin{definition}
	{A \textit{constellation} refers to the set of all concepts within a system, each concept equipped with its' MICE.}
\end{definition}

As before, we consider all ways to partition the system $Z$. However, on this occasions, each partition is a one directional cut. Hence there exist twice as many possible partitions as in section \ref{sec:mech_integration}. We compute the constellation for the partitioned system, labelling it as $M^p$. For this partitioned system, some of the concepts from the while system will remain intact, but others will have been destroyed by the partition.

Let the function $C(P)$ refer to the set of concepts, given the partition $P$. Then we define:

\begin{equation}
\label{def:Phi_integration1}
\Phi^P(Z_t = X) = \sum \limits_{S \in (Z \setminus C(p))} \varphi^{\text{Max}}(S_t = X)D(M^S, M^{uc})
\end{equation}

The difference between $\Phi^P$ and $CI$ is that while in $CI$ we sum over all concepts, in $\Phi^P$ we only sum over the concepts which have been destroyed by the partition.

As before we seek the minimum information partition (MIP). This time we define it as:

\begin{equation}
\label{def:Phi_integration2}
\Phi^{\text{MIP}} (Z_t = X) = \min \limits_{P} \Phi^P(Z_t = X)
\end{equation}

\begin{remark}
	As in section \ref{sec:CI}, the value specified in equation \ref{def:Phi_integration2} is not defined, for the same reason as previously. Krohn and Ostwald present the same solution as before: they remove the $D(M^S, M^{uc})$ term from the equation, leaving only the $\varphi^{\text{Max}}$ terms.
\end{remark}

\subsubsection{maximally irreducible conceptual structure}

Thus far in how $\Phi$ is defined, there exists an intuitive example which breaks the definition. Consider a network consisting of a dense cluster of nodes which has a large value of $\Phi$. Next, add a single node to this cluster, which we connect to the cluster with a single edge. If we compute $\Phi$ now, find a partition which makes almost no difference at all (when we eliminate the single node), which results in the new system having a small $\Phi$ value. 

Intuitively we understand that the conclusion: `adding a single extra neuron to the brain destroys all consciousness' is ridiculous. Hence we need the value $\Phi^{\text{Max}}$ to finish our definition of Integrated Information Theory. We define:

\begin{equation}
\label{def:Phimax}
\Phi^{\text{Max}}(Z_t = X) := \max \limits_{W \in \mathbb{P}(Z)}\Phi^{\text{MIP}} (W_t = X)
\end{equation}

\begin{remark}
	When we compute $\Phi^{\text{MIP}} $ for all subsets $W$ of $Z$, we are not computing it over the \textit{mechanism} $W$ but rather over the \textit{system} $W$. This means that all nodes in $Z \setminus W$ are now treated as external inputs/outputs, instead of unknown nodes in system.
\end{remark}

\subsection{Computational cost}
We now ask how expensive is the computation of $\Phi^{Max}$. Let $Z$ refer to a system of nodes such that $|Z| = n$.

\begin{enumerate}
	\item To compute $\Phi^{\text{Max}}$, we must calculate $\Phi$ for possible subsets of our system. There are at most $2^n$ such subsets, and hence we must compute $\Phi$ this many times.
	\item For a particular subset of consideration, we must determine the Minimum information partition of one directional cuts. If the subset is of size $m$, then there at most $2^{m+1}$ ways to do this (if the connectivity matrix is sparse, then there are considerably less). $m$ itself is bounded by $n$, so we say that this step must occur at most $2^{n+1}$ times.
	\item Each computation of $\Phi$ for a particular partition requires the calculation of all values of $\varphi^{\text{Max}}$. As each element of the power set may have a positive value of such, we must carry out this computation up to $2^n$ times.
	\item Each computation of $\varphi^{\text{Max}}$ requires both the core cause and core effect to be identified. This involves calculation $\varphi^{\text{MIP}}_{cause}$ and $\varphi^{\text{MIP}}_{effect}$ each over the entire power set, resulting in a further $2^{n+1}$ computations.  
	\item To compute $\phi_{cause}^{\text{MIP}}$, we must search over all possible partitions. There are $2^n$ of these.
	\item Finally, when measuring the difference made by a partition, we must measure the distance between probability distributions. This is done using the Earth Mover's Distance, which scales $O(N^3 \log N)$, where $N$ is the number of states found in the distributions the distance is being measured between. As there are $2^n$ of these, this step scales with $O(2^{3n} (\log n)^3)$
\end{enumerate}

When we put this all together, we conclude that the calculation of $\Phi^{Max}$ scales with $O( 2^{8n}(\log n)^3)$.


\section{Modelling an Organisation}

In this section, we seek to model communication flow within an organisation. To do this, the first step is to specify the type of organisation that we're referring to. 

\begin{enumerate}
	\item The organisation is a company which generates revenue by completing projects.
	
	\item Each project requires the application of certain skills in order to be completed.
	
	\item The organisation consists of a fixed number of teams, each possessing one or more skill.
	
	\item Projects are completed by assigning sufficiently many teams to the project which possess all skills required to complete the project.
\end{enumerate} 

Within this framework, where does communication come in? Suppose that a project appears which requires python programming skills. Further, let there be 2 distinct teams which have this skill. What happens now? If these teams are not communicating, then they might both take on the same project, depending on the policy by which they decide what to do. Alternatively, if they are communication, not only can they guarantee that they don't do the same thing, but they can also collaborate with each other, thus finishing the project faster than otherwise.

Suppose we have $n$ teams. We represent these teams in mathematics as nodes in a graph. Each of these nodes has 2 states: `on' and `off'. A team is active if its node is `on', and is idle if the node is `off'. Next we say that one team $v_1$ is paying attention to another team $v_2$ if there exists a directed edge from $v_1$ to $v_2$. Furthermore, these teams are said to be communicating both teams are paying attention to each other.

With this structure defined, we now need to consider how to build dynamics into the model. In particular we must define the following:

\begin{itemize}
	\item Progression of time. We take our model to be a discrete iterative process. Each iteration marks the passage of a fixed time period. 

	\item Arrival of Projects. We model projects such that with each time step, a single project might arrive. The nature of the project which arrives we determine using a multivariate Bernoulli distribution.
	
	\item Completion of Projects. We arbitrarily decide that the duration of a project will be distributed exponentially. This is equivalent to saying that each project has an identical chance of completion following each iteration.
\end{itemize}


\subsection{The small 3-node model}
In this model, we consider there to be 3 teams, and 2 skill types. We label the teams as $A$, $B$ and $C$, and the skill types as $\alpha$ and $\beta$. We decide arbitrarily that teams $A$ and $C$ have skill $\alpha$, while teams $B$ and $C$ have skill $\beta$. This arrangement is illustrated in figure \ref{fig:diagram1}.

\begin{figure}[ht]
	\centering

	\includegraphics[]{ModelDiagram.png}
	\caption{We have 3 types of nodes: skill types ($\alpha$ and $\beta$), teams ($A$, $B$ and $C$), and incoming project alerts ($P_\alpha$ and $P_\beta$). If a team node is joined to a skill node by an edge, then the team possesses that skill. All of the teams have one way connections with the incoming project alerts nodes because the teams respective state do not effect incoming projects' state, but are effected by them.}
	\label{fig:diagram1}
\end{figure}

With the teams, skills and assignment of these defined, we specify the details of the model dynamics in the following three steps.

\begin{steps}
	
	\item \textbf{Arrival of projects}\\
	Earlier we stated that this process was based on a multivariate Bernoulli distribution. Specifically we use the 2-dimensional version, as we are working with 2 types of skills. We specify the vector of probabilities: $\mathbf{p} = (p_\alpha, p_\beta)$ such that an incoming project requires skill $\alpha$ with probability $p_\alpha$ and similarly for skill $\beta$.
	
	We create 2 `incoming project alert' nodes which we label as $P_\alpha$ and $P_\beta$. The state of these nodes is determined only by the previously mentioned probability distribution. Hence these nodes transition states independently of any other node. 
	
	\item \textbf{Assignment of projects}\\
	First are the 3 simple cases. If a project which requires skill $\alpha$ but not $\beta$ arrives, and team $A$ is idle, then the project is assigned to $A$, resulting in team $A$ turning on. Similarly teams $B$ and $C$ will turn on if a project arrives tailored to their abilities while they are not already active.	
	
	2 more cases exist: If a project suitable for team $A$ arrives while $A$ is busy and $C$ is idle, then $C$ will be assigned $A$'s task. The same will apply if $B$ is busy when such a project arrives. Finally, if a project requiring both skills arrives while $C$ is busy while $A$ and $B$ are both idle, then $A$ and $B$ will be assigned the project, resulting in both of them transitioning to a state of `on'.
	
	\item \textbf{Completion of projects}\\
	We already stated the time required to complete a project to be modelled by th exponential distribution. This was so we could use a simple Bernoulli process to determine when a project is completed. This means that the probability of completing a project is constant w.r.t. time. However, to make this process more realistic, we decide that the probability of completing a project will not be independent of active working connections.
	
	We define the parameters $k_A$, $k_B$ and $k_C$ to represent the effectiveness of each team. If $A$ is active, then it will complete its task with probability $k_A$ after each time-step, and so on. 
	
	However, when teams are working on similar tasks, then collaboration occurs. Specifically, if teams $A$ and $C$ are both active, since skill $\alpha$ is required for both projects, $C$ will assist $A$. However, as $C$'s project also involved skill $\beta$, $A$ will be unable to return the assistance. In this case, $A$ will finish its task after the next time-step with probability $k_A + k_B$, which for $C$ things are unchanged. 
	
	$C$ can only receive assistance when all teams are active, since together $A$ and $B$ account for all required skills. In this final case, $C$ will complete its task with probability $k_A+k_B+k_C$.
\end{steps}


Now we can put this all together to form the state by node transition probability matrix: $\mathbf{T}$, defined as:
\begin{equation}
\mathbf{T}_{ij}= P(z^j_{t+1}=1 | Z_t = i)
\end{equation}

where $Z$ refers to the entire network with $z^j$ standing for $A$, $B$, and $C$ (the team nodes) in addition to $P_\alpha$ and $P_\beta$, (the incoming project alert nodes) for $j=1,2, \ldots, 5$. $\mathbf{T}$ is the \textit{state by node} transition probability matrix, as previous described in section \ref{sec:conditional_independence} having 32 rows and 5 columns. We present this matrix in table \ref{mat:simple_system}.


\begin{table}[h!]
	\centering
	$
	\begin{array}{|l|ccccc}
		\hline
		\multicolumn{1}{|r|}{\text{State}} & \multicolumn{1}{c|}{A} & \multicolumn{1}{c|}{B} & \multicolumn{1}{c|}{C} & \multicolumn{1}{c|}{P_\alpha} & \multicolumn{1}{c|}{P_\beta} \\ \hline
		000 00                      & 0                      & 0                      & 0                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		100 00                      & 1-k_A                 & 0                      & 0                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		010 00                      & 0                      & 1-k_B                 & 0                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		110 00                      & 1-k_A                 & 1-k_B                 & 0                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		001 00                      & 0                      & 0                      & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		101 00                      & 1-k_A-k_C            & 0                      & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		011 00                      & 0                      & 1-k_B-k_C            & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		111 00                      & 1-k_A-k_C            & 1-k_B-k_C            & 1-k_A-k_B-k_C       & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		000 10                      & 1                      & 0                      & 0                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		100 10                      & 1-k_A                 & 0                      & 1                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		010 10                      & 1                      & 1-k_B                 & 0                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		110 10                      & 1-k_A                 & 1-k_B                 & 1                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		001 10                      & 1                      & 0                      & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		101 10                      & 1-k_A-k_C            & 0                      & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		011 10                      & 1                      & 1-k_B-k_C            & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		111 10                      & 1-k_A-k_C            & 1-k_B-k_C            & 1-k_A-k_B-k_C       & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		000 01                      & 0                      & 1                      & 0                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		100 01                      & 1-k_A                 & 1                      & 0                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		010 01                      & 0                      & 1-k_B                 & 1                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		110 01                      & 1-k_A                 & 1-k_B                 & 1                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		001 01                      & 0                      & 1                      & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		101 01                      & 1-k_A-k_C            & 1                      & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		011 01                      & 0                      & 1-k_B-k_C            & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		111 01                      & 1-k_A-k_C            & 1-k_B-k_C            & 1-k_A-k_B-k_C       & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		000 11                      & 0                      & 0                      & 1                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		100 11                      & 1-k_A                 & 0                      & 1                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		010 11                      & 0                      & 1-k_B                 & 1                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		110 11                      & 1-k_A                 & 1-k_B                 & 1                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		001 11                      & 1                      & 1                      & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		101 11                      & 1-k_A-k_C            & 0                      & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		011 11                      & 0                      & 1-k_B-k_C            & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		111 11                      & 1-k_A - k_C          & 1-k_B-k_C            & 1-k_A-k_B-k_C       & p_\alpha                      & p_\beta                      \\ \cline{1-1}
	\end{array}
	$
	\caption{Above is the Transition Probability Matrix for the small 3-node model. We represent each state of the system as a length 5 binary string, where the 1's and 0's refer to `on' and `off' respectively. We list nodes in the order: $A, B, C, P_\alpha, P_\beta$. Hence, 10010 means that nodes $A$ and $P_\alpha$ are active, while the rest are idle.}
	\label{mat:simple_system}
\end{table}



Finally, for this model to be interesting, we need to have some control over the parameters. For this, we think of $k_A$, $k_B$ and $k_C$ of being directly related to the funding invested in each team. Hence we assume $k_A+k_B+k_C = K$, where $K$ is a constant which refers to the total amount of funding at the organisations disposal. $k_i$'s refer to how we allocate that funding.

When solving for this model, we will employ two methods: IIT and a classical approach. For IIT, we will compute the value of $\Phi$, while for the classical approach, we instead will introduce the notion of costs, and from this compute the economic performance with respect to the parameters $k_A$, $k_B$ and $k_C$. 

\subsubsection{Classical Approach to solving the model}
Currently in our model a project will definitely be completed, the question is how long it will take. Thus we don't have to worry about the cost of failed projects. Instead, we concern ourselves with the value of missed projects: those which arrive when there is no suitable team or combination of team available to be assigned to it. Define $W_A$, $W_B$ and $W_C$ to be the waste incurred when a project requiring skills $\alpha$, $\beta$ and both  is missed respectively.

When does this waste happen? Look back at table \ref{mat:model1}. Based on how we've define the allocation process, the only states at which waste can occur are: $10110$, $11110$, $01101$, $11101$, $10111$, $01111$ and $11111$. If the last two digits of the state is $10$, then a project requiring skill $\alpha$ is lost, resulting in waste of $W_A$. $01$ means that a project needing skill $\beta$ is lost, resulting in waste of $W_C$. The rest refer to a project needing both skills, for which the waste is $W_C$. In short, waste results from exactly 7 different states, and can be either $W_A$, $W_B$ or $W_C$.

So we know how much money we expect to waste for each state. Now the question is: how often do we expect to be at each state? We can take two approaches: either we can simulate the system and compute waste from the time series, or else we can compute the expected waste per iteration by finding the stationary distribution of the system. We take the latter approach.

When the values of $k_i \in (0,1)$, then the $32\times32$ state by state transition probability matrix $\mathbf{M}$ will have an eigenvalue of 1 with geometric multiplicity 1. Furthermore, $-1$ will not be an eigenvalue. Hence the left eigenvector with eigenvalue 1 will the be stationary distribution of the system, which precisely describes the long term behaviour of the system. 

Hence our cost function is:
\begin{equation}
\label{eq:simple_model_cost_function}
f(k_A, k_B, k_C) = \mathbf{q}(W_A, W_B, W_C) \cdot \mathbf{v}(k_A, k_B, k_C, p_\alpha, p_\beta)
\end{equation}

where $\mathbf{v}$ is the stationary distribution of the system, which depends on $k_A$, $k_B$, $k_C$, $p_\alpha$ and $p_\beta$ while $\mathbf{q}$ is a vector which contains the cost of each state hence depending on $W_A$, $W_B$ and $W_C$. In short, given the 5 constants: $p_\alpha$, $p_\beta$, $W_A$, $W_B$ and $W_C$, we can express cost as a function of $k_A$, $k_B$ and $k_C$. 

\subsubsection{IIT Solution}

In this section we compare the results of IIT with the expected waste of the network. $\Phi$ depends on the matrix $\mathbf{M}$ and the initial state. However, we would prefer to have a function which is independent of state like our cost function. Thus, just as we computed cost in equation \ref{eq:simple_model_cost_function} by taking the inner project of the cost vector with the stationary distribution, we take a similar approach here.
Define $\mathbf{\Phi}$ the length $2^n$ vector containing the values of $\Phi$ at each state of the system. Using this, we compute:

\begin{equation}
\mathbb{E}[\Phi]:= \mathbf{\Phi}\cdot \mathbf{v}(k_A, k_B, k_C, p_\alpha, p_\beta)
\end{equation}

Using $\mathbb{E}[\Phi]$ instead of $\Phi$ given a particular state makes sense intuitively. Suppose $\Phi$ measured in some what the quality of the project allocation process at a particular step. Then its is possible that the reason it was a good step was because it will create opportunities in the future by taking on costs in the present. Thus we would be more interested in the average value of $\Phi$ if it were to have this meaning, which is what we hope.

Finally we compare $\mathbb{E}[\Phi]$ against expected waste. We arbitrarily choose $p_\alpha$ and $p_\beta$ to both be $0.5$, while we pick $W_A=0.3$, $W_B = 0.5$ and $W_C = 0.2$. Finally we set $K = k_A+k_B+k_C = 0.5$, and vary the parameters according to this constraint. We present our results in figure \ref{fig:simple_model_phi_cost_plot}.

\begin{figure}[h!]
	\centering
	\includegraphics[scale = 0.5]{phicostplot.pdf}
	\caption{We present a scatter-plot of the values for $\mathbf{E}[\Phi]$ and expected waste, when we vary the parameters $k_A, k_B$ and $k_C$ subject to $k_A+k_B+k_B=1/2$.}
	\label{fig:simple_model_phi_cost_plot}
\end{figure}



\begin{enumerate}
	\item What $\Phi$ computes is the difference in information that a system has, above an beyond what it would have if the system was partitioned. As things stand, our model is a fully connected 3 node system. Thus we can't expect interesting $\Phi$ behaviour, as there are no partitions which might radically affect our network. 

	\item The mechanism we defined for allocation of projects is one which assumes perfect knowledge and communication. We never have a scenario in which two teams work on the same thing unnecessarily, or one team neglects working on a project becomes it assumes that another team is. These events are far more indicative of waste, then what was measured previously. 

\end{enumerate}

Motivated by these observations, we proceed to the next model.



\subsection{A two cluster model}

The purpose of this next model is to deliberately allow scenarios where realistic miscommunication might occur which results in waste. The question of interest is whether $\Phi$ can measure such miscommunication.

We extend the previous model as follows: 
\begin{enumerate}
	\item Now we take there to be 3 skills: $\alpha, \beta$ and $\gamma$.
	
	\item As before we have nodes $A$, $B$ and $C$ which interact in the same way as previously. In addition, we include the nodes $D$ and $E$. $D$ is equipped with skills $\alpha$ and $\gamma$, while $E$ has skills $\beta$ and $\gamma$. 
\end{enumerate}

We illustrate the new system in the following figure \ref{fig:diagram2}.
\begin{figure}[ht]
	\centering	
	\includegraphics[]{Model2Diagram.png}
	\caption{We have 3 types of nodes: skill types ($\alpha$, $\beta$, and $\gamma$), teams ($A$, $B$, $C$, $D$ and $E$), and incoming project alerts ($P_\alpha$, $P_\beta$ and $P_\gamma$). If a team node is joined to a skill node by an edge, then the team possesses that skill. The teams receive inputs from the incoming project alert nodes, but the dependence is strictly one directional.
	Certain teams are connected, indicating that they are actively communicating with each other so to distribute work efficiently. Note that in this figure, we have 2 disconnected clusters of teams. This will give rise to waste.}
	\label{fig:diagram2}
\end{figure}

In the previous model, we constructed the TPM from a global perspective. This was valid since all the teams involved were in communication. For this model, we use the following policy to determined whether or not a node decides  to take on a project. In decreasing order of importance, we aim to:


\begin{enumerate}
	\item allocate the project if it is possible to do so.
	\item minimize the amount of teams needed to work on the project.
	\item minimize the amount of excess skills possessed by the team/teams assigned to the project.
\end{enumerate}

When applying this policy, we must do it from the perspective of each individual team. This means that if a team is disconnected from all other teams (meaning it does not know what any of the others are doing), then it will always take on an incoming project which it can do. This will happen independently of whether another team is also taking on the project, because the isolated team does not know this. 

Alternatively, if a pair of strongly connected teams see a project which they are overqualified for, and can both see another pair of teams which can complete the project with less excess skills, then the first team will ignore the project. However, while the first pair of teams observed that the second pair were both idle, it couldn't observe whether the 2nd two were strongly connected. If the second team are not strongly connected, then the project will be missed entirely, due to lack of communication. We illustrate this phenomenon in figure 

\begin{figure}[ht]
	\centering	
	\includegraphics[scale=0.13]{Waste1demo1.png}
	\caption{In this example we have an incoming project which requires both skills $\alpha$ and $\beta$. Teams $D$ and $E$ would possess these skills if they collaborate which they can do as they are connected, but have 2 $\gamma$ skills in excess. However, both $D$ and $E$ can see that the collaboration of $A$ and $B$ can complete the project more efficiently. Thus $D$ and $E$ do not take on the project as they do not know that $A$ and $B$ are not collaborating, and thus won't take the project either. Due to this lack of communication, even though there were plenty of ways that the project might have been done, the project is wasted.}
	\label{fig:waste1demo1}
\end{figure}

Ultimately, this procedure precisely determines a $2^8 \times 8$ transition probability matrix, which for obvious reasons is not presented here.

\subsubsection{Classical Solution of the 2 Cluster Model}

In this section, we compute the expected waste which will result from a particular connectivity matrix. However, we first must lay out what we mean by `waste'. In the context of this model, there are 3 different types of inefficiencies that can occur in the distribution of projects:

\begin{enumerate}
	\item \textbf{Unnecessary dismissal of project}\\
	If there exists a minimal subset of idle teams which possess the required skills to take on an incoming project, and yet do not have it assigned to them, then this is wasteful of the project itself.
	
	\item \textbf{Duplication of work}\\
	If there exists multiple minimal subsets of idle teams which possess the required skills to take on an incoming project, and multiple of these teams are then assigned to the project, then this is an unnecessary duplication of labour.
	
	\item \textbf{Excess Skills}
	If there exists an idle team which possesses skills beyond the requirements of an incoming project, and this team is assigned to the project, then this wasteful of these excess skills.
\end{enumerate}

Of these 3 sources of waste, we arbitrarily view type 1 to be 10 times worse than type 2 which is again 10 times worse than type 3. However, what is the numerical value of these costs?

For this we take a simplistic approach. We assign the values $w_\alpha, w_\beta$ and $w_\gamma$ to be the values of each skill type. When counting type 1 waste (a doable project is ignored), we add the values of all skills required and scale by 10. Hence, a project requiring all 3 skills would have a cost of $10(w_\alpha+w_\beta+w_\gamma)$.

With type 2 waste (a project being worked on by more than one team), we count the skills possessed by all teams which are assigned to the project. Then we determine how many times the project could be completed form this pool of skills. We assign the cost in this case to be the sum of the costs applying to the skills required by the project, multiplied by the number of times we find this 

 When counting type 3 waste, we count how many excess skills are possessed by the assigned teams, and then add up the values of these skills. Finally we scale this value by $1/10$.

For type 2 waste, we count 




\subsection{Next steps}

Here we present additional features which might develop this model into being more useful:

\begin{enumerate}
	\item A continuum of states for a project. Before a project was either `on' or `off'. It would be better if 1 were to refer to unstarted, 0 referred to completed, and any number in between indicated the progress made. This would allow the completion rate of projects to not be memoryless.
	\item A more sophisticated mechanism for collaboration. 
\end{enumerate}

\section{Criticism of IIT}

\section{Conclusions}

\section{Applying IIT}
In this section I intend to talk about observing how $\Phi$ actually behaves when I use it to measure consciousness. What type of shape it has, what type of optimal values can be achieved in practice. This section should include a detailed look at simple cases.

\subsection{2 nodes}
Examine how $\Phi$ behaves on networks with 2 nodes. As this case is small, try to conduct exhaustive searches in pursuit of some intuition as to how $\Phi$ behaves.
\subsection{3 nodes}
Attempt to generalise ideas from previous section here. Can I find an optimum with manageable computational effort? Can I apply principles from the 2 nodes case to anticipate what an optimum might be?

\subsection{Alternative Measures of $\Phi$}
Compare measurements of $\Phi$ using IIT 3.0 with results using alternative measures which have been proposed. Are they correlated. Are they measuring the same thing?

\section{Applicability of IIT to organisations}
In this section we consider the properties of $\Phi$, and question whether or not they are desirable properties in the context of a model for an organisation.

\begin{enumerate}
	\item \textbf{State Dependence}: Not only does the computation of $\Phi$ depend on the networks structure and transition mechanism, but it also depends on the state of every node within the system at the current time-step, but also on the previous state of every node outside the subsystem of consideration. This makes sense from the perspective of neuroscience as the level of consciousness is determined by which nodes are active at once, and not merely on the structure of the brain. Hence, within a fixed brain, consciousness various throughout the day. 
	
	In the context of a model for an organisation, a single time-step is not of particular interest if ones goal is simply to optimize profits. 
	
	
	\item \textbf{Consciousness of Deterministic Systems}: It is stated by Tegmark \cite{tegmark2016improved} that it is undesirable for a measurement of consciousness to be 0 for deterministic systems. Thus from the perspective of IIT, it is not necessarily unreasonable that numerical experiments would find $\Phi$ tending to be larger for deterministic systems than probabilistic ones.
	
	From the perspective of an organisation, a fully random decision process is obviously bad. However, 
\end{enumerate}