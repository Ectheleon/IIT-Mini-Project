 


\section{Introduction}
Within any organisation, no matter what the type, communication must be present. If members of a company do not communicate, then there is no way for a worker to know what they should be doing, or if what they are doing is actually important to the company. At the same time, if all members of an organisation are talking to each other there this may damage productivity, as well as giving rise to redundant communication. We investigate models of organisational structures that maximise productivity and flexibility.

This problem is an specific example from the wider context of social network theory. Zhang and van der Schaar \cite{zhang2015reputational} looked at a similar problem,  creating a model where each agent in their network decides which connections are of value to it based on limited information of their value, and how this affects the welfare of both the individual agent, and the network as a whole. This approach would be applicable to the problem, when thinking of the value of a connection between agents, as the importance of them communicating.

However, we approach the problem from a very different angle. Specifically we identify the brain as a biological example of effective communication between individual neurons. If we think of the neurons within the brain passing information between each other as being equivalent to individual workers/teams within an organisation talking to each other, then this becomes a similar problem in theory. Motivated by this, we attempt to apply Integrated Information theory to the problem.

What is integrated information theory? Originally present in 2004 by Tononi \cite{tononi2004information}, this is the most recent attempt to rigorously define consciousness. Since its first appearance it presents the function $\Phi$ which computes the integrated information of a system of mechanism. The main claim of integrated information theory is that consciousness and integrated information are the same thing, and hence computing $\Phi$ is computing consciousness. The arguments used to justify this claim are primarily philosophical in nature, and thus will not be discussed in this report. 

Since 2004, IIT has received multiple updates and adjustments \cite{tononi2011integrated,balduzzi2008integrated,tononi2016consciousness} each of which resolve issues found in the previous definition. Currently the most up to date version of IIT is version 3.0 \cite{oizumi2014phenomenology}, and hence we will primarily focus on that version in this report.

While IIT has developed from version 1.0 to 3.0 by its inventor Giulio Tononi, at the same time other authors have developed the theory in different directions. For example Barrett and Smith \cite{barrett2011practical} designed an alternative definition which was applicable to time series data. This $\Phi_e$ as they called it, has similar behaviour to the original $\Phi$ in settings where both could be applied, but can be used in more contexts. A list of such alternative definitions was compiled by Tegmark \cite{tegmark2016improved} for the purpose of considering their relative mathematical merits.

Our focus is to investigate whether the computation of $\Phi$ for a network model of an organisation might give any insight into the efficiency of communication within the organisation. As $\Phi$ is expensive to compute (as will be discussed in greater detail in section \ref{sec:cost}), we restrict our attention to a small scale toy model which we derive for the purpose of capturing the effects of poor communication within an organisation. Despite the greater cost of using IIT 3.0 than 2.0, we choose to use the most up-to-date version, as we wish to avoid the flaws which have previously been identified in older editions.


\section{Integrated Information Theory}
\label{sec:iit}

In this section, we present an overview of Integrated Information Theory 3.0 as presented by Oizumi et all \cite{oizumi2014phenomenology}, while adjusting the notation in order to make it mathematically consistent.
	
\subsection{Definitions and Notation}

Integrated Information Theory proposes a function called $\Phi$ which is defined based on the notions of \textit{mechanisms} and \textit{systems} \cite{oizumi2014phenomenology}. However, these notions are not given a rigorous mathematical definition. Hence we introduce our own mathematical definition with the aim of staying loyal to the notation in used in \cite{krohn2016computing} so far as is possible.

Let $Z_t$ be a discrete time multivariate stochastic process which takes values from $[0,1]^n$.  The stochastic process $Z_t$ is assumed to be a markov process, and it thus equipped with a transition probability matrix $\mathbf{M}$. We relate this stochastic process to a graph containing $n$ nodes. Each node refers to one of the individual random variables and has two \textit{states}: \textit{off}  and \textit{on}. Within this report, we abuse notation by allowing $Z$ to refer to the multivariate random process, and the set of all nodes in the graph simultaneously. 

\begin{definition}
	The \textit{state} of a node simply refers to whether that node is \textit{on} or \textit{off}. We denote \textit{on} with a 1, and \textit{off} with a 0.
\end{definition}

\begin{definition}
	\label{def:element}
	An \textit{elementary mechanism} doubly refers to a node in the graph $Z$, as well as a Bernoulli random variable. It has two states: \textit{off}, which corresponds to when the random variable takes the value 0, and \textit{on}, which corresponds to when the random variable takes the value 1. We denote an \textit{elementary mechanism} by $z^i$, and refer to its state at time $t$ by $z^i_t$.
\end{definition}
	
\begin{definition}
	\label{def:mech}
	A $m$-th order \textit{mechanism} is a set of $m$ distinct \textit{elementary mechanisms}. As such, it also has the double meaning referring both to a subset of nodes in the graph $Z$, as well as the corresponding random variables. The state of a mechanism is given by the states of all \textit{elementary mechanisms} within it. Hence a $m$th order \textit{mechanism} has $2^m$ distinct states. We denote the state of $W$ at time $t$ as $W_t$.
\end{definition}

\begin{definition}
	\label{def:system}
	A \textit{system} is the combination of a directed graph $Z$ with $n$ nodes, and the stochastic process $Z_t$. Therefore, all \textit{mechanisms} are contained within the \textit{system}.
\end{definition}
	
The graph $Z$ is directed and has edges, so what do these mean in the context of the stochastic process? We join $z^i$ to $z^j$ with a directed edge if the $z^i_{t+1}$ depends in some way on $z^j_t$. 

\begin{definition}
	\label{def:distributions}
	Let $A$ and $B$ be $i$-th and $j$-th order \textit{mechanisms}, $\mathbf{s} \in \mathbb{S}(A)$ and $\mathbf{r} \in \mathbb{S}(B)$. Then we define the
	\begin{enumerate}
		\item \textit{Forward Distribution}, $p(A_{t+1}|B_t = \mathbf{r})$ to be the probability distribution that each state of $A$ occurs. This distribution contains $2^i$ values.
		\item \textit{Backward Distribution}, $p(A_{t}=\mathbf{s}|\mathbf{B}_{t-1})$ to be the probability of each previous state of $B$ leading to $A_t = \mathbf{s}$. This distribution contains $2^j$ values.
		\item When we specify both the event, and the condition, then $p(A_t = \mathbb{s}|B_t = \mathbf{r})$ refers to a number between 0 and 1, the probability of the event occurring given the condition.
	\end{enumerate}
\end{definition}



\begin{definition}
	{IIT \cite{oizumi2014phenomenology} uses the names of \textit{effect repertoire} and \textit{cause repertoire} for specific distributions. Denoted as $p_e$ and $p_c$, these are similar to the forward and backward distributions, but rely on assumption \ref{asmp:cond_independence} which we will describe later. }
\end{definition}


\begin{remark}
	In this document, we use Krohn and Ostwalds  \cite{krohn2016computing} notation: $W_{t-1}, W_t, W_{t+1}$ to denote the past, present, and future states of a \textit{mechanism}. In \cite{oizumi2014phenomenology} however, these are denoted by $W^p, W^c$ and $W^f$ respectively.
\end{remark}

\begin{tabularx}{\textwidth}{ll X}
	Term & Usual Notation & Notes \\
	\hline
	\endfirsthead
	\hline
	\endhead
	\endfoot
	\hline
	\caption{Key Definitions and Notation} 
			%\addcontentsline{lot}{table}{\numberline{}Common abbreviations} % For use with fancy header package. 
	\label{tab:defs}
	\endlastfoot
	\textit{System} & $Z$ & A system is a set of \textit{elementary mechanisms}. We usually take the size to be $n$. For details see \ref{def:system}.\\
		\hline
	\textit{Mechanism} & $W$ & A $m$-order \textit{mechanism} is a size $m$  subset of a system $Z$. We usually take the size to be $m$. For details, see Definition \ref{def:mech}. \\
		\hline
	\textit{Elementary Mechanism} & $w^i$ & An \textit{elementary mechanism} consists of a single node, random variable pair. For details see \ref{def:element}.\\
		\hline
	\textit{Null Mechanism} & $\emptyset$ & The \textit{null mechanism} exists for the purpose of saying that nothing is known.\\
		\hline
	\textit{State Set} & $\mathbb{S}(W)$ & A $m$-th order \textit{mechanisms} \textit{state set} is the set of all possible \textit{states} of that \textit{mechanism}. \\
		\hline
	\textit{State} & $\mathbf{s}$ & We usually write the state of a \textit{mechanism} as $\mathbf{s}$.\\
		\hline
	Power Set & $\mathbb{P}(W)$ & The set of all subsets of a \textit{mechanism}.\\
		\hline
	Forward Distribution & $p(W_{t+1}|V_t=\mathbf{s})$ &The distribution of future states of $W$ given present knowledge of $V$. See Definition \ref{def:distributions}. \\
		\hline
	Backward Distribution & $p(W_{t}=\mathbf{s}|V_{t-1})$ & The distribution of past states of $V$ given present knowledge of $W$. See Definition \ref{def:distributions}.\\
\end{tabularx}









\subsection{Computation of Repertoires}
\label{sec:cost}
In this section, we construct each of the previously defined repertoires from $\mathbf{M}$, the transition probability matrix. For later use, we define the product of probability distributions.

%{First however, we need to introduce both the \textit{perturb function}, and the assumption of conditional independence, as all future definitions rely on these.

%\begin{definition}
%	{Let $S$ be a set such that $|S| = n$, and its elements are indexed by $s_1, s_2, \ldots, s_n$. Further let $f$ be a function which operates on the elements of $S$. Then we write the perturbation function as:
%	\[per(f(a, S), S) = \left(\begin{array}{cccc}f(a,s_1)&f(a,s_2)&\ldots&f(a,s_n) \end{array}\right)^T\]
%	That is, the perturbation function returns a vector where each of its entries corresponds to the $f$ taking a different input from $S$.}
%\end{definition} 

\begin{definition}
	\label{def:dist_prod}
	Let $A, B \subset Z$ such that $A$ and $B$ are disjoint. Then we define the \textit{distribution product} of $A$ and $B$ by:
	\[p(A_{t+1}|Z_t)p(B_{t+1}|Z_t):=p(A_{t+1} \cup B_{t+1}|Z_t).\]
	In other words the product of the distributions is the distribution for the union of the sets $A$ and $B$.
\end{definition} 

\subsubsection{Conditional Independence}
\label{sec:conditional_independence}
In order to simplify all computations, IIT \cite{oizumi2014phenomenology} assumes the following theorem to hold.

\begin{assumption}
	\label{asmp:cond_independence}
	Let $Z$ be a \textit{system}. Then it holds that:
	\begin{equation}
	\label{eq:cond_independence}
	p(Z_{t+1}|Z_t = \mathbf{s}) = \prod \limits_{i=1}^{n} p(z^i_{t+1}|Z_t=\mathbf{s})
	\end{equation}
	
	where we have reduced the probability distribution for future states of $Z$ to the products of the distributions for each of its \textit{elementary mechanisms}. 
\end{assumption}

Assumption \ref{asmp:cond_independence} motivates the following definition.

\begin{definition}
	\label{def:generator}
	Let $p(Z_{t+1}|Z_t = X)$ be a probability distribution. We define the row vector $\mathbf{q}(Z_{t+1}|Z_t = X)$ such that $q_i = p(z^i_{t+1}=1|Z_t=X), \quad \forall i \in 1, 2, \ldots, n$. We call $\mathbf{q}$ the \textit{distribution generator}.
\end{definition}

Now we present following key theorem which reduces the storage space required for future computations:

\begin{theorem}
	\label{thm:bijection}
	Let $A$ be the set of distributions for the system $Z$, and $B$ be the set of \textit{distribution generators} for the same system. Then there exists a bijection between between $A$ and $B$.
\end{theorem}

\begin{proof}
	We prove this bijection by construction the function which converts a distribution into its \textit{generator}, and its inverse.
	
	Let $p$ be a probability distribution of length $2^n$ that applies to the system $Z$, such that $p_i$ is the probability of $i \in \mathbb{S}(Z)$ occurring. We order the \textit{states} of $\mathbb{S}(Z)$ in order to write $p$ as a vector, which we now write as $\mathbf{p}$. 
	
	Next we construct the $2^n \times n$ state matrix $\mathbf{S}$. Each row of this matrix is a state of the \textit{system}, which in turn is a row vector. To map from $\mathbf{p}$ to its generator $\mathbf{q}$, we simply write: $\mathbf{q} = \mathbf{p} \mathbf{S}$. We demonstrate this transformation in equation \ref{eq:matrix_tranform_demo}. Naturally, $\mathbf{q}$ is dependent on the ordering of states.
	
	To go back, we write:
	
	\begin{equation}
	\label{eq:map_inv}
	p_i = R(\mathbf{q}) := \prod \limits_{j=1}^{n} q_j^{S_{ij}} (1-q_j)^{1-S_{ij}}\quad \forall i \in \mathbb{S}(Z)
	\end{equation}
	
	where  $S_{ij}$  indexes the state matrix and specifically says whether the $j$th node in the $i$ state is \textit{on} or \textit{off}. We name the function which converts a generator into its disribution $R$. Hence we can compute $\mathbf{p}$ from $\mathbf{q}$, and go back. Thus this is a bijection.
\end{proof}

Theorem \ref{thm:bijection} enables us to condense $\mathbf{M}$ by converting each of its rows into the corresponding \textit{distribution generator}. We define the condensed matrix:

\begin{equation}
\label{def:generators}
\mathbf{T}_{i} := \mathbf{q}(Z_{t+1} = j| Z_t = i) , \quad \forall i \in \mathbb{S}(Z).
\end{equation}

We demonstrate transforming the transition probability matrix into the \textit{condensed matrix} in equation \ref{eq:matrix_tranform_demo}. In practice this is done by multiplying $\mathbf{M}$ to the $2^n \times n$ matrix whose rows are the elements of $\mathbb{S}(Z)$ appearing in chosen ordering:



\begin{equation}
\label{eq:matrix_tranform_demo}
\left( \begin{array}{cccc} 0&0&0.25&0.75\\
							0.35&0.15&0.35&0.15\\
							0.1&0&0.9&0\\
							0&0.6&0&0.4
							\end{array} \right) 							
\left(\begin{array}{cc}0&0\\
1&0\\
0&1\\
1&1 \end{array} \right)
\rightarrow \left( \begin{array}{cc}.75&1\\
											.3&.5\\
											0&.9\\
											1&.4 \end{array} \right).
\end{equation}

\begin{remark}
	In IIT 3.0 \cite{oizumi2014phenomenology}, the \textit{condensed matrix} $\mathbf{T}$ is incorrectly referred to a transition probability matrix. This name is incorrect as $\mathbf{T}$ is not a stochastic matrix. Hence we rename it for the purpose of mathematical consistency.
\end{remark}

The notion of \textit{generators} enables us to generalise definition \ref{def:dist_prod}. 

\begin{definition}
	\label{def:dist_prod_gen}
	Let $A, B \subset Z$ such that $A$ and $B$ are disjoint, and $W,V$ be mechanisms in $Z$. Define $\mathbf{Q}$ as the concatenation of $\mathbf{q}(A_{t+1}|W_t = \mathbf{s})$ and 	$\mathbf{q}(B_{t+1}|V_t = \mathbf{s})$. Then we define the general \textit{distribution product} to be:
	
	\[p(A_{t+1}|Z_t)p(B_{t+1}|Z_t):=R(\mathbf{Q}).\]
	
	This is consistent with definition \ref{def:dist_prod}, and now includes the case where $W \neq V$.
\end{definition}

\subsubsection{Effect repertoire}

Let $Z$ a \textit{system} and $W$ a $m$-th order mechanism, and suppose that the state of $W \subset Z$ is known, $W_t = \mathbf{s}$. Then the  \textit{effect repertoire} is defined by IIT \cite{oizumi2014phenomenology} to have the property of factorisation, that is:

\begin{equation}
\label{def:controversial}
p_e(Z_{t+1}|W_t = \mathbf{s}) = \prod \limits_{i= 1}^n p(z^i_{t+1}|W_t = \mathbf{s}).
\end{equation}

It is important to note that this factorisation does not follow generally from equation \ref{eq:cond_independence}, as it is much stronger. It was only assumed that future state of each node was conditionally independent with respect to the current states of the entire system, as opposed to with respect to all possible subsets of this system as well.

This is justified by Oizumi et al \cite{oizumi2014phenomenology} in their supplementary methods document on the grounds that they are interested in how $W_t=X$ affects each $z^i_{t+1}$ individually and thus factorise as above in order to remove correlations.


Finally, let $W$ be a $m$-th order \textit{mechanism} of the \textit{system} $Z$, the current state of which is known, and let $z^{i_0}$ be a particular node in $Z$. The mathematical definition \cite{krohn2016computing} of $p_e$ is
\begin{equation}
\label{def:effect_repertoire}
p_e(z_{t+1}^{i_0}|W_t = \mathbf{s}) = 2^{-|n-m|}\sum \limits_{\mathbf{r} \in \mathbb{S}(Z\setminus W)} p(z_{t+1}^{i_0}|W_t = X, (Z\setminus W)_t = \mathbf{r}).
\end{equation}

This is equivalent to averaging over all rows of the TPM which corresponds to states of $Z_t$ such that $ W_t = \mathbf{s} $.


\subsubsection{Cause repertoire}

Just as the effect repertoire is broken into a smaller problem in equation \ref{def:controversial}, there exists an equivalent simplification for computing the cause repertoire. Let the state of the $m$-order \textit{mechanism} $W \subset Z$ be known, and $V$ be another $k$-th order \textit{mechanism}. Then the mathematical definition \cite{krohn2016computing} of $p_c$ is

\begin{equation}
\label{def:cause_rep1}
p_c(V_{t-1} | W_t=\mathbf{s}) = \prod \limits_{i = 1}^{m} p_c(V_{t-1}|w^i_{t} = s_i).
\end{equation}

We define $p_c$ given knowledge of a single \textit{elementary mechanism}

\begin{equation}
\label{def:cause_rep2}
p_c(V_{t-1}| w_t = x) = \frac{\sum \limits_{\mathbf{r} \in \mathbb{S}(Z\setminus V)} p_e(w_t = x| V_{t-1}, (Z \setminus V)_t = \mathbf{r})}{p(w_t = x)}.
\end{equation}

In short, we add up the probabilities of each individual previous state that results in our current information ($w_t = x)$, and then scale by the overall probability that we observe $w_t = x$ in the first place. Note that equation \ref{def:cause_rep2} features the effect repertoire $p_e$ on the right hand side, not $p_c$.

\begin{remark}
	Equation \ref{def:cause_rep1} does not require additional assumption, because it is a consequence from equation \ref{def:controversial}.
\end{remark}



\subsection{The Earth Mover's Distance }
In the context of this document, we calculate the distance between two probability distributions $p1$ and $p2$ using $D(p1,p2)$, where $D$ is referring to the Earth Mover's Distance (EMD) \cite{rubner1998metric}.

To use this distance, we require the existence of another metric which measures the distance between any pair of states. For this we use the Hamming distance (see \cite{hill1986first} for more details) which is the number of individual bytes that disagree when comparing two states. (i.e. the hamming distance between 001 and 101 is 1, as the have 1 disagreement in the first digit)

In simple terms, if we think of each distribution as piles of dirt on top of each given state. The earth mover's distance is the product of how much dirt needs to moved by how far this dirt needs to go. 

\begin{definition}
	\label{def:emd}
	 Let $S$ be a set of $n$ states, $s_i, s_j \in S$, $\mathbf{D} = \left[ D_{ij}\right]$ where $D_{ij}$ is the distance between $s_i$ and $s_j$, $P$ and $Q$ be two probability distributions over $S$ such that $P(X = s_i) = p_i$ and $Q(X=s_j) = q_j$, $\forall s_i, s_j \in S$. 
	
	Calculate the $n\times n$ matrix $\mathbf{F}$ which solves the following optimization problem:
	
	\begin{align}
	\label{eq:EMD1}
	\min \limits_{\mathbf{F}}\sum \limits_{i,j=1}^n &F_{ij} D_{ij}\quad \text{subject to}\\
	&F_{ij}\geq 0,\quad \forall 1 \leq i,j \leq n\\
	\sum \limits_{j=1}^n &F_{ij} = p_i,\quad 1 \leq i \leq n\\
	\sum \limits_{i=1}^n &F_{ij} = q_j,\quad 1 \leq j \leq n
	\end{align}
	
	Finally, we define distance between $p$ and $q$ as: 
	
	\begin{equation}
	\label{def:EMD}
	\text{EMD}(P, Q) = \sum \limits_{i,j=1}^{n} F_{ij} D_{ij}
	\end{equation}
\end{definition}

From now on, we'll use the notation $D(P,Q)$ to denote the earth mover's distance.

\begin{tabularx}{\textwidth}{ll X}
	Term & Usual Notation & Notes \\
	\hline
	\endfirsthead
	\hline
	\endhead
	\endfoot
	\hline
	\caption{Key Definitions and Notation} 
	%\addcontentsline{lot}{table}{\numberline{}Common abbreviations} % For use with fancy header package. 
	\label{tab:defs2}
	\endlastfoot
	\textit{Minimum Information Partition} & MIP & The pair of sets $M$, $N$ which minimise the value of $\varphi_{cause}^{M,N}(W_t=\mathbf{s}, V)$.\\
	\hline
	\textit{Core Cause, Effect} & $C, E$ & The sets $C$ and $E$ which minimise $\varphi^{\text{MIP}}_{\text{cause}}(W_t = \mathbf{s}, C)$ and $\varphi^{\text{MIP}}_{\text{effect}}(W_t = \mathbf{s}, E)$ respectively . \\
	\hline
	\textit{Concept} & - & A \textit{mechanism} $W$ for which $\varphi^{\text{Max}}(W_t =\mathbf{s})>0$ is called a \textit{concept} .\\
	\hline
	\textit{MICE} & - & The MICE of a \textit{mechanism} is the combination of the \textit{cause repertoire} and \textit{effect repertoire} over the \textit{core cause} and \textit{core effect} respectively. \\
	\hline
	\textit{Candidate Set} & $Y$ & A subset of $Z$. All nodes outside of $Y$ are considered to be background conditions.\\
	\hline
	\textit{Complex} & - & The \textit{candidate set} $Y$ which maximises $\Phi^{\text{MIP}} (Y_t = \mathbf{s})$.\\
	\hline
\end{tabularx}

\subsection{Calculations for Mechanisms}\label{sec:little_phi}
There are 3 functions which operate over mechanisms: cei, $\varphi^{\text{MIP}}$ and $\varphi^{\text{Max}}$. When applying these functions to a \textit{mechanism} $W$ within the system \textit{system} $Z$, they treat nodes differently depending on whether the nodes are found within the \textit{mechanism} itself, the \textit{consideration set} but not the \textit{mechanism}, or the \textit{system} but not the \textit{consideration set}.

We have not yet defined the \textit{consideration set}, and will not do so rigorously until section \ref{sec:systems}, as they are not important until then. For now, we merely define a consideration set $Y$ as a subset of the \textit{system} $Z$ such that $W \subset Y$, where $W$ is the $m$-th order mechanism. Figure \ref{fig:IIT_illustration1} illustrates this.


When we compute cei, $\varphi^{\text{MIP}}$ or $\varphi^{\text{Max}}$, we are computing the effect of knowing the state of the \textit{mechanism}, $W_t = \mathbf{s}$. However, we do not know the state of the nodes in $Y\setminus W$, and we thus assume they could be \textit{on} or \textit{off} with equal probability. Finally all nodes in $Z \setminus Y$ are considered as background conditions. These calculations require that the past and present states of such nodes are known. 

In summary, cei, $\varphi^{\text{MIP}}$ and $\varphi^{\text{Max}}$ measure an effect that knowing the state of $W$ has on the \textit{consideration set}, given the background conditions of external inputs/outputs.


\begin{SCfigure}
	\centering
	\includegraphics[scale = 0.1]{IITexplanationdiagram1.png}
	\caption{In this illustration, we identify the mechanism $CD$ by circling it in red. The \textit{consideration set} is similarly circled in green. Finally, all remaining nodes of the system which lie outside of the \textit{consideration set} are external inputs/outputs.}
	\label{fig:IIT_illustration1}
\end{SCfigure}

\subsubsection{Cause-Effect Information}
\label{sec:cei}
The \textit{cause-effect information} (cei) is a measurement of the significance of a piece of information. It is calculated in two parts. First we have the \textit{cause information} (ci), which measures how the past can be constrained given knowledge of the present. 

Let $W$ and $V$ be $m$-th and $k$-th order \textit{mechanisms} respectively such that $W,V \subset Y$, the \textit{consideration set}. Then \textit{cause information} is defined \cite{oizumi2014phenomenology} by:

\begin{equation}
\label{def:ci}
\text{ci}(W_{t} = X, V) = D\left(p_c(V_{t-1}|W_{t} = X),p_c(V_{t-1}|\emptyset)\right)
\end{equation}

What we do is compare using the earth mover's distance the probability distribution of future states of the  $V $ given knowledge of the present, to the distribution of future states given no knowledge of the present. The bigger this difference is, the more information is generated. 

Second the \textit{effect information} (ei) measures how the future is constrained given knowledge of the present. It is defined in IIT \cite{oizumi2014phenomenology} as:
\begin{equation}
\label{def:ei}
\text{ei}(W_{t} = \mathbf{s}, V) = D\left(p_e(V_{t+1}|W_{t} = \mathbf{s}),p_{e}(V_{t+1}|\emptyset)\right).
\end{equation}

Finally, we define the cause-effect information ($cei$) to be the minimum between the cause information and effect information:

\begin{equation}
\label{def:cei}
\text{cei}(W_{t} = \mathbf{s}, V) = \min\left(\text{ci}(W_{t} = \mathbf{s}, V), \text{ei}(W_{t} = \mathbf{s}, V) \right)
\end{equation}

The minimum of these two functions is taken in order to ensure that knowledge which generates either no \textit{cause information} or no \textit{effect information} will thus generate no \textit{cause effect information}. Intuitively, cei measures how much $W$ effects, and is effected by $V$.

\subsubsection{Integrated Information}
\label{sec:mech_integration}
The function $\varphi^{\text{MIP}}$ measures the \textit{irreducibility} of the information generated by knowledge of a \textit{mechanism}. Specifically this function questions whether the same information might have been generated if the graph was cut into bipartitions. 

Intuitively, if a mechanism can be split into disjoint parts and these generate the same result, then the mechanism is reducible and $\varphi=0$. In contrast, the larger $\varphi$ is, the more information the mechanism has beyond the sum of its parts. In order to make IIT's definition of $\varphi^{\text{MIP}}$ easier, we define some intermediate calculations, the first of which is the \textit{partitioned cause repertoire} as

\begin{equation}
\label{def:preMIP}
p_c^{M,N}(A_{t-1}|B_t ):= p(N_{t-1}|M_t) p((A \backslash N)_{t-1} |(B \backslash M)_t).
\end{equation}

In other words, we partition the information of the present into $M$ and $B\setminus M$, and possibilities of the past into $N$ and $A \setminus N$. Then instead of determining the distribution of past states of $A$ given $B$, we compute it for $N$ given $M$ and $A\setminus N$ given $B \setminus M$ separately. We then multiply these distributions together to get the \textit{partitioned cause repertoire}.

Next, we define the \textit{partitioned cause information}:

\begin{equation}
\label{def:phi2}
\varphi_{cause}^{M,N}(W_t=\mathbf{s}, V) := D \left( p_c(V_{t-1}|W_t=\mathbf{s}) ,p^{M,N}_c(V_{t-1}|W_{t} = \mathbf{s})  \right).
\end{equation}.

where as in section \ref{sec:cei}, $V, W \subset Y$ are $k$-th and $m$-th order \textit{mechanisms} respectively. What this measures, is the difference between the distribution of future states of the $V$ , and the \textit{partitioned cause repertoire} using the EMD. In other words, we measure the difference made by partitioning our system.

We then define the \textit{partitioned cause information} as below.

\begin{equation}
\label{def:phi3}
\varphi_{cause}^{\text{MIP}}(W_t=\mathbf{s}, V)  =\min \limits_{M \in \mathbb{P}(V), N \in \mathbb{P}(W)} \varphi_{cause}^{M,N}(W_t=\mathbf{s}, V) 
\end{equation}

We call the sets $M$ and $N$ which gave rise the minimum the \textit{minimum information partition} (MIP) \cite{oizumi2014phenomenology}. We compute \textit{partitioned cause information} because the information we are measuring is only irreducible if a partition makes a difference even in the worst case scenario.


To compute the analogous MIP for effects and $\varphi^{\text{MIP}}_{effect}$, We need only to swap $p_c$ for $p_e$. This allows us to define integrated information $\varphi^{\text{MIP}}$ \cite{oizumi2014phenomenology}:
\begin{equation}
\label{def:phi}
\varphi^{\text{MIP}}(W_t=\mathbf{s}, V) = \min \left( \varphi_{cause}^{\text{MIP}}(W_t=\mathbf{s}, V), \varphi_{effect}^{\text{MIP}}(W_t=\mathbf{s}, V)  \right) 
\end{equation}



It is useful to recognise the relation between $\varphi^{\text{MIP}}$ and $cei$. Specifically we have following result which was established by Marshall et all \cite{marshall2016integrated}:
\begin{equation}
\label{eq:bound_phi_cei}
\varphi^{\text{MIP}}(W_t=\mathbf{s}, V) \leq cei(W_t=\mathbf{s},V) .
\end{equation}

This implies that the biggest difference we can make to $\varphi^{\text{MIP}}$ by partitioning a mechanism occurs when the partitioned repertoire is precisely the unconstrained repertoire. 



\subsubsection{Maximally Integrated Information}
The last function on a \textit{mechanism} level to define is $\varphi^{\text{Max}}$. Let $W_t = \mathbf{s}$ be a $m$-th order mechanism, and $Y$ be the \textit{candidate set}, such that $W \subset Y$. We define $\varphi^{\text{Max}}$, the maximally integrated information \cite{oizumi2014phenomenology} as: 
\begin{equation}
\label{def:core_cause}
\varphi^{\text{Max}}_{\text{cause}}(W_t = \mathbf{s}):=\max \limits_{V \in \mathbb{P}(Y)}\varphi^{\text{MIP}}_{\text{cause}}(W_t = \mathbf{s}, V).
\end{equation}

What $\varphi^{\text{Max}}$ determines is how much integrated information is generated by $W$ on the subset of the \textit{candidate set} for which it generates the most integrated information. The \textit{mechanism} $V$ which gave rise to the maximum is called the \textit{core cause} of $W_t = \mathbf{s}$.

The \textit{core effect} and  $\varphi^{\text{Max}}_{\text{effect}}$ are defined similarly. Finally we finish  by setting $\varphi^{\text{Max}}$ to be the minimum of the two as before. It is important to note that we find the \textit{core cause} and \textit{effect separately}, and that these need not be the same set.

As with $\varphi^{\text{MIP}}$ we bound $\varphi^{\text{Max}}$ \cite{marshall2016integrated}. 

\begin{equation}
\label{eq:bound_phimax}
\varphi^{\text{MIP}}(W_t = \mathbf{s}, V) \leq \varphi^{\text{Max}}(W_t = \mathbf{s})\leq cei(W_t = \mathbf{s}, V) \quad \forall V \in \mathbb{P}(Y).
\end{equation}

If we find that $\varphi^{\text{Max}}(W_t =\mathbf{s})>0$, then we call the combination of $\varphi^{\text{Max}}(W_t = \mathbf{s})$ with its core cause and effect a \textit{concept}. This allows us to define a \textit{maximally integrated cause effect repertoire}.

\begin{definition}
	{The \textit{maximally integrated cause effect repertoire} of a piece of information, or MICE, is the combination of the cause repertoire $p_c(C_{t-1}|W_t = \mathbf{s})$, where $C$ is the core cause of $W_t=\mathbf{s}$ along with the effect repertoire $p_e(E_{t+1}|W_t = \mathbf{s})$, where $E$ is the core effect of $W_t = \mathbf{s}$.}
\end{definition}

\subsection{Calculations for Systems of Mechanisms}
\label{sec:systems}
Thus far calculations have been restricted to a single mechanism, whether 1st, 2nd, or $n$th order. However, a network of more than one node may contain multiple mechanisms, which may overlap with each other. Specifically a system of $n$ nodes contains $2^n-1$ \textit{mechanisms}.

Now we focus our attention on computing integrated information in a system of mechanisms. 

\subsubsection{Conceptual Information}
\label{sec:CI}
The \textit{Conceptual Information} (CI)\cite{oizumi2014phenomenology}  extends the notion of \textit{cause-effect information} to the entire \textit{system} of nodes. Before we computed the distance between the repertoire specified by some information and the unconstrained repertoire. Now, instead of computing the distance between repertoires, we add up the distances between concepts.

The Conceptual Information is the sum of the distance between the MICE of each of its concepts, and the unconstrained MICE, weighted by the $. We compute it below:
\varphi^{\textit{Max}}$ corresponding to each \textit{concept}.

\begin{equation}
\label{def:CI}
CI(Z_t = \mathbf{s}) = \sum \limits_{S \in \mathbb{P}(Z)} \varphi^{\text{Max}}(S_t=\mathbf{s}) D(M^S, M^{uc}).
\end{equation}

where $M^S$ is the MICE of the concept $S$, and $M^{uc}$ is the unconstrained MICE, which is the unconstrained cause and effect repertoires. We measure the distance between $M^S$ and $M^{uc}$ by adding the distances between the two cause, and effect repertoires \cite{oizumi2014phenomenology}.

\begin{remark}
	Equation \ref{def:CI} uses Oizumi et al's \cite{oizumi2014phenomenology} definition of $CI$. However, it was pointed out by Krohn and Ostwald \cite{krohn2016computing} that this definition is not well defined. The MICE is defined as the set of cause and effect repertoires that maximize $\varphi^{MIP}$. However, there may be two such MICE's: $M_1$ and $M_2$, that produce the same value for $\phi^{Max}$, and yet affect Equation \ref{def:CI} differently. We show equation \ref{def:CI} as we used the software provided by Mayner et all \cite{pyphi} which follows the above definition. Krohn and Ostwald propose a simpler definition which fixes this issue, where they merely add up the values of $\varphi^{\text{Max}}$, and ignore the MICE.
\end{remark}

\subsubsection{Integrated Conceptual Information}
We measure the integration of a piece of information on the level of a system of mechanisms. For this task it is useful to define the term \textit{constellation}.

\begin{definition}
	A \textit{constellation} refers to the set of all concepts within a system, each concept equipped with its' MICE. That is, all of the mechanisms $W$ within the system such that $\varphi^{\text{Max}}>0$, each equipped with their \textit{effect repertoire} on the \textit{core effect}, and their \textit{cause repertoire} on their \textit{core cause}.
\end{definition}

As before, we consider all ways to apply a one directional cut to the system $Z$. This means that I divide all \textit{elementary mechanisms} into two sets, pick one of them, and remove all edge pointing to that set from the other. This contrasts the partition from section \ref{sec:mech_integration} where we removed all edges between the sets.

We compute the constellation for the partitioned system. For this partitioned system, some of the concepts from the while system will remain intact, but others may be  destroyed by the partition.

Let the function $C(P)$ give the set of concepts for the partition $P$. Then we define the \textit{Partitioned Conceptual Informaiton}

\begin{equation}
\label{def:Phi_integration1}
\Phi^P(Z_t = \mathbf{s}) = \sum \limits_{K \in (\mathbb{P}(Z) \setminus C(p))} \varphi^{\text{Max}}(K_t = \mathbf{s})D(M^S, M^{uc}).
\end{equation}

The difference between $\Phi^P$ and $CI$ is that while in $CI$ we sum over all concepts, in $\Phi^P$ we only sum over the concepts which have been destroyed by the partition.

As before we seek the minimum information partition (MIP) which is given by

\begin{equation}
\label{def:Phi_integration2}
\Phi^{\text{MIP}} (Z_t = \mathbf{s}) = \min \limits_{P} \Phi^P(Z_t = \mathbf{s}).
\end{equation}

\begin{remark}
	As in section \ref{sec:CI}, the value specified in equation \ref{def:Phi_integration2} is not well defined, for the same reason as previously. Krohn and Ostwald solve this inconsistency  as before: they remove the $D(M^S, M^{uc})$ term from the equation, leaving only the corresponding $\varphi^{\text{Max}}$ terms.
\end{remark}

\subsubsection{Maximally Irreducible Conceptual Structure}

The definition of $\Phi^{\text{MIP}}$ in equation \ref{def:Phi_integration2} leaves an intuitive example which breaks the definition. We show this example in figure \ref{fig:phimax}. 

\begin{SCfigure}
	\centering
	\includegraphics[scale = 0.13]{Phimaxillustration.jpg}
	\caption{We show a dense cluster of nodes which if taken to be the \textit{system} generates a large $\Phi^{\text{MIP}}$ in the shaded background. Now we add an extra node to this system. Given how this new node is sparsely linked to the original system, the MIP will simply be cutting off this node, resulting in a small change. The result of this is that $\Phi^{\text{MIP}}$ for the new system would be very small.}
	\label{fig:phimax}
\end{SCfigure}

Intuitively we understand that the conclusion: `adding a single extra neuron to the brain destroys all consciousness' is clearly not true. Hence we need the value $\Phi^{\text{Max}}$ to finish our definition of Integrated Information. We define:

\begin{equation}
\label{def:Phimax}
\Phi^{\text{Max}}(Z_t = \mathbf{s}) := \max \limits_{Y \in \mathbb{P}(Z)}\Phi^{\text{MIP}} (Y_t = \mathbf{s}).
\end{equation}

In equation \ref{def:Phimax}, when we take $Y \in \mathbb{P}(Z)$, we are not referring to a \textit{mechanism} with the \textit{system} $\mathbf{Z}$, but rather to a \textit{candidate set}.

\begin{definition}
	A \textit{candidate set} \cite{oizumi2014phenomenology} is a subset of the \textit{system}. It has the property that all nodes outside of it cease to be random variables, and are instead view to be fixed.  
\end{definition}

\begin{definition}
	We call the \textit{candidate set} which gives the largest value computing $\Phi^{\text{Max}}$ a \textit{complex} \cite{oizumi2014phenomenology}.
\end{definition}

When using IIT to compute the integrated information of a \textit{system}, what we actually do is identify the \textit{complex}, and then compute $\Phi^{\text{MIP}}$ for this specific \textit{candidate set}.

\subsection{Computational Cost}
We now ask how expensive is the computation of $\Phi^{Max}$. Let $Z$ refer to a system of nodes such that $|Z| = n$.

\begin{theorem}
	Let $Z$ refer to a system of $n$ nodes. Then computing $\Phi^{Max}$ scales with order $O(n^3 2^{8n})$.
\end{theorem}

\begin{proof}
To prove this theorem, we go through the required calculations step by step.

\begin{enumerate}
	
	\item To compute $\Phi^{\text{Max}}$, we must calculate $\Phi^{\text{MIP}}$ for \textit{candidate sets} of our system. There are at most $2^n$ such subsets, and hence we must compute $\Phi^{\text{MIP}}$ this many times.
	\item For a particular \textit{candidate set}, we must determine the MIP of one directional cuts. If the subset is of size $m$, then there at most $2^{m+1}$ ways to do this (if the connectivity matrix is sparse, then there are considerably less). We bound $m$  by $n$, so we say that this step must occur at most $2^{n+1}$ times.
	\item Each computation of $\Phi^{\text{MIP}}$ for a particular partition requires us to calculate  $\varphi^{\text{Max}}$ for all \textit{mechanisms} in the \textit{candidate set}. Thus we must carry out this computation up to $2^n$ times.
	\item Each computation of $\varphi^{\text{Max}}$ requires both the \textit{core cause} and \textit{core effect} to be identified. This involves calculation $\varphi^{\text{MIP}}_{cause}$ and $\varphi^{\text{MIP}}_{effect}$ each over the entire power set of the \textit{candidate set}, resulting in a further $2^{n+1}$ computations.  
	\item To compute $\varphi_{cause}^{\text{MIP}}$, we must search over all possible partitions. There are $2^n$ of these.
	\item Finally, when measuring the difference made by a partition, we must measure the distance between probability distributions. This is done using the Earth Mover's Distance, which scales $O(k^3 \log k)$, where $k$ is the number of states found in the distributions the distance is being measured between. In this case $k = 2^n$ so this step scales with $O(2^{3n} n^3)$
\end{enumerate}

We multiply all these steps together to conclude that  $\Phi^{Max}$ scales with $O(n^3 2^{8n})$.

\end{proof}
\section{Modelling an Organisation}

In this section, we seek to model communication flow within an organisation. To do this, the first step is to specify the type of organisation that we're referring to. 

\begin{enumerate}
	\item The organisation is a company which generates revenue by completing projects.
	
	\item Each project requires the application of certain skills in order to be completed.
	
	\item The organisation consists of a fixed number of teams, each possessing one or more skill.
	
	\item Projects are completed by assigning sufficiently many teams to the project which possess all skills required to complete the project.
\end{enumerate} 

Within this framework, where does communication come in? Suppose that a project appears which requires python programming skills. Further, let there be 2 distinct teams which have this skill. What happens now? If these teams are not communicating, then they might both take on the same project, depending on the policy by which they decide what to do. Alternatively, if they are communication, not only can they guarantee that they don't do the same thing, but they can also collaborate with each other, thus finishing the project faster than otherwise.

Suppose we have $n$ teams. We represent these teams in mathematics as nodes in a graph. Each of these nodes has 2 states: `on' and `off'. A team is active if its node is `on', and is idle if the node is `off'. Next we say that one team $v_1$ is paying attention to another team $v_2$ if there exists a directed edge from $v_1$ to $v_2$. Furthermore, these teams are said to be communicating both teams are paying attention to each other.

With this structure defined, we now need to consider how to build dynamics into the model. In particular we must define the following:

\begin{itemize}
	\item Progression of time. We take our model to be a discrete iterative process. Each iteration marks the passage of a fixed time period. 

	\item Arrival of Projects. We model projects such that with each time step, a single project might arrive. The nature of the project which arrives we determine using a multivariate Bernoulli distribution.
	
	\item Completion of Projects. We arbitrarily decide that the duration of a project will be distributed exponentially. This is equivalent to saying that each project has an identical chance of completion following each iteration.
\end{itemize}


\subsection{The Small 3-node Model}
\label{sec:3nodemodel}
In this model, we consider there to be 3 teams, and 2 skill types. We label the teams as $A$, $B$ and $C$, and the skill types as $\alpha$ and $\beta$. Assume that teams $A$ and $C$ have skill $\alpha$, while teams $B$ and $C$ have skill $\beta$. This arrangement is illustrated in figure \ref{fig:diagram1}.

\begin{figure}[ht]
	\centering

	\includegraphics[]{ModelDiagram.png}
	\caption{We have 3 types of nodes: skill types ($\alpha$ and $\beta$), teams ($A$, $B$ and $C$), and incoming project alerts ($P_\alpha$ and $P_\beta$). If a team node is joined to a skill node by an edge, then the team possesses that skill. All of the teams have one way connections with the incoming project alerts nodes because the teams respective state do not effect incoming projects' state, but are effected by them.}
	\label{fig:diagram1}
\end{figure}

With the teams, skills and assignment of these defined, we specify the details of the model dynamics in the following three steps.

\begin{steps}
	
	\item \textbf{Arrival of projects}\\
	Earlier we stated that this process was based on a multivariate Bernoulli distribution. Specifically we use the 2-dimensional version, as we are working with 2 types of skills. We specify the vector of probabilities: $\mathbf{p} = (p_\alpha, p_\beta)$ such that an incoming project requires skill $\alpha$ with probability $p_\alpha$ and similarly for skill $\beta$.
	
	We create two `incoming project alert' nodes which we label as $P_\alpha$ and $P_\beta$. The state of these nodes is determined only by the previously mentioned probability distribution. Hence these nodes transition states independently of any other node. 
	
	\item \textbf{Assignment of projects}\\
	First are the 3 simple cases. If a project which requires skill $\alpha$ but not $\beta$ arrives, and team $A$ is idle, then the project is assigned to $A$, resulting in team $A$ turning on. Similarly teams $B$ and $C$ will turn on if a project arrives tailored to their abilities while they are not already active.	
	
	2 more cases exist: If a project suitable for team $A$ arrives while $A$ is busy and $C$ is idle, then $C$ will be assigned $A$'s task. The same will apply if $B$ is busy when such a project arrives. Finally, if a project requiring both skills arrives while $C$ is busy while $A$ and $B$ are both idle, then $A$ and $B$ will be assigned the project, resulting in both of them transitioning to a state of `on'.
	
	\item \textbf{Completion of projects}\\
	We already stated the time required to complete a project to be modelled by th exponential distribution. This was so we could use a simple Bernoulli process to determine when a project is completed. This means that the probability of completing a project is constant with respect to time. However, to make this process more realistic, we decide that the probability of completing a project will not be independent of active working connections.
	
	We define the parameters $k_A$, $k_B$ and $k_C$ to represent the effectiveness of each team. If $A$ is active, then it will complete its task with probability $k_A$ after each time-step, and so on. 
	
	However, when teams are working on similar tasks, then collaboration occurs. Specifically, if teams $A$ and $C$ are both active, since skill $\alpha$ is required for both projects, $C$ will assist $A$. However, as $C$'s project also involved skill $\beta$, $A$ will be unable to return the assistance. In this case, $A$ will finish its task after the next time-step with probability $k_A + k_B$, which for $C$ things are unchanged. 
	
	$C$ can only receive assistance when all teams are active, since together $A$ and $B$ account for all required skills. In this final case, $C$ will complete its task with probability $k_A+k_B+k_C$.
\end{steps}


Now we can put this all together to form the state by node transition probability matrix: $\mathbf{T}$, defined as:
\begin{equation}
\mathbf{T}_{ij}= P(z^j_{t+1}=1 | Z_t = i)
\end{equation}

where $Z$ refers to the entire network with $z^j$ standing for $A$, $B$, and $C$ (the team nodes) in addition to $P_\alpha$ and $P_\beta$, (the incoming project alert nodes) for $j=1,2, \ldots, 5$. $\mathbf{T}$ is the \textit{state by node} transition probability matrix, as previous described in section \ref{sec:conditional_independence} having 32 rows and 5 columns. We present this matrix in table \ref{mat:simple_system}.


\begin{table}[h!]
	\centering
	$
	\begin{array}{|l|ccccc}
		\hline
		\multicolumn{1}{|r|}{\text{State}} & \multicolumn{1}{c|}{A} & \multicolumn{1}{c|}{B} & \multicolumn{1}{c|}{C} & \multicolumn{1}{c|}{P_\alpha} & \multicolumn{1}{c|}{P_\beta} \\ \hline
		000 00                      & 0                      & 0                      & 0                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		100 00                      & 1-k_A                 & 0                      & 0                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		010 00                      & 0                      & 1-k_B                 & 0                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		110 00                      & 1-k_A                 & 1-k_B                 & 0                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		001 00                      & 0                      & 0                      & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		101 00                      & 1-k_A-k_C            & 0                      & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		011 00                      & 0                      & 1-k_B-k_C            & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		111 00                      & 1-k_A-k_C            & 1-k_B-k_C            & 1-k_A-k_B-k_C       & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		000 10                      & 1                      & 0                      & 0                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		100 10                      & 1-k_A                 & 0                      & 1                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		010 10                      & 1                      & 1-k_B                 & 0                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		110 10                      & 1-k_A                 & 1-k_B                 & 1                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		001 10                      & 1                      & 0                      & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		101 10                      & 1-k_A-k_C            & 0                      & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		011 10                      & 1                      & 1-k_B-k_C            & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		111 10                      & 1-k_A-k_C            & 1-k_B-k_C            & 1-k_A-k_B-k_C       & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		000 01                      & 0                      & 1                      & 0                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		100 01                      & 1-k_A                 & 1                      & 0                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		010 01                      & 0                      & 1-k_B                 & 1                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		110 01                      & 1-k_A                 & 1-k_B                 & 1                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		001 01                      & 0                      & 1                      & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		101 01                      & 1-k_A-k_C            & 1                      & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		011 01                      & 0                      & 1-k_B-k_C            & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		111 01                      & 1-k_A-k_C            & 1-k_B-k_C            & 1-k_A-k_B-k_C       & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		000 11                      & 0                      & 0                      & 1                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		100 11                      & 1-k_A                 & 0                      & 1                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		010 11                      & 0                      & 1-k_B                 & 1                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		110 11                      & 1-k_A                 & 1-k_B                 & 1                      & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		001 11                      & 1                      & 1                      & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		101 11                      & 1-k_A-k_C            & 0                      & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		011 11                      & 0                      & 1-k_B-k_C            & 1-k_C                 & p_\alpha                      & p_\beta                      \\ \cline{1-1}
		111 11                      & 1-k_A - k_C          & 1-k_B-k_C            & 1-k_A-k_B-k_C       & p_\alpha                      & p_\beta                      \\ \cline{1-1}
	\end{array}
	$
	\caption{Above is the Transition Probability Matrix for the small 3-node model. We represent each state of the system as a length 5 binary string, where the 1s and 0s refer to `on' and `off' respectively. We list nodes in the order: $A, B, C, P_\alpha, P_\beta$. Hence, 10010 means that nodes $A$ and $P_\alpha$ are active, while the rest are idle.}
	\label{mat:simple_system}
\end{table}



Finally, for this model to be interesting, we need to have some control over the parameters. For this, we think of $k_A$, $k_B$ and $k_C$ of being directly related to the funding invested in each team. Hence we assume $k_A+k_B+k_C = K$, where $K$ is a constant which refers to the total amount of funding at the organisations disposal. $k_A$, $k_B$ and $k_C$ refer to how we allocate that funding.

When solving for this model, we will employ two methods: IIT and a classical approach. For IIT, we will compute the value of $\Phi$, while for the classical approach, we instead will introduce the notion of costs, and from this compute the economic performance with respect to the parameters $k_A$, $k_B$ and $k_C$. 

\subsubsection{Classical Solution}
Currently in our model a project will definitely be completed, the question is how long it will take. Thus we don't have to worry about the cost of failed projects. Instead, we concern ourselves with the value of missed projects: those which arrive when there is no suitable team or combination of team available to be assigned to it. Define $W_A$, $W_B$ and $W_C$ to be the waste incurred when a project requiring skills $\alpha$, $\beta$ and both  is missed respectively.

When does this waste happen? Look back at table \ref{mat:model1}. In the defined allocation process, the only states at which waste can occur are: $10110$, $11110$, $01101$, $11101$, $10111$, $01111$ and $11111$. If the last two digits of the state is $10$, then a project requiring skill $\alpha$ is lost, resulting in waste of $W_A$. If the digits are $01$, a project needing skill $\beta$ is lost, resulting in waste of $W_C$. The rest refer to a project needing both skills, for which the waste is $W_C$. In short, waste results from exactly 7 different states, and can be either $W_A$, $W_B$ or $W_C$.

So we know how much money we expect to waste for each state. Now the question is: how often do we expect to be at each state? We can take two approaches: either we can simulate the system and compute waste from the time series, or else we can compute the expected waste per iteration by finding the stationary distribution of the system. We take the latter approach.

When the values of $k_i \in (0,1)$, then the $32\times32$ state by state transition probability matrix $\mathbf{M}$ will have an eigenvalue of 1 with geometric multiplicity 1. Furthermore, $-1$ will not be an eigenvalue. Hence the left eigenvector with eigenvalue 1 will the be stationary distribution of the system, which precisely describes the long term behaviour of the system. 

Hence our cost function is:
\begin{equation}
\label{eq:simple_model_cost_function}
f(k_A, k_B, k_C) = \mathbf{q}(W_A, W_B, W_C) \cdot \mathbf{v}(k_A, k_B, k_C, p_\alpha, p_\beta)
\end{equation}

where $\mathbf{v}$ is the stationary distribution of the system, which depends on $k_A$, $k_B$, $k_C$, $p_\alpha$ and $p_\beta$ while $\mathbf{q}$ is a vector which contains the cost of each state hence depending on $W_A$, $W_B$ and $W_C$. In short, given the 5 constants: $p_\alpha$, $p_\beta$, $W_A$, $W_B$ and $W_C$, we can express cost as a function of $k_A$, $k_B$ and $k_C$. 

\begin{remark}
	In equation \ref{eq:simple_model_cost_function} we assume that $\mathbf{v}$, the stationary distribution of the TPM exists. In practice for the model derived this is a valid assumption. For every computation, we first checked that -1 is not an eigenvalue of $\mathbf{M}$, and that the eigenvalue 1 has geometric multiplicity of 1. This was always the case.
\end{remark}

\subsubsection{IIT Comparison}

In this section we compare the results of IIT with the expected waste of the network. $\Phi$ depends on the matrix $\mathbf{M}$ and the initial state. However, we would prefer to have a function which is independent of state like our cost function. Thus, just as we computed cost in equation \ref{eq:simple_model_cost_function} by taking the inner project of the cost vector with the stationary distribution, we take a similar approach here.
Define $\mathbf{\Phi}$ the length $2^n$ vector containing the values of $\Phi$ at each state of the system. Using this, we compute:

\begin{equation}
\mathbb{E}[\Phi]:= \mathbf{\Phi}\cdot \mathbf{v}(k_A, k_B, k_C, p_\alpha, p_\beta)
\end{equation}

Using $\mathbb{E}[\Phi]$ instead of $\Phi$ given a particular state makes sense intuitively. Suppose $\Phi$ measured in some what the quality of the project allocation process at a particular step. Then its is possible that the reason it was a good step was because it will create opportunities in the future by taking on costs in the present. Thus we would be more interested in the average value of $\Phi$ if it were to have this meaning, which is what we hope.

Finally we compare $\mathbb{E}[\Phi]$ against expected waste. We arbitrarily choose $p_\alpha$ and $p_\beta$ to both be $0.5$, while we pick $W_A=0.3$, $W_B = 0.5$ and $W_C = 0.2$. Finally we set $K = k_A+k_B+k_C = 0.5$, and vary the parameters according to this constraint. We present our results in figure \ref{fig:simple_model_phi_cost_plot}.

\begin{figure}[!ht]
	\centering
	\includegraphics[scale = 0.5]{phicostplot.pdf}
	\caption{We present a scatter-plot of the values for $\mathbb{E}[\Phi]$ and expected waste, when we vary the parameters $k_A, k_B$ and $k_C$ subject to $k_A+k_B+k_B=1/2$.}
	\label{fig:simple_model_phi_cost_plot}
\end{figure}

What we find is there does seem to be a relation between the expected waste and $\mathbb{E}[\Phi]$. When we look at figure, we see what the points lie along a shape which resembles a quadratic function with respect to expected waste. This is ideal from the perspective that it leads us to believe that these values are not independent of each other. On the other hand, we can't express Expected Waste as a function of $\mathbb{E}[\Phi]$ since, the shape bends back on itself. i.e. if we pick the value of $\mathbb{E}[\Phi]$ which corresponding to the point of minimal waste, there are other points that have considerably more waste, yet with the same value of $\mathbb{E}[\Phi]$.

While we could adjust the parameters to see how this shape evolves, instead we question whether this model is suitable, or should be added to. We identify the following flaws in this setup:

\begin{enumerate}
	\item As things stand, the project allocation process assumes that all three worker nodes are connected to each other, and hence communicating at all times. More interesting results might be obtained if the connectivity was more sparse.
	
	\item The current definition of waste is the value of the projects which can't be done because the workers are busy. However, this rather measures missed opportunities due to the size of the organisation, as opposed to communication errors. We're more interested in measuring the direct consequences of miscommunication.

\end{enumerate}

Motivated by these observations, we need to include more worker nodes into the model so that we can have sparser connections, without the system becoming trivial. 

\subsection{The 5-node Model}

The general design of this model is the same as that in section \ref{sec:3nodemodel}. We begin by listing the extensions/adjustments:



We extend the previous model as follows: 
\begin{enumerate}


	\item Before there were 2 types of skills: $\alpha$ and $\beta$. We now include a third: $\gamma$.
	
	\item As implied in the section title, we increase the size of the organization from 3 to 5 nodes. The first 3 nodes: $A$, $B$ and $C$ possess the same skills as in section \ref{sec:3nodemodel}. The two additional nodes $D$ and $E$ possess the skills $\alpha, \gamma$ and $\beta, \gamma$ respectively. We illustrate this in figure \ref{fig:diagram2}.
	
	\item We change our definition of waste to focus on errors due to miscommunication, as opposed to merely projects which cannot be attempted.
	
	\item We adjust the project allocation procedure to be dependent on the connectivity matrix.
\end{enumerate}

\begin{SCfigure}
	\centering	
	\includegraphics[]{Model2Diagram.png}
	\caption{We have 3 types of nodes: skill types ($\alpha$, $\beta$, and $\gamma$), teams ($A$, $B$, $C$, $D$, and $E$), and incoming project alerts ($P_\alpha$, $P_\beta$ and $P_\gamma$). If a team node is joined to a skill node by an edge, then the team possesses that skill. The teams receive inputs from the incoming project alert nodes, but the dependence is strictly one directional.
		Certain teams are connected, indicating that they are actively communicating with each other so to distribute work efficiently. Note that in this figure, we have 2 disconnected clusters of teams. This will give rise to waste.}
	\label{fig:diagram2}
\end{SCfigure}

The increased size of this model allows us more realistic scenarios in which waste occurs due to miscommunication. The main question is: will $\Phi$ have a more obvious relation to this form of waste. Now we must define in detail: how allocate incoming projects, and how to define waste.


In the previous model, we allocated projects from a global perspective. We knew for any given project was the the best arrangement would be, and then chose this to happen. Since all the teams involved were in communication, this made sense. However, what happens if teams are not all communicating? For this model, we establish the following localised decision making policy to determine whether or not a team decides to take on a project. In decreasing order of importance, each team should aim to:


\begin{enumerate}
	\item Ensure that a project is allocated if it is possible to do so.
	\item Ensure that if a project is being worked on, that only on set of teams is doing so. In other words, ensure that there doesn't exist any duplication of labour.
	\item Minimize the amount of excess skills possessed by the team/teams assigned to the project.
\end{enumerate}

When applying this policy, each individual team acts as if any team which it is not paying attention to does not exist. This means that if a team is disconnected from all other teams (meaning it does not know what any of the others are doing), then it will always take on an incoming project which it can do. This will happen independently of whether another team is also taking on the project, because the isolated team does not know this. 

Similarly, if a pair of strongly connected teams see a project which they are overqualified for, and can both see another pair of teams which can complete the project with less excess skills, then the first team will ignore the project. However, while the first pair of teams observed that the second pair were both idle, it couldn't observe whether the 2nd two were strongly connected. If the second team are not strongly connected, then the project will be missed entirely, due to lack of communication. We illustrate this phenomenon in figure \ref{fig:waste1demo1}.

\begin{SCfigure}
	\centering	
	\includegraphics[scale=0.09]{Waste1demo1.png}
	\caption{In this example we have an incoming project which requires both skills $\alpha$ and $\beta$. Teams $D$ and $E$ would possess these skills if they collaborate which they can do as they are connected, even though they have 2 $\gamma$ skills in excess. However, both $D$ and $E$ can see that the collaboration of $A$ and $B$ can complete the project more efficiently. Thus $D$ and $E$ do not take on the project as they do not know that $A$ and $B$ are not collaborating, and thus won't take the project either. Due to this lack of communication, even though there were plenty of ways that the project might have been done, the project is wasted.}
	\label{fig:waste1demo1}
\end{SCfigure}

 Next we turn our attention exclusively to the classical solution, where we redefine the notion of waste.

\subsubsection{Classical Solution}

In this section, we compute the expected waste which will result from a particular connectivity matrix. However, we first must lay out what we mean by `waste'. In the context of this model, there are 3 different types of inefficiencies that can occur in the distribution of projects:

\begin{enumerate}
	\item \textbf{Unnecessary dismissal of project}\\
	If there exists a minimal subset of idle teams which possess the required skills to take on an incoming project, and yet the project is not assigned to anyone, then this is wasteful of the project itself.
	
	\item \textbf{Duplication of work}\\
	If there exists multiple minimal subsets of idle teams which possess the required skills to take on an incoming project, and multiple of these groups of teams are assigned to the project, then this is an unnecessary duplication of labour.
	
	\item \textbf{Excess Skills}
	If there exists an idle team which possesses skills beyond the requirements of an incoming project, and this team is assigned to the project, then this wasteful of these excess skills.
\end{enumerate}

Of these 3 sources of waste, we arbitrarily view type 1 to be 10 times worse than type 2 which is again 10 times worse than type 3. However, what is the numerical value of these costs?

For this we take a simplistic approach. We assign the values $W_\alpha, W_\beta$ and $W_\gamma$ to be the values of each skill type. When counting type 1 waste (a doable project is ignored), we add the values of all skills required and scale by 10. Hence, a project requiring all 3 skills would have a cost of $10(W_\alpha+W_\beta+W_\gamma)$.

With type 2 waste (a project being worked on by more than one team), we count the skills possessed by all teams which are assigned to the project. Then we determine how many times the project could be completed form this pool of skills. We assign the cost in this case to be the sum of the costs applying to the skills required by the project, multiplied by the number of times we find this 

When counting type 3 waste, we count how many excess skills are possessed by the assigned teams, and then add up the values of these skills. Finally we scale this value by $1/10$.

\begin{remark}
	In section \ref{sec:3nodemodel}, we assigned a distinct cost to each type of project. Here we simplify that approach as otherwise we would be left with 8 parameters.
\end{remark}

By applying this definition of waste to all states of the system, we construct the vector function $\mathbf{q}(W_\alpha, W_\beta, W_\gamma)$ so that each value in the vector refers to the waste given the corresponding state and parameters. From this, we construct our function:

\begin{equation}
\label{eq:cost_function}
Cost(k_A, k_B, k_C) = \mathbf{q}(W_A, W_B, W_C) \cdot \mathbf{v}(k_A, k_B, k_C,k_E, k_F, p_\alpha, p_\beta, p_\gamma)
\end{equation}
where $\mathbf{v}$ is the same vector function defined in section \ref{sec:3nodemodel} appropriately adjusted for the additional nodes and skill type.

\subsubsection{IIT Comparison}

When comparing $\mathbb{E}[Cost]$ to $\mathbb{E}[\Phi]$, we first need to decide the context in which we are doing do. The approach we took was to keep the parameters $k_i, p_i$ and $W_i$ all fixed, and instead to vary the connectivity matrix. We justify this choice on grounds that: in an existing organisation, these values would be difficult to change. What could change more easily is who talks to whom. Thus we view that choosing the connectivity matrix to be our variable is more relevant to the problem.


We set up a small problem which can be solved exhaustively. Specifically, we consider the matrix which applies to figure \ref{fig:diagram2}, in that the nodes $A$, $B$ and $C$ are completely connected to each other, which being entirely disconnected from $D$ and $E$. This matrix is a $5\times 5$ block diagonal matrix consisting of a $3 \times 3$ and $2 \times 2$ matrix of 1's along the diagonal. Next we introduce an addition 4 directed edges with which we want to join these 2 clusters.

Intuitively, this problem can be though of as forcing two distinct department to talk to each other, and searching for the best way that this can be accomplished. In this setup, there are only 495 different connectivity matrices, and hence an exhaustive search is achievable.



\begin{SCfigure}
	\centering
	\includegraphics[scale=0.4]{maxvscost_small.pdf}
	\caption{We plot  $\mathbb{E}[Cost]$ against $\mathbb{E}[\Phi]$ for connectivity matrices where we add 4 directed edges to the network shown in figure \ref{fig:diagram2}}
	\label{fig:maxvscost_small}
\end{SCfigure}

We plot $\mathbb{E}[Cost]$ against $\mathbb{E}[\Phi]$ for this case, showing the result in figure \ref{fig:maxvscost_small}. We see that $\mathbb{E}[Cost]$ correlates with $\mathbb{E}[\Phi]$ similarly to figure \ref{fig:model_costvsphi}. The shape is not linear, but there is a trend that increasing $\mathbb{E}[\Phi]$ will reduce \ref{fig:model_costvsphi}.

\begin{SCfigure}
	\centering
	\includegraphics[scale = 0.13]{Best_option.png}
	\caption{We show the network which generated both the smallest $\mathbb{E}[Cost]$, and the largest $\mathbb{E}[\Phi]$. The two way link between $B$ and $D$ allows the network to have one combination of teams which can complete the project requiring all skills. The other one way links from $D$ affect results by minimizing duplication of work.}
	\label{fig:opt_network}
\end{SCfigure}

In figure \ref{fig:opt_network} we show the network which both maximised $\mathbb{E}[\Phi]$ and minimized $\mathbb{E}[Cost]$. What is interesting is that of the connections added, we see both unidirectional edges, and a two-way edge. This makes sense when we consider that two-way edges reduce waste due to missed opportunities, as only these connections allow two teams to collectively complete a project which on their own would not be possible. Unidirectional edges on the other hand are equally effective at reducing duplication of labour, and are more efficient at doing so. We conclude that the relative importance that the company places on avoiding duplication of work, and missing opportunities needlessly will affect how many two-way edges exist in the optimal network.


\section{IIT revisited}
In section \ref{sec:iit}, we presented the definitions of Integrated Information Theory as defined by Oizumi et al \cite{oizumi2014phenomenology}, while using a modification of the notation presented by \cite{krohn2016computing}. In this section, we will critique the mathematical implementation of IIT, and consider whether it is indeed applicable to the problem of consideration: communication within an organisation.

\subsection{Distance Between Repertoires}
\label{sec:speedup}
We examine the process of computing distances between \textit{effect repertoires}. Let $Y$ be a \textit{consideration set}, and $W$ a $m$-th order mechanism. Consider the computation of: $\varphi^{M,N}_{cause}(W_t = \mathbf{s}, Y)$. This value is equal to the distance between two repertoires: $p_e(Y_{t+1}|W_t = \mathbf{s})$ and $p_e^{M,N}(Y_{t+1}|W_t = \mathbf{s})$. We call these distributions $\mathbf{p}^1$ and $\mathbf{p}^2$ for convenience.

In practice, we always compute the \textit{generators} before constructing the distributions. Call the \textit{generators} of these two functions $\mathbf{q}^1$ and $\mathbf{q}^2$. Then:

\begin{equation}
\label{eq:demonstrating_idea1}
\text{EMD}(\mathbf{p}^1, \mathbf{p}^2) =\text{EMD}(R(\mathbf{q}^1), R(\mathbf{q}^2))
\end{equation}

Computing eqation \ref{eq:demonstrating_idea1} first involves applying $R$, which scales with $2^n$, and then using the $EMD$ which scales with $n^3 2^{3n}$. In order to skip this step, we propose the following theorem:

\begin{theorem}
	\label{thm:speedup}
	Let $\mathbf{p}^1$, $\mathbf{p}^2$, $\mathbf{q}^1$, and $\mathbf{q}^1$ be defined as above. Then:
	
	\begin{equation}
	\label{eq:theorem_statement}
	\text{EMD}(\mathbf{p}^1, \mathbf{p}^2)= ||\mathbf{q}^1 - \mathbf{q}^2||_1
	\end{equation}
\end{theorem}

\begin{proof}
	From theorem \ref{thm:bijection} we know $\mathbf{p}^i = \mathbf{q}^i \mathbf{S} \quad i = 1,2$, where $S$ is the \textit{state matrix}. 
	
	Let the matrix $\mathbf{F}$, and $\mathbf{D}$ be the matrices from definition \ref{def:emd}. Then
	\begin{equation}
	\label{proof1}
	\text{EMD}(\mathbf{p}^1, \mathbf{p}^2) = \sum \limits_{i,j = 1}^n F_{ij} D_{ij}.
	\end{equation}
	
	Furthermore, we know from definition \ref{def:emd} that $\sum \limits_{j=1}^n F_{ij} = \mathbf{p}^1_i$ and $\sum \limits_{i=1}^n F_{ij} = \mathbf{p}^2_j$.
	We insert these values into equation \ref{eq:theorem_statement} to get:
	
	\begin{equation}
	\label{proof2}
	\sum \limits_{i,j = 1}^n F_{ij} D_{ij} = || (\mathbf{p}^1 - \mathbf{p}^2)\mathbf{S}||_1.
	\end{equation}
	
	By substituting $\mathbf{p}^1_i$ and $\mathbf{p}^2_i$ for $\sum \limits_{j=1}^n F_{ij}$ and $\sum \limits_{j=1}^n F_{ji}$ respectively on the RHS and rewriting in sigma notation, we simplify this to
	\begin{equation}
	\label{proof3}
	\sum \limits_{i,j = 1}^n F_{ij} D_{ij} = \sum \limits_{i,j = 1}^n F_{ij}|| S_{ki} - S_{kj}||_1.
	\end{equation}
	
	However, $|| S_{ik} - S_{jk}||_1$ gives precisely the Hamming Distance between the states $S_i$ and $S_j$. Therefore $|| S_{ik} - S_{jk}||_1 = D_{ij}$. Hence we have equality.
\end{proof}

\begin{remark}
	Theorem \ref{thm:speedup} states that the process of computing the distance between repertoires by calculating $\text{EMD}(R(\mathbf{q}^1), R(\mathbf{q}^2))$ which scales with $O(n^3 2^n)$ gives precisely the same value as $||\mathbf{q}^1-\mathbf{q}^2||_1$ which scales with $O(n)$. We illustrate the reduction in computation time in figure
\end{remark}
	
\begin{SCfigure}
	\centering
	\includegraphics[scale = 0.37]{speedup_demo.pdf}
	\caption{We compare the cost of measuring distance using the Earth Movers Distance between distributions against using the 1-norm on \textit{distributio generators} by plotting how they scale on a loglog plot.}
	\label{fig:speedup_demo}
\end{SCfigure}	
	
\subsection{Mathematical Assumptions of IIT}

In this section, we return to certain assumptions/definitions of IIT and question their necessity for the communication flow problem. However, we do not comment on the necessity of these assumptions for defining \textit{consciousness}, since the argument that $\Phi^{\text{Max}}$ is \textit{consciousness} is entirely philosophical. We discus the following points:
\begin{enumerate}
	\item Necessity of \textit{cause}.
	\item Assumption of Conditional Independence.
	\item Use of a Causal Network setting instead of Bayesian.
\end{enumerate}

First of all, when computing the importance of some information in section \ref{sec:little_phi}, we make the computation looking both into the past and future. In the context of communication within an organisation, there is no reason why this should be important, given that the past is known anyway. A company would rather know how a decision would affect results in the future, than worrying about what it says about the past. Removal of this feature would immediately reduce the computational time by a factor of at least 2.

In \cite{oizumi2014phenomenology}, all of the computations rely on the assumption of conditionally independence. The fact that this is assumed is not stated in the paper, but only in the supplementary text. When stated, no justification is given for why this assumption is made. Therefore we do not know whether it is meant to simplify computations, or is based on some measurable property of the brain.


Finally, within the context of a \textit{system}, it is unclear why IIT does not make use of Bayesian methods. In particular, the property that the \textit{cause repertoire} is given in equation \ref{def:controversial} 

\section{Conclusions}
In summary, the first focus of this project was to investigate whether or not $\Phi^\text{Max}$ related to information flow within an organisation. We constructed a model to measure the cost of wasted opportunities due to poor communication. The cost of this waste as we defined it does correlate with $\Phi^\text{Max}$. This correlation is rough, but it does exist, which justifies the theory that $\Phi^\text{Max}$ does relate to communication within a company. 

We proved that the $\Phi^\text{Max}$ is too computationally expensive to use in practice, even on systems containing as few as 9 nodes. This computational expense is caused to iterating over the power set of the \textit{system} multiple times, in addition to searching all possible partitions repeatedly. However, as the steps in computing $\Phi^\text{Max}$ are repetitive, we expect that further mathematical scrutiny may result in reducing the size of the computation by locating and removing irrelevant steps. In section \ref{sec:speedup} we identified one such inefficiency, and suggested an alternative method which reduced the expense of a particular step from $O(n^3 2^{3n})$ to $O(n)$. 

If an  method could be found to approximate the minimum information partition (MIP), this would speed up the process considerably. Alternatively, it might be possible to determine what types of networks generate large $\Phi^\text{Max}$, and design a recipe to construct them directly. However until either of these are accomplished and speed up is achieved, IIT is far too expensive to be used on models containing a realistic number of workers. Hence, while $\Phi^\text{Max}$ correlates with effectiveness of the network, it doesn't provide any practical help in optimizing communication while in its current state.


